{"id": "2507.07315", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.07315", "abs": "https://arxiv.org/abs/2507.07315", "authors": ["Ricardo Vega", "Cameron Nowzari"], "title": "Classifying Emergence in Robot Swarms: An Observer-Dependent Approach", "comment": "25 pages, 3 tables, 8 figures", "summary": "Emergence and swarms are widely discussed topics, yet no consensus exists on\ntheir formal definitions. This lack of agreement makes it difficult not only\nfor new researchers to grasp these concepts, but also for experts who may use\nthe same terms to mean different things. Many attempts have been made to\nobjectively define 'swarm' or 'emergence,' with recent work highlighting the\nrole of the external observer. Still, several researchers argue that once an\nobserver's vantage point (e.g., scope, resolution, context) is established, the\nterms can be made objective or measured quantitatively. In this note, we\npropose a framework to discuss these ideas rigorously by separating externally\nobservable states from latent, unobservable ones. This allows us to compare and\ncontrast existing definitions of swarms and emergence on common ground. We\nargue that these concepts are ultimately subjective-shaped less by the system\nitself than by the perception and tacit knowledge of the observer.\nSpecifically, we suggest that a 'swarm' is not defined by its group behavior\nalone, but by the process generating that behavior. Our broader goal is to\nsupport the design and deployment of robotic swarm systems, highlighting the\ncritical distinction between multi-robot systems and true swarms.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u2018\u6d8c\u73b0\u2019\u548c\u2018\u7fa4\u4f53\u2019\u7684\u5b9a\u4e49\u7f3a\u4e4f\u5171\u8bc6\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u5206\u53ef\u89c2\u5bdf\u548c\u4e0d\u53ef\u89c2\u5bdf\u72b6\u6001\u6765\u8ba8\u8bba\u8fd9\u4e9b\u6982\u5ff5\uff0c\u5e76\u5f3a\u8c03\u8fd9\u4e9b\u6982\u5ff5\u7684\u4e3b\u89c2\u6027\u3002", "motivation": "\u7531\u4e8e\u2018\u6d8c\u73b0\u2019\u548c\u2018\u7fa4\u4f53\u2019\u7f3a\u4e4f\u660e\u786e\u7684\u5b9a\u4e49\uff0c\u5bfc\u81f4\u65b0\u7814\u7a76\u8005\u96be\u4ee5\u7406\u89e3\uff0c\u4e13\u5bb6\u4e5f\u53ef\u80fd\u5bf9\u540c\u4e00\u672f\u8bed\u6709\u4e0d\u540c\u7406\u89e3\u3002\u8bba\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u4e25\u8c28\u7684\u8ba8\u8bba\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u533a\u5206\u5916\u90e8\u53ef\u89c2\u5bdf\u72b6\u6001\u548c\u6f5c\u5728\u4e0d\u53ef\u89c2\u5bdf\u72b6\u6001\uff0c\u4ee5\u6bd4\u8f83\u548c\u5bf9\u6bd4\u73b0\u6709\u5b9a\u4e49\u3002", "result": "\u8ba4\u4e3a\u2018\u6d8c\u73b0\u2019\u548c\u2018\u7fa4\u4f53\u2019\u7684\u6982\u5ff5\u662f\u4e3b\u89c2\u7684\uff0c\u66f4\u591a\u53d6\u51b3\u4e8e\u89c2\u5bdf\u8005\u7684\u89c6\u89d2\u548c\u9690\u6027\u77e5\u8bc6\uff0c\u800c\u975e\u7cfb\u7edf\u672c\u8eab\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u4e86\u7fa4\u4f53\u884c\u4e3a\u751f\u6210\u8fc7\u7a0b\u7684\u91cd\u8981\u6027\uff0c\u800c\u975e\u4ec5\u884c\u4e3a\u672c\u8eab\uff0c\u4e3a\u673a\u5668\u4eba\u7fa4\u4f53\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2507.07370", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.07370", "abs": "https://arxiv.org/abs/2507.07370", "authors": ["Zhanhong Jiang", "Dylan Shah", "Hsin-Jung Yang", "Soumik Sarkar"], "title": "Data-driven Kinematic Modeling in Soft Robots: System Identification and Uncertainty Quantification", "comment": "6 pages; 6 figures; accepted at the 5th Modeling, Estimation and\n  Control Conference (MECC 2025)", "summary": "Precise kinematic modeling is critical in calibration and controller design\nfor soft robots, yet remains a challenging issue due to their highly nonlinear\nand complex behaviors. To tackle the issue, numerous data-driven machine\nlearning approaches have been proposed for modeling nonlinear dynamics.\nHowever, these models suffer from prediction uncertainty that can negatively\naffect modeling accuracy, and uncertainty quantification for kinematic modeling\nin soft robots is underexplored. In this work, using limited simulation and\nreal-world data, we first investigate multiple linear and nonlinear machine\nlearning models commonly used for kinematic modeling of soft robots. The\nresults reveal that nonlinear ensemble methods exhibit the most robust\ngeneralization performance. We then develop a conformal kinematic modeling\nframework for soft robots by utilizing split conformal prediction to quantify\npredictive position uncertainty, ensuring distribution-free prediction\nintervals with a theoretical guarantee.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5171\u5f62\u9884\u6d4b\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u975e\u7ebf\u6027\u96c6\u6210\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u9ad8\u5ea6\u975e\u7ebf\u6027\u548c\u590d\u6742\u884c\u4e3a\u4f7f\u5f97\u7cbe\u786e\u8fd0\u52a8\u5b66\u5efa\u6a21\u6210\u4e3a\u6311\u6218\uff0c\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5b58\u5728\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u7814\u7a76\u591a\u79cd\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u63d0\u51fa\u57fa\u4e8e\u5171\u5f62\u9884\u6d4b\u7684\u6846\u67b6\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u975e\u7ebf\u6027\u96c6\u6210\u65b9\u6cd5\u8868\u73b0\u6700\u4f18\uff0c\u5171\u5f62\u9884\u6d4b\u6846\u67b6\u80fd\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u7684\u9884\u6d4b\u533a\u95f4\u3002", "conclusion": "\u5171\u5f62\u9884\u6d4b\u6846\u67b6\u4e3a\u8f6f\u4f53\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2507.07559", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.07559", "abs": "https://arxiv.org/abs/2507.07559", "authors": ["Amirhossein Sadough", "Mahyar Shahsavari", "Mark Wijtvliet", "Marcel van Gerven"], "title": "Real-Time Decorrelation-Based Anomaly Detection for Multivariate Time Series", "comment": null, "summary": "Anomaly detection (AD) plays a vital role across a wide range of real-world\ndomains by identifying data instances that deviate from expected patterns,\npotentially signaling critical events such as system failures, fraudulent\nactivities, or rare medical conditions. The demand for real-time AD has surged\nwith the rise of the (Industrial) Internet of Things, where massive volumes of\nmultivariate sensor data must be processed instantaneously. Real-time AD\nrequires methods that not only handle high-dimensional streaming data but also\noperate in a single-pass manner, without the burden of storing historical\ninstances, thereby ensuring minimal memory usage and fast decision-making. We\npropose DAD, a novel real-time decorrelation-based anomaly detection method for\nmultivariate time series, based on an online decorrelation learning approach.\nUnlike traditional proximity-based or reconstruction-based detectors that\nprocess entire data or windowed instances, DAD dynamically learns and monitors\nthe correlation structure of data sample by sample in a single pass, enabling\nefficient and effective detection. To support more realistic benchmarking\npractices, we also introduce a practical hyperparameter tuning strategy\ntailored for real-time anomaly detection scenarios. Extensive experiments on\nwidely used benchmark datasets demonstrate that DAD achieves the most\nconsistent and superior performance across diverse anomaly types compared to\nstate-of-the-art methods. Crucially, its robustness to increasing\ndimensionality makes it particularly well-suited for real-time,\nhigh-dimensional data streams. Ultimately, DAD not only strikes an optimal\nbalance between detection efficacy and computational efficiency but also sets a\nnew standard for real-time, memory-constrained anomaly detection.", "AI": {"tldr": "DAD\u662f\u4e00\u79cd\u57fa\u4e8e\u5728\u7ebf\u53bb\u76f8\u5173\u5b66\u4e60\u7684\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff0c\u5177\u6709\u9ad8\u6548\u6027\u548c\u5185\u5b58\u53cb\u597d\u6027\u3002", "motivation": "\u968f\u7740\u5de5\u4e1a\u7269\u8054\u7f51\u7684\u5174\u8d77\uff0c\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u9700\u6c42\u6fc0\u589e\uff0c\u9700\u8981\u5904\u7406\u9ad8\u7ef4\u6d41\u6570\u636e\u4e14\u65e0\u9700\u5b58\u50a8\u5386\u53f2\u5b9e\u4f8b\u7684\u65b9\u6cd5\u3002", "method": "DAD\u901a\u8fc7\u52a8\u6001\u5b66\u4e60\u548c\u76d1\u63a7\u6570\u636e\u7684\u76f8\u5173\u7ed3\u6784\uff0c\u9010\u6837\u672c\u5904\u7406\u6570\u636e\uff0c\u5b9e\u73b0\u5355\u6b21\u901a\u8fc7\u7684\u9ad8\u6548\u68c0\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDAD\u5728\u591a\u79cd\u5f02\u5e38\u7c7b\u578b\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u5408\u9ad8\u7ef4\u5b9e\u65f6\u6570\u636e\u6d41\u3002", "conclusion": "DAD\u5728\u68c0\u6d4b\u6548\u679c\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e3a\u5b9e\u65f6\u5185\u5b58\u53d7\u9650\u7684\u5f02\u5e38\u68c0\u6d4b\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2507.07769", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.07769", "abs": "https://arxiv.org/abs/2507.07769", "authors": ["Ruohong Liu", "Jack Umenberger", "Yize Chen"], "title": "BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning", "comment": "Accepted at the Workshop on Computational Optimization of Buildings\n  (ICML CO-BUILD), 42nd International Conference on Machine Learning (ICML\n  2025), Vancouver, Canada", "summary": "Recent years have seen significant advancements in designing reinforcement\nlearning (RL)-based agents for building energy management. While individual\nsuccess is observed in simulated or controlled environments, the scalability of\nRL approaches in terms of efficiency and generalization across building\ndynamics and operational scenarios remains an open question. In this work, we\nformally characterize the generalization space for the cross-environment,\nmulti-objective building energy management task, and formulate the\nmulti-objective contextual RL problem. Such a formulation helps understand the\nchallenges of transferring learned policies across varied operational contexts\nsuch as climate and heat convection dynamics under multiple control objectives\nsuch as comfort level and energy consumption. We provide a principled way to\nparameterize such contextual information in realistic building RL environments,\nand construct a novel benchmark to facilitate the evaluation of generalizable\nRL algorithms in practical building control tasks. Our results show that\nexisting multi-objective RL methods are capable of achieving reasonable\ntrade-offs between conflicting objectives. However, their performance degrades\nunder certain environment variations, underscoring the importance of\nincorporating dynamics-dependent contextual information into the policy\nlearning process.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u591a\u76ee\u6807\u4e0a\u4e0b\u6587RL\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u4e86\u8bc4\u4f30\u57fa\u51c6\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u73af\u5883\u53d8\u5316\u4e0b\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u5728\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u89e3\u51b3\u8de8\u73af\u5883\u548c\u591a\u76ee\u6807\u4efb\u52a1\u7684\u6311\u6218\u3002", "method": "\u5f62\u5f0f\u5316\u591a\u76ee\u6807\u4e0a\u4e0b\u6587RL\u95ee\u9898\uff0c\u53c2\u6570\u5316\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5e76\u6784\u5efa\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "\u73b0\u6709\u591a\u76ee\u6807RL\u65b9\u6cd5\u80fd\u5728\u51b2\u7a81\u76ee\u6807\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4f46\u5728\u73af\u5883\u53d8\u5316\u4e0b\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u9700\u5728\u7b56\u7565\u5b66\u4e60\u4e2d\u878d\u5165\u52a8\u6001\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u4ee5\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.07129", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07129", "abs": "https://arxiv.org/abs/2507.07129", "authors": ["A. Bochkov"], "title": "Growing Transformers: Modular Composition and Layer-wise Expansion on a Frozen Substrate", "comment": null, "summary": "The prevailing paradigm for scaling large language models (LLMs) involves\nmonolithic, end-to-end training, a resource-intensive process that lacks\nflexibility. This paper explores an alternative, constructive approach to model\ndevelopment, built upon the foundation of non-trainable, deterministic input\nembeddings. In prior [1], we established that high-level semantic reasoning can\nemerge in Transformers using frozen embeddings derived from the visual\nstructure of Unicode glyphs. Here, we demonstrate that this fixed\nrepresentational substrate acts as a universal \"docking port,\" enabling two\npowerful and efficient scaling paradigms: seamless modular composition and\nprogressive layer-wise growth.\n  First, we show that specialist models trained on disparate datasets (e.g.,\nRussian and Chinese text) can be merged into a single, more capable\nMixture-of-Experts (MoE) model, post-training, with zero architectural\nmodification. This is achieved by simply averaging their output logits. The\nresulting MoE model exhibits immediate performance improvements on reasoning\nbenchmarks like MMLU, surpassing its constituent experts without catastrophic\nforgetting. Second, we introduce a layer-wise constructive training\nmethodology, where a deep Transformer is \"grown\" by progressively stacking and\ntraining one layer at a time. This method demonstrates stable convergence and a\nclear correlation between model depth and the emergence of complex reasoning\nabilities, such as those required for SQuAD.\n  Our findings suggest a paradigm shift from monolithic optimization towards a\nmore biological or constructive model of AI development, where complexity is\nbuilt incrementally and modules can be composed freely. This opens new avenues\nfor resource-efficient scaling, continual learning, and a more democratized\necosystem for building powerful AI systems. We release all code and models to\nfacilitate further research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u53ef\u8bad\u7ec3\u3001\u786e\u5b9a\u6027\u8f93\u5165\u5d4c\u5165\u7684\u6784\u9020\u6027\u65b9\u6cd5\uff0c\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6269\u5c55\uff0c\u652f\u6301\u6a21\u5757\u5316\u7ec4\u5408\u548c\u9010\u5c42\u589e\u957f\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6269\u5c55\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u4e14\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u5f00\u53d1\u8303\u5f0f\u3002", "method": "\u5229\u7528\u56fa\u5b9a\u5d4c\u5165\u4f5c\u4e3a\u901a\u7528\u63a5\u53e3\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u7ec4\u5408\uff08\u4e13\u5bb6\u6a21\u578b\u5408\u5e76\uff09\u548c\u9010\u5c42\u589e\u957f\u8bad\u7ec3\u3002", "result": "\u6a21\u5757\u5316\u7ec4\u5408\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\uff08\u5982MMLU\uff09\uff0c\u9010\u5c42\u589e\u957f\u8bad\u7ec3\u7a33\u5b9a\u4e14\u80fd\u9010\u6b65\u63d0\u5347\u590d\u6742\u63a8\u7406\u80fd\u529b\uff08\u5982SQuAD\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aAI\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u751f\u7269\u5316\u3001\u6784\u9020\u6027\u7684\u8303\u5f0f\uff0c\u652f\u6301\u8d44\u6e90\u9ad8\u6548\u6269\u5c55\u548c\u6301\u7eed\u5b66\u4e60\u3002"}}
{"id": "2507.07142", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07142", "abs": "https://arxiv.org/abs/2507.07142", "authors": ["Quanjie Qiu", "MengCheng Lau"], "title": "g2o vs. Ceres: Optimizing Scan Matching in Cartographer SLAM", "comment": null, "summary": "This article presents a comparative analysis of g2o and Ceres solvers in\nenhancing scan matching performance within the Cartographer framework.\nCartographer, a widely-used library for Simultaneous Localization and Mapping\n(SLAM), relies on optimization algorithms to refine pose estimates and improve\nmap accuracy. The research aims to evaluate the performance, efficiency, and\naccuracy of the g2o solver in comparison to the Ceres solver, which is the\ndefault in Cartographer. In our experiments comparing Ceres and g2o within\nCartographer, Ceres outperformed g2o in terms of speed, convergence efficiency,\nand overall map clarity. Ceres required fewer iterations and less time to\nconverge, producing more accurate and well-defined maps, especially in\nreal-world mapping scenarios with the AgileX LIMO robot. However, g2o excelled\nin localized obstacle detection, highlighting its value in specific situations.", "AI": {"tldr": "\u6bd4\u8f83\u4e86g2o\u548cCeres\u6c42\u89e3\u5668\u5728Cartographer\u6846\u67b6\u4e2d\u7684\u626b\u63cf\u5339\u914d\u6027\u80fd\uff0c\u53d1\u73b0Ceres\u5728\u901f\u5ea6\u3001\u6536\u655b\u6548\u7387\u548c\u5730\u56fe\u6e05\u6670\u5ea6\u65b9\u9762\u4f18\u4e8eg2o\uff0c\u800cg2o\u5728\u5c40\u90e8\u969c\u788d\u7269\u68c0\u6d4b\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u8bc4\u4f30g2o\u4e0eCeres\u6c42\u89e3\u5668\u5728Cartographer\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4ee5\u4f18\u5316SLAM\u7684\u5b9a\u4f4d\u548c\u5efa\u56fe\u7cbe\u5ea6\u3002", "method": "\u5728Cartographer\u6846\u67b6\u4e2d\u5bf9\u6bd4g2o\u548cCeres\u7684\u626b\u63cf\u5339\u914d\u6027\u80fd\uff0c\u4f7f\u7528AgileX LIMO\u673a\u5668\u4eba\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "Ceres\u5728\u901f\u5ea6\u3001\u6536\u655b\u6548\u7387\u548c\u5730\u56fe\u6e05\u6670\u5ea6\u4e0a\u4f18\u4e8eg2o\uff0c\u4f46g2o\u5728\u5c40\u90e8\u969c\u788d\u7269\u68c0\u6d4b\u4e2d\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "Ceres\u66f4\u9002\u5408Cartographer\u7684\u6574\u4f53\u4f18\u5316\u9700\u6c42\uff0c\u800cg2o\u5728\u7279\u5b9a\u573a\u666f\uff08\u5982\u969c\u788d\u7269\u68c0\u6d4b\uff09\u4e2d\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2507.07792", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.07792", "abs": "https://arxiv.org/abs/2507.07792", "authors": ["Hermann Klein", "Max Heinz Herkersdorf", "Oliver Nelles"], "title": "Space-Filling Regularization for Robust and Interpretable Nonlinear State Space Models", "comment": null, "summary": "The state space dynamics representation is the most general approach for\nnonlinear systems and often chosen for system identification. During training,\nthe state trajectory can deform significantly leading to poor data coverage of\nthe state space. This can cause significant issues for space-oriented training\nalgorithms which e.g. rely on grid structures, tree partitioning, or similar.\nBesides hindering training, significant state trajectory deformations also\ndeteriorate interpretability and robustness properties. This paper proposes a\nnew type of space-filling regularization that ensures a favorable data\ndistribution in state space via introducing a data-distribution-based penalty.\nThis method is demonstrated in local model network architectures where good\ninterpretability is a major concern. The proposed approach integrates ideas\nfrom modeling and design of experiments for state space structures. This is why\nwe present two regularization techniques for the data point distributions of\nthe state trajectories for local affine state space models. Beyond that, we\ndemonstrate the results on a widely known system identification benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7a7a\u95f4\u586b\u5145\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u5206\u5e03\u60e9\u7f5a\u6539\u5584\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u6570\u636e\u5206\u5e03\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u679c\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u72b6\u6001\u8f68\u8ff9\u53d8\u5f62\u5bfc\u81f4\u72b6\u6001\u7a7a\u95f4\u6570\u636e\u8986\u76d6\u4e0d\u8db3\uff0c\u5f71\u54cd\u8bad\u7ec3\u7b97\u6cd5\u6548\u679c\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6570\u636e\u5206\u5e03\u7684\u6b63\u5219\u5316\u60e9\u7f5a\uff0c\u7ed3\u5408\u5efa\u6a21\u548c\u5b9e\u9a8c\u8bbe\u8ba1\u601d\u60f3\uff0c\u63d0\u51fa\u4e24\u79cd\u6b63\u5219\u5316\u6280\u672f\u3002", "result": "\u5728\u5c40\u90e8\u4eff\u5c04\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u7cfb\u7edf\u8fa8\u8bc6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u7ed3\u679c\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u6539\u5584\u4e86\u72b6\u6001\u7a7a\u95f4\u6570\u636e\u5206\u5e03\uff0c\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u679c\u548c\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.07135", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07135", "abs": "https://arxiv.org/abs/2507.07135", "authors": ["Fran\u00e7ois Gard\u00e8res", "Shizhe Chen", "Camille-Sovanneary Gauthier", "Jean Ponce"], "title": "FACap: A Large-scale Fashion Dataset for Fine-grained Composed Image Retrieval", "comment": null, "summary": "The composed image retrieval (CIR) task is to retrieve target images given a\nreference image and a modification text. Recent methods for CIR leverage large\npretrained vision-language models (VLMs) and achieve good performance on\ngeneral-domain concepts like color and texture. However, they still struggle\nwith application domains like fashion, because the rich and diverse vocabulary\nused in fashion requires specific fine-grained vision and language\nunderstanding. An additional difficulty is the lack of large-scale fashion\ndatasets with detailed and relevant annotations, due to the expensive cost of\nmanual annotation by specialists. To address these challenges, we introduce\nFACap, a large-scale, automatically constructed fashion-domain CIR dataset. It\nleverages web-sourced fashion images and a two-stage annotation pipeline\npowered by a VLM and a large language model (LLM) to generate accurate and\ndetailed modification texts. Then, we propose a new CIR model FashionBLIP-2,\nwhich fine-tunes the general-domain BLIP-2 model on FACap with lightweight\nadapters and multi-head query-candidate matching to better account for\nfine-grained fashion-specific information. FashionBLIP-2 is evaluated with and\nwithout additional fine-tuning on the Fashion IQ benchmark and the enhanced\nevaluation dataset enhFashionIQ, leveraging our pipeline to obtain\nhigher-quality annotations. Experimental results show that the combination of\nFashionBLIP-2 and pretraining with FACap significantly improves the model's\nperformance in fashion CIR especially for retrieval with fine-grained\nmodification texts, demonstrating the value of our dataset and approach in a\nhighly demanding environment such as e-commerce websites. Code is available at\nhttps://fgxaos.github.io/facap-paper-website/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFACap\u6570\u636e\u96c6\u548cFashionBLIP-2\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u65f6\u5c1a\u9886\u57df\u7684\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\uff08CIR\uff09\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ec6\u7c92\u5ea6\u6587\u672c\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709CIR\u65b9\u6cd5\u5728\u901a\u7528\u9886\u57df\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u65f6\u5c1a\u9886\u57df\u56e0\u8bcd\u6c47\u4e30\u5bcc\u591a\u6837\u4e14\u7f3a\u4e4f\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u96c6\u800c\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u6784\u5efaFACap\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6807\u6ce8\u6d41\u7a0b\uff08VLM+LLM\uff09\uff1b\u63d0\u51faFashionBLIP-2\u6a21\u578b\uff0c\u57fa\u4e8eBLIP-2\u5fae\u8c03\uff0c\u5f15\u5165\u8f7b\u91cf\u9002\u914d\u5668\u548c\u591a\u5934\u67e5\u8be2-\u5019\u9009\u5339\u914d\u3002", "result": "FashionBLIP-2\u5728Fashion IQ\u548cenhFashionIQ\u4e0a\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u5728\u7ec6\u7c92\u5ea6\u6587\u672c\u68c0\u7d22\u4efb\u52a1\u4e2d\u3002", "conclusion": "FACap\u6570\u636e\u96c6\u548cFashionBLIP-2\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u5c1a\u9886\u57dfCIR\u7684\u6311\u6218\uff0c\u9002\u7528\u4e8e\u7535\u5546\u7b49\u9ad8\u9700\u6c42\u573a\u666f\u3002"}}
{"id": "2507.07221", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07221", "abs": "https://arxiv.org/abs/2507.07221", "authors": ["Nam Gyun Kim", "William E. Heap", "Yimeng Qin", "Elvy B. Yao", "Jee-Hwan Ryu", "Allison M. Okamura"], "title": "Self-Wearing Adaptive Garments via Soft Robotic Unfurling", "comment": null, "summary": "Robotic dressing assistance has the potential to improve the quality of life\nfor individuals with limited mobility. Existing solutions predominantly rely on\nrigid robotic manipulators, which have challenges in handling deformable\ngarments and ensuring safe physical interaction with the human body. Prior\nrobotic dressing methods require excessive operation times, complex control\nstrategies, and constrained user postures, limiting their practicality and\nadaptability. This paper proposes a novel soft robotic dressing system, the\nSelf-Wearing Adaptive Garment (SWAG), which uses an unfurling and growth\nmechanism to facilitate autonomous dressing. Unlike traditional approaches,the\nSWAG conforms to the human body through an unfurling based deployment method,\neliminating skin-garment friction and enabling a safer and more efficient\ndressing process. We present the working principles of the SWAG, introduce its\ndesign and fabrication, and demonstrate its performance in dressing assistance.\nThe proposed system demonstrates effective garment application across various\ngarment configurations, presenting a promising alternative to conventional\nrobotic dressing assistance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u8f6f\u673a\u5668\u4eba\u7a7f\u8863\u7cfb\u7edfSWAG\uff0c\u901a\u8fc7\u5c55\u5f00\u548c\u751f\u957f\u673a\u5236\u5b9e\u73b0\u81ea\u4e3b\u7a7f\u8863\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u521a\u6027\u673a\u5668\u4eba\u5904\u7406\u53d8\u5f62\u8863\u7269\u548c\u786e\u4fdd\u5b89\u5168\u4ea4\u4e92\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u7a7f\u8863\u65b9\u6848\u4f9d\u8d56\u521a\u6027\u673a\u68b0\u81c2\uff0c\u5b58\u5728\u64cd\u4f5c\u65f6\u95f4\u957f\u3001\u63a7\u5236\u590d\u6742\u3001\u7528\u6237\u59ff\u52bf\u53d7\u9650\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b9e\u7528\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5c55\u5f00\u7684\u90e8\u7f72\u65b9\u6cd5\uff0c\u4f7fSWAG\u80fd\u8d34\u5408\u4eba\u4f53\uff0c\u51cf\u5c11\u76ae\u80a4\u4e0e\u8863\u7269\u6469\u64e6\uff0c\u5b9e\u73b0\u66f4\u5b89\u5168\u9ad8\u6548\u7684\u7a7f\u8863\u8fc7\u7a0b\u3002", "result": "SWAG\u5728\u4e0d\u540c\u8863\u7269\u914d\u7f6e\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4f20\u7edf\u673a\u5668\u4eba\u7a7f\u8863\u8f85\u52a9\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "SWAG\u7cfb\u7edf\u901a\u8fc7\u8f6f\u673a\u5668\u4eba\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7a7f\u8863\u8f85\u52a9\u7684\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.07137", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07137", "abs": "https://arxiv.org/abs/2507.07137", "authors": ["Eric Yeats", "Darryl Hannan", "Henry Kvinge", "Timothy Doster", "Scott Mahan"], "title": "Automating Evaluation of Diffusion Model Unlearning with (Vision-) Language Model World Knowledge", "comment": null, "summary": "Machine unlearning (MU) is a promising cost-effective method to cleanse\nundesired information (generated concepts, biases, or patterns) from\nfoundational diffusion models. While MU is orders of magnitude less costly than\nretraining a diffusion model without the undesired information, it can be\nchallenging and labor-intensive to prove that the information has been fully\nremoved from the model. Moreover, MU can damage diffusion model performance on\nsurrounding concepts that one would like to retain, making it unclear if the\ndiffusion model is still fit for deployment. We introduce autoeval-dmun, an\nautomated tool which leverages (vision-) language models to thoroughly assess\nunlearning in diffusion models. Given a target concept, autoeval-dmun extracts\nstructured, relevant world knowledge from the language model to identify nearby\nconcepts which are likely damaged by unlearning and to circumvent unlearning\nwith adversarial prompts. We use our automated tool to evaluate popular\ndiffusion model unlearning methods, revealing that language models (1) impose\nsemantic orderings of nearby concepts which correlate well with unlearning\ndamage and (2) effectively circumvent unlearning with synthetic adversarial\nprompts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u5de5\u5177autoeval-dmun\uff0c\u7528\u4e8e\u8bc4\u4f30\u6269\u6563\u6a21\u578b\u4e2d\u7684\u4fe1\u606f\u9057\u5fd8\u6548\u679c\uff0c\u5e76\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u6392\u5e8f\u548c\u5bf9\u6297\u63d0\u793a\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u9057\u5fd8\uff08MU\uff09\u5728\u6269\u6563\u6a21\u578b\u4e2d\u96be\u4ee5\u9a8c\u8bc1\u4fe1\u606f\u662f\u5426\u5b8c\u5168\u6e05\u9664\u53ca\u53ef\u80fd\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\uff08\u89c6\u89c9\uff09\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u7ed3\u6784\u5316\u77e5\u8bc6\uff0c\u8bc6\u522b\u53ef\u80fd\u53d7\u635f\u7684\u90bb\u8fd1\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u5bf9\u6297\u63d0\u793a\u7ed5\u8fc7\u9057\u5fd8\u3002", "result": "\u8bed\u8a00\u6a21\u578b\u80fd\u6709\u6548\u6392\u5e8f\u90bb\u8fd1\u6982\u5ff5\uff08\u4e0e\u9057\u5fd8\u635f\u5bb3\u76f8\u5173\uff09\u5e76\u751f\u6210\u5bf9\u6297\u63d0\u793a\u7ed5\u8fc7\u9057\u5fd8\u3002", "conclusion": "autoeval-dmun\u4e3a\u8bc4\u4f30\u6269\u6563\u6a21\u578b\u9057\u5fd8\u6548\u679c\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.07225", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07225", "abs": "https://arxiv.org/abs/2507.07225", "authors": ["Yimeng Qin", "Jared Grinberg", "William Heap", "Allison M. Okamura"], "title": "3D Steering and Localization in Pipes and Burrows using an Externally Steered Soft Growing Robot", "comment": null, "summary": "Navigation and inspection in confined environments, such as tunnels and\npipes, pose significant challenges for existing robots due to limitations in\nmaneuverability and adaptability to varying geometries. Vine robots, which are\nsoft growing continuum robots that extend their length through soft material\neversion at their tip, offer unique advantages due to their ability to navigate\ntight spaces, adapt to complex paths, and minimize friction. However, existing\nvine robot designs struggle with navigation in manmade and natural passageways,\nwith branches and sharp 3D turns. In this letter, we introduce a steerable vine\nrobot specifically designed for pipe and burrow environments. The robot\nfeatures a simple tubular body and an external tip mount that steers the vine\nrobot in three degrees of freedom by changing the growth direction and, when\nnecessary, bracing against the wall of the pipe or burrow. Our external tip\nsteering approach enables: (1) active branch selection in 3D space with a\nmaximum steerable angle of 51.7{\\deg}, (2) navigation of pipe networks with\nradii as small as 2.5 cm, (3) a compliant tip enabling navigation of sharp\nturns, and (4) real-time 3D localization in GPS-denied environments using\ntip-mounted sensors and continuum body odometry. We describe the forward\nkinematics, characterize steerability, and demonstrate the system in a 3D pipe\nsystem as well as a natural animal burrow.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u53ef\u8f6c\u5411\u85e4\u8513\u673a\u5668\u4eba\uff0c\u7528\u4e8e\u5728\u72ed\u7a84\u7ba1\u9053\u548c\u6d1e\u7a74\u4e2d\u5bfc\u822a\uff0c\u5177\u6709\u4e3b\u52a8\u5206\u652f\u9009\u62e9\u3001\u9002\u5e94\u5c0f\u534a\u5f84\u7ba1\u9053\u3001\u901a\u8fc7\u5c16\u9510\u8f6c\u5f2f\u548c\u5b9e\u65f63D\u5b9a\u4f4d\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u85e4\u8513\u673a\u5668\u4eba\u5728\u4eba\u9020\u548c\u81ea\u7136\u901a\u9053\u4e2d\u5bfc\u822a\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u5206\u652f\u548c\u5c16\u95103D\u8f6c\u5f2f\u5904\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u5916\u90e8\u5c16\u7aef\u5b89\u88c5\u7684\u8f6c\u5411\u673a\u5236\uff0c\u901a\u8fc7\u6539\u53d8\u751f\u957f\u65b9\u5411\u548c\u5fc5\u8981\u65f6\u652f\u6491\u7ba1\u9053\u58c1\u5b9e\u73b03D\u8f6c\u5411\u3002", "result": "\u5b9e\u73b0\u4e86\u6700\u592751.7\u5ea6\u7684\u8f6c\u5411\u89d2\u5ea6\u3001\u9002\u5e942.5\u5398\u7c73\u5c0f\u534a\u5f84\u7ba1\u9053\u3001\u901a\u8fc7\u5c16\u9510\u8f6c\u5f2f\uff0c\u5e76\u5229\u7528\u5c16\u7aef\u4f20\u611f\u5668\u5b9e\u73b0\u5b9e\u65f63D\u5b9a\u4f4d\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86\u85e4\u8513\u673a\u5668\u4eba\u5728\u590d\u6742\u72ed\u7a84\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u80fd\u529b\u3002"}}
{"id": "2507.07138", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07138", "abs": "https://arxiv.org/abs/2507.07138", "authors": ["Francesco Ferrini", "Veronica Lachi", "Antonio Longa", "Bruno Lepri", "Andrea Passerini"], "title": "GNNs Meet Sequence Models Along the Shortest-Path: an Expressive Method for Link Prediction", "comment": null, "summary": "Graph Neural Networks (GNNs) often struggle to capture the link-specific\nstructural patterns crucial for accurate link prediction, as their node-centric\nmessage-passing schemes overlook the subgraph structures connecting a pair of\nnodes. Existing methods to inject such structural context either incur high\ncomputational cost or rely on simplistic heuristics (e.g., common neighbor\ncounts) that fail to model multi-hop dependencies. We introduce SP4LP (Shortest\nPath for Link Prediction), a novel framework that combines GNN-based node\nencodings with sequence modeling over shortest paths. Specifically, SP4LP first\napplies a GNN to compute representations for all nodes, then extracts the\nshortest path between each candidate node pair and processes the resulting\nsequence of node embeddings using a sequence model. This design enables SP4LP\nto capture expressive multi-hop relational patterns with computational\nefficiency. Empirically, SP4LP achieves state-of-the-art performance across\nlink prediction benchmarks. Theoretically, we prove that SP4LP is strictly more\nexpressive than standard message-passing GNNs and several state-of-the-art\nstructural features methods, establishing it as a general and principled\napproach for link prediction in graphs.", "AI": {"tldr": "SP4LP\u662f\u4e00\u4e2a\u7ed3\u5408GNN\u548c\u6700\u77ed\u8def\u5f84\u5e8f\u5217\u5efa\u6a21\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u6355\u6349\u591a\u8df3\u4f9d\u8d56\u5173\u7cfb\uff0c\u63d0\u5347\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GNN\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u94fe\u63a5\u7279\u5b9a\u7684\u7ed3\u6784\u6a21\u5f0f\uff0c\u4e14\u73b0\u6709\u6ce8\u5165\u7ed3\u6784\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\u8981\u4e48\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u8981\u4e48\u4f9d\u8d56\u7b80\u5355\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "SP4LP\u5148\u901a\u8fc7GNN\u8ba1\u7b97\u8282\u70b9\u8868\u793a\uff0c\u518d\u63d0\u53d6\u5019\u9009\u8282\u70b9\u5bf9\u7684\u6700\u77ed\u8def\u5f84\u5e76\u7528\u5e8f\u5217\u6a21\u578b\u5904\u7406\u8282\u70b9\u5d4c\u5165\u5e8f\u5217\u3002", "result": "SP4LP\u5728\u94fe\u63a5\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u8868\u8fbe\u80fd\u529b\u4f18\u4e8e\u6807\u51c6GNN\u548c\u5176\u4ed6\u7ed3\u6784\u7279\u5f81\u65b9\u6cd5\u3002", "conclusion": "SP4LP\u662f\u4e00\u79cd\u901a\u7528\u4e14\u539f\u5219\u6027\u7684\u94fe\u63a5\u9884\u6d4b\u65b9\u6cd5\uff0c\u80fd\u9ad8\u6548\u6355\u6349\u591a\u8df3\u5173\u7cfb\u6a21\u5f0f\u3002"}}
{"id": "2507.07299", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.07299", "abs": "https://arxiv.org/abs/2507.07299", "authors": ["Sonia Raychaudhuri", "Enrico Cancelli", "Tommaso Campari", "Lamberto Ballan", "Manolis Savva", "Angel X. Chang"], "title": "LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation", "comment": null, "summary": "Recent progress in large vision-language models has driven improvements in\nlanguage-based semantic navigation, where an embodied agent must reach a target\nobject described in natural language. Despite these advances, we still lack a\nclear, language-focused benchmark for testing how well such agents ground the\nwords in their instructions. We address this gap with LangNav, an open-set\ndataset specifically created to test an agent's ability to locate objects\ndescribed at different levels of detail, from broad category names to fine\nattributes and object-object relations. Every description in LangNav was\nmanually checked, yielding a lower error rate than existing lifelong- and\nsemantic-navigation datasets. On top of LangNav we build LangNavBench, a\nbenchmark that measures how well current semantic-navigation methods understand\nand act on these descriptions while moving toward their targets. LangNavBench\nallows us to systematically compare models on their handling of attributes,\nspatial and relational cues, and category hierarchies, offering the first\nthorough, language-centric evaluation of embodied navigation systems. We also\npresent Multi-Layered Feature Map (MLFM), a method that builds a queryable\nmulti-layered semantic map, particularly effective when dealing with small\nobjects or instructions involving spatial relations. MLFM outperforms\nstate-of-the-art mapping-based navigation baselines on the LangNav dataset.", "AI": {"tldr": "LangNav\u662f\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u8bed\u8a00\u7406\u89e3\u7684\u8bed\u4e49\u5bfc\u822a\u6570\u636e\u96c6\uff0c\u65e8\u5728\u6d4b\u8bd5\u667a\u80fd\u4f53\u5bf9\u4e0d\u540c\u5c42\u6b21\u8bed\u8a00\u63cf\u8ff0\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86LangNavBench\u57fa\u51c6\u548cMLFM\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u5bfc\u822a\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u8bed\u8a00\u7406\u89e3\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u667a\u80fd\u4f53\u5bf9\u8bed\u8a00\u6307\u4ee4\u7684\u51c6\u786e\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86LangNav\u6570\u636e\u96c6\u548cLangNavBench\u57fa\u51c6\uff0c\u5e76\u5f00\u53d1\u4e86Multi-Layered Feature Map (MLFM)\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u53ef\u67e5\u8be2\u7684\u591a\u5c42\u8bed\u4e49\u5730\u56fe\u3002", "result": "MLFM\u65b9\u6cd5\u5728LangNav\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u5730\u56fe\u7684\u5bfc\u822a\u57fa\u7ebf\u3002", "conclusion": "LangNav\u548cLangNavBench\u4e3a\u8bed\u8a00\u5bfc\u822a\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\uff0cMLFM\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u8bed\u8a00\u6307\u4ee4\u65f6\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.07140", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07140", "abs": "https://arxiv.org/abs/2507.07140", "authors": ["Samin Yeasar Arnob", "Zhan Su", "Minseon Kim", "Oleksiy Ostapenko", "Riyasat Ohib", "Esra'a Saleh", "Doina Precup", "Lucas Caccia", "Alessandro Sordoni"], "title": "Exploring Sparse Adapters for Scalable Merging of Parameter Efficient Experts", "comment": null, "summary": "Merging parameter-efficient task experts has recently gained growing\nattention as a way to build modular architectures that can be rapidly adapted\non the fly for specific downstream tasks, without requiring additional\nfine-tuning. Typically, LoRA serves as the foundational building block of such\nparameter-efficient modular architectures, leveraging low-rank weight\nstructures to reduce the number of trainable parameters. In this paper, we\nstudy the properties of sparse adapters, which train only a subset of weights\nin the base neural network, as potential building blocks of modular\narchitectures. First, we propose a simple method for training highly effective\nsparse adapters, which is conceptually simpler than existing methods in the\nliterature and surprisingly outperforms both LoRA and full fine-tuning in our\nsetting. Next, we investigate the merging properties of these sparse adapters\nby merging adapters for up to 20 natural language processing tasks, thus\nscaling beyond what is usually studied in the literature. Our findings\ndemonstrate that sparse adapters yield superior in-distribution performance\npost-merging compared to LoRA or full model merging. Achieving strong held-out\nperformance remains a challenge for all methods considered.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u7a00\u758f\u9002\u914d\u5668\u4f5c\u4e3a\u6a21\u5757\u5316\u67b6\u6784\u6784\u5efa\u5757\u7684\u6f5c\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4efb\u52a1\u5408\u5e76\u4e2d\u8868\u73b0\u4f18\u4e8eLoRA\u548c\u5168\u5fae\u8c03\u3002", "motivation": "\u63a2\u7d22\u7a00\u758f\u9002\u914d\u5668\u4f5c\u4e3a\u6a21\u5757\u5316\u67b6\u6784\u7684\u6784\u5efa\u5757\uff0c\u4ee5\u5b9e\u73b0\u5728\u4e0d\u989d\u5916\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u5feb\u901f\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u7a00\u758f\u9002\u914d\u5668\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5728\u591a\u4efb\u52a1\u5408\u5e76\u4e2d\u7684\u6027\u80fd\u3002", "result": "\u7a00\u758f\u9002\u914d\u5668\u5728\u5408\u5e76\u540e\u8868\u73b0\u51fa\u4f18\u4e8eLoRA\u548c\u5168\u6a21\u578b\u5408\u5e76\u7684\u5206\u5e03\u5185\u6027\u80fd\uff0c\u4f46\u6240\u6709\u65b9\u6cd5\u5728\u5206\u5e03\u5916\u6027\u80fd\u4e0a\u4ecd\u6709\u6311\u6218\u3002", "conclusion": "\u7a00\u758f\u9002\u914d\u5668\u662f\u6a21\u5757\u5316\u67b6\u6784\u7684\u6709\u6548\u6784\u5efa\u5757\uff0c\u4f46\u5728\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2507.07141", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07141", "abs": "https://arxiv.org/abs/2507.07141", "authors": ["Dongxiao He", "Yongqi Huang", "Jitao Zhao", "Xiaobao Wang", "Zhen Wang"], "title": "Str-GCL: Structural Commonsense Driven Graph Contrastive Learning", "comment": "Accepted by WWW 2025", "summary": "Graph Contrastive Learning (GCL) is a widely adopted approach in\nself-supervised graph representation learning, applying contrastive objectives\nto produce effective representations. However, current GCL methods primarily\nfocus on capturing implicit semantic relationships, often overlooking the\nstructural commonsense embedded within the graph's structure and attributes,\nwhich contains underlying knowledge crucial for effective representation\nlearning. Due to the lack of explicit information and clear guidance in general\ngraph, identifying and integrating such structural commonsense in GCL poses a\nsignificant challenge. To address this gap, we propose a novel framework called\nStructural Commonsense Unveiling in Graph Contrastive Learning (Str-GCL).\nStr-GCL leverages first-order logic rules to represent structural commonsense\nand explicitly integrates them into the GCL framework. It introduces\ntopological and attribute-based rules without altering the original graph and\nemploys a representation alignment mechanism to guide the encoder in\neffectively capturing this commonsense. To the best of our knowledge, this is\nthe first attempt to directly incorporate structural commonsense into GCL.\nExtensive experiments demonstrate that Str-GCL outperforms existing GCL\nmethods, providing a new perspective on leveraging structural commonsense in\ngraph representation learning.", "AI": {"tldr": "Str-GCL\u662f\u4e00\u79cd\u65b0\u9896\u7684\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e00\u9636\u903b\u8f91\u89c4\u5219\u663e\u5f0f\u6574\u5408\u7ed3\u6784\u5e38\u8bc6\uff0c\u63d0\u5347\u8868\u793a\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u56fe\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9690\u5f0f\u8bed\u4e49\u5173\u7cfb\uff0c\u5ffd\u7565\u4e86\u56fe\u4e2d\u7ed3\u6784\u548c\u5c5e\u6027\u4e2d\u7684\u7ed3\u6784\u5e38\u8bc6\uff0c\u8fd9\u4e9b\u5e38\u8bc6\u5bf9\u8868\u793a\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u3002", "method": "Str-GCL\u5229\u7528\u4e00\u9636\u903b\u8f91\u89c4\u5219\u8868\u793a\u7ed3\u6784\u5e38\u8bc6\uff0c\u5e76\u901a\u8fc7\u8868\u793a\u5bf9\u9f50\u673a\u5236\u5c06\u5176\u6574\u5408\u5230\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u4e0d\u6539\u53d8\u539f\u56fe\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cStr-GCL\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u56fe\u8868\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "conclusion": "Str-GCL\u9996\u6b21\u5c06\u7ed3\u6784\u5e38\u8bc6\u76f4\u63a5\u5f15\u5165\u56fe\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.07327", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.07327", "abs": "https://arxiv.org/abs/2507.07327", "authors": ["Brian B. Vuong", "Josie Davidson", "Sangheui Cheon", "Kyujin Cho", "Allison M. Okamura"], "title": "Effects of Wrist-Worn Haptic Feedback on Force Accuracy and Task Speed during a Teleoperated Robotic Surgery Task", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Previous work has shown that the addition of haptic feedback to the hands can\nimprove awareness of tool-tissue interactions and enhance performance of\nteleoperated tasks in robot-assisted minimally invasive surgery. However,\nhand-based haptic feedback occludes direct interaction with the manipulanda of\nsurgeon console in teleoperated surgical robots. We propose relocating haptic\nfeedback to the wrist using a wearable haptic device so that haptic feedback\nmechanisms do not need to be integrated into the manipulanda. However, it is\nunknown if such feedback will be effective, given that it is not co-located\nwith the finger movements used for manipulation. To test if relocated haptic\nfeedback improves force application during teleoperated tasks using da Vinci\nResearch Kit (dVRK) surgical robot, participants learned to palpate a phantom\ntissue to desired forces. A soft pneumatic wrist-worn haptic device with an\nanchoring system renders tool-tissue interaction forces to the wrist of the\nuser. Participants performed the palpation task with and without wrist-worn\nhaptic feedback and were evaluated for the accuracy of applied forces.\nParticipants demonstrated statistically significant lower force error when\nwrist-worn haptic feedback was provided. Participants also performed the\npalpation task with longer movement times when provided wrist-worn haptic\nfeedback, indicating that the haptic feedback may have caused participants to\noperate at a different point in the speed-accuracy tradeoff curve.", "AI": {"tldr": "\u5c06\u89e6\u89c9\u53cd\u9988\u4ece\u624b\u90e8\u8f6c\u79fb\u5230\u624b\u8155\u7684\u7a7f\u6234\u8bbe\u5907\uff0c\u53ef\u907f\u514d\u5e72\u6270\u624b\u672f\u673a\u5668\u4eba\u64cd\u4f5c\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u529b\u65bd\u52a0\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u624b\u90e8\u89e6\u89c9\u53cd\u9988\u5728\u624b\u672f\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u906e\u6321\u76f4\u63a5\u4ea4\u4e92\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8f6f\u6c14\u52a8\u624b\u8155\u7a7f\u6234\u89e6\u89c9\u8bbe\u5907\uff0c\u6d4b\u8bd5\u5176\u5728\u8fbe\u82ac\u5947\u624b\u672f\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5bf9\u529b\u65bd\u52a0\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "result": "\u63d0\u4f9b\u624b\u8155\u89e6\u89c9\u53cd\u9988\u65f6\uff0c\u53c2\u4e0e\u8005\u65bd\u52a0\u7684\u529b\u8bef\u5dee\u663e\u8457\u964d\u4f4e\uff0c\u4f46\u64cd\u4f5c\u65f6\u95f4\u5ef6\u957f\u3002", "conclusion": "\u624b\u8155\u89e6\u89c9\u53cd\u9988\u6709\u6548\uff0c\u4f46\u53ef\u80fd\u5f71\u54cd\u64cd\u4f5c\u901f\u5ea6\u4e0e\u51c6\u786e\u6027\u7684\u6743\u8861\u3002"}}
{"id": "2507.07143", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07143", "abs": "https://arxiv.org/abs/2507.07143", "authors": ["Karthik Pappu", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Understanding Malware Propagation Dynamics through Scientific Machine Learning", "comment": "17 pages, 6 figures, 4 tables", "summary": "Accurately modeling malware propagation is essential for designing effective\ncybersecurity defenses, particularly against adaptive threats that evolve in\nreal time. While traditional epidemiological models and recent neural\napproaches offer useful foundations, they often fail to fully capture the\nnonlinear feedback mechanisms present in real-world networks. In this work, we\napply scientific machine learning to malware modeling by evaluating three\napproaches: classical Ordinary Differential Equations (ODEs), Universal\nDifferential Equations (UDEs), and Neural ODEs. Using data from the Code Red\nworm outbreak, we show that the UDE approach substantially reduces prediction\nerror compared to both traditional and neural baselines by 44%, while\npreserving interpretability. We introduce a symbolic recovery method that\ntransforms the learned neural feedback into explicit mathematical expressions,\nrevealing suppression mechanisms such as network saturation, security response,\nand malware variant evolution. Our results demonstrate that hybrid\nphysics-informed models can outperform both purely analytical and purely neural\napproaches, offering improved predictive accuracy and deeper insight into the\ndynamics of malware spread. These findings support the development of early\nwarning systems, efficient outbreak response strategies, and targeted cyber\ndefense interventions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u5efa\u6a21\u6076\u610f\u8f6f\u4ef6\u4f20\u64ad\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u548c\u7eaf\u795e\u7ecf\u65b9\u6cd5\u3002", "motivation": "\u51c6\u786e\u5efa\u6a21\u6076\u610f\u8f6f\u4ef6\u4f20\u64ad\u5bf9\u8bbe\u8ba1\u6709\u6548\u7684\u7f51\u7edc\u5b89\u5168\u9632\u5fa1\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u5b9e\u65f6\u6f14\u5316\u7684\u81ea\u9002\u5e94\u5a01\u80c1\u3002\u4f20\u7edf\u65b9\u6cd5\u548c\u7eaf\u795e\u7ecf\u65b9\u6cd5\u672a\u80fd\u5b8c\u5168\u6355\u6349\u73b0\u5b9e\u7f51\u7edc\u4e2d\u7684\u975e\u7ebf\u6027\u53cd\u9988\u673a\u5236\u3002", "method": "\u8bba\u6587\u8bc4\u4f30\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a\u7ecf\u5178\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODEs\uff09\u3001\u901a\u7528\u5fae\u5206\u65b9\u7a0b\uff08UDEs\uff09\u548c\u795e\u7ecfODE\u3002\u901a\u8fc7Code Red\u8815\u866b\u7206\u53d1\u6570\u636e\uff0c\u9a8c\u8bc1\u4e86UDE\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "result": "UDE\u65b9\u6cd5\u5c06\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e\u4e8644%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u89e3\u91ca\u6027\u3002\u901a\u8fc7\u7b26\u53f7\u6062\u590d\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u7f51\u7edc\u9971\u548c\u3001\u5b89\u5168\u54cd\u5e94\u548c\u6076\u610f\u8f6f\u4ef6\u53d8\u79cd\u6f14\u5316\u7b49\u6291\u5236\u673a\u5236\u3002", "conclusion": "\u6df7\u5408\u7269\u7406\u4fe1\u606f\u6a21\u578b\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u52a8\u6001\u6d1e\u5bdf\u529b\u4e0a\u4f18\u4e8e\u7eaf\u5206\u6790\u548c\u7eaf\u795e\u7ecf\u65b9\u6cd5\uff0c\u652f\u6301\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u548c\u9488\u5bf9\u6027\u9632\u5fa1\u7b56\u7565\u7684\u5f00\u53d1\u3002"}}
{"id": "2507.07356", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07356", "abs": "https://arxiv.org/abs/2507.07356", "authors": ["Kangning Yin", "Weishuai Zeng", "Ke Fan", "Zirui Wang", "Qiang Zhang", "Zheng Tian", "Jingbo Wang", "Jiangmiao Pang", "Weinan Zhang"], "title": "UniTracker: Learning Universal Whole-Body Motion Tracker for Humanoid Robots", "comment": "10 pages, 5 figures", "summary": "Humanoid robots must achieve diverse, robust, and generalizable whole-body\ncontrol to operate effectively in complex, human-centric environments. However,\nexisting methods, particularly those based on teacher-student frameworks often\nsuffer from a loss of motion diversity during policy distillation and exhibit\nlimited generalization to unseen behaviors. In this work, we present\nUniTracker, a simplified yet powerful framework that integrates a Conditional\nVariational Autoencoder (CVAE) into the student policy to explicitly model the\nlatent diversity of human motion. By leveraging a learned CVAE prior, our\nmethod enables the student to retain expressive motion characteristics while\nimproving robustness and adaptability under partial observations. The result is\na single policy capable of tracking a wide spectrum of whole-body motions with\nhigh fidelity and stability. Comprehensive experiments in both simulation and\nreal-world deployments demonstrate that UniTracker significantly outperforms\nMLP-based DAgger baselines in motion quality, generalization to unseen\nreferences, and deployment robustness, offering a practical and scalable\nsolution for expressive humanoid control.", "AI": {"tldr": "UniTracker\u6846\u67b6\u901a\u8fc7\u96c6\u6210CVAE\u4fdd\u7559\u52a8\u4f5c\u591a\u6837\u6027\uff0c\u63d0\u5347\u4eba\u5f62\u673a\u5668\u4eba\u63a7\u5236\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u5e08\u751f\u6846\u67b6\u7684\u65b9\u6cd5\u5728\u52a8\u4f5c\u591a\u6837\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u5229\u7528CVAE\u663e\u5f0f\u5efa\u6a21\u4eba\u7c7b\u52a8\u4f5c\u7684\u6f5c\u5728\u591a\u6837\u6027\uff0c\u7ed3\u5408\u5b66\u751f\u7b56\u7565\u3002", "result": "\u5728\u4eff\u771f\u548c\u5b9e\u9645\u90e8\u7f72\u4e2d\u663e\u8457\u4f18\u4e8eMLP-based DAgger\u57fa\u7ebf\u3002", "conclusion": "UniTracker\u4e3a\u8868\u8fbe\u6027\u4eba\u5f62\u63a7\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07145", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07145", "abs": "https://arxiv.org/abs/2507.07145", "authors": ["Zhaojing Zhou", "Xunchao Li", "Minghao Li", "Handi Zhang", "Haoshuang Wang", "Wenbin Chang", "Yiqun Liu", "Qingqing Dang", "Dianhai Yu", "Yanjun Ma", "Haifeng Wang"], "title": "CCQ: Convolutional Code for Extreme Low-bit Quantization in LLMs", "comment": "11 pages, 3 figures", "summary": "The rapid scaling of Large Language Models (LLMs) elevates inference costs\nand compounds substantial deployment barriers. While quantization to 8 or 4\nbits mitigates this, sub-3-bit methods face severe accuracy, scalability, and\nefficiency degradation. We propose Convolutional Code Quantization (CCQ), an\ninference-optimized quantization approach compressing LLMs to 2.0-2.75 bits\nwith minimal accuracy loss. Departing from error-prone scalar quantization or\nslow vector quantization, CCQ integrates a hardware-aware bit-shift encoding\nand decoding solution with Convolutional Code, Hybrid Encoding, and Code\nCluster, jointly overcoming accuracy-speed bottlenecks. We construct a\nlookup-free encoding space, enabling a linear mapping between the codebook and\nweight vectors, thereby optimizing inference performance. Meanwhile, by drawing\non the concept of data mapping from vector quantization, we minimize the\nperformance degradation of the model under extremely low-bit conditions.\nExperiments demonstrate that CCQ achieves outstanding performance on LLMs\nacross various benchmarks. We compress DeepSeek-V3 (671B total parameters) to\n184GB and ERNIE-4.5-300B-A47B to 89GB, enabling single-GPU deployment of ERNIE\n4.5 and eliminating inter-card communication. The 2-bit ERNIE-4.5-300B-A47B\nmodel and inference engine have been open-sourced.", "AI": {"tldr": "CCQ\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u76842.0-2.75\u4f4d\u91cf\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u4e14\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3LLM\u63a8\u7406\u6210\u672c\u9ad8\u548c\u90e8\u7f72\u96be\u5ea6\u5927\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u4f4e\u6bd4\u7279\u91cf\u5316\uff08\u59823\u4f4d\u4ee5\u4e0b\uff09\u5e26\u6765\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u4e0b\u964d\u3002", "method": "\u7ed3\u5408\u786c\u4ef6\u611f\u77e5\u7684\u4f4d\u79fb\u7f16\u7801\u4e0e\u89e3\u7801\u3001\u5377\u79ef\u7801\u3001\u6df7\u5408\u7f16\u7801\u548c\u7801\u7c07\u6280\u672f\uff0c\u6784\u5efa\u65e0\u67e5\u627e\u8868\u7684\u7f16\u7801\u7a7a\u95f4\uff0c\u4f18\u5316\u63a8\u7406\u6027\u80fd\u3002", "result": "\u6210\u529f\u5c06DeepSeek-V3\u548cERNIE-4.5-300B-A47B\u538b\u7f29\u81f3184GB\u548c89GB\uff0c\u5b9e\u73b0\u5355GPU\u90e8\u7f72\u3002", "conclusion": "CCQ\u5728\u6781\u4f4e\u6bd4\u7279\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u5347LLM\u7684\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.07146", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07146", "abs": "https://arxiv.org/abs/2507.07146", "authors": ["Zixuan Huang", "Kecheng Huang", "Lihao Yin", "Bowei He", "Huiling Zhen", "Mingxuan Yuan", "Zili Shao"], "title": "An attention-aware GNN-based input defender against multi-turn jailbreak on LLMs", "comment": null, "summary": "Large Language Models (LLMs) have gained widespread popularity and are\nincreasingly integrated into various applications. However, their capabilities\ncan be exploited for both benign and harmful purposes. Despite rigorous\ntraining and fine-tuning for safety, LLMs remain vulnerable to jailbreak\nattacks. Recently, multi-turn attacks have emerged, exacerbating the issue.\nUnlike single-turn attacks, multi-turn attacks gradually escalate the dialogue,\nmaking them more difficult to detect and mitigate, even after they are\nidentified.\n  In this study, we propose G-Guard, an innovative attention-aware GNN-based\ninput classifier designed to defend against multi-turn jailbreak attacks on\nLLMs. G-Guard constructs an entity graph for multi-turn queries, explicitly\ncapturing relationships between harmful keywords and queries even when those\nkeywords appear only in previous queries. Additionally, we introduce an\nattention-aware augmentation mechanism that retrieves the most similar\nsingle-turn query based on the multi-turn conversation. This retrieved query is\ntreated as a labeled node in the graph, enhancing the ability of GNN to\nclassify whether the current query is harmful. Evaluation results demonstrate\nthat G-Guard outperforms all baselines across all datasets and evaluation\nmetrics.", "AI": {"tldr": "G-Guard\u662f\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u611f\u77e5\u7684GNN\u8f93\u5165\u5206\u7c7b\u5668\uff0c\u7528\u4e8e\u9632\u5fa1LLMs\u7684\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6613\u53d7\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\uff0c\u4f20\u7edf\u5355\u8f6e\u653b\u51fb\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u3002", "method": "\u63d0\u51faG-Guard\uff0c\u901a\u8fc7\u6784\u5efa\u5b9e\u4f53\u56fe\u6355\u6349\u591a\u8f6e\u67e5\u8be2\u4e2d\u7684\u6709\u5bb3\u5173\u952e\u8bcd\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u6ce8\u610f\u529b\u611f\u77e5\u589e\u5f3a\u673a\u5236\u3002", "result": "G-Guard\u5728\u6240\u6709\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "G-Guard\u6709\u6548\u63d0\u5347\u4e86LLMs\u5bf9\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002"}}
{"id": "2507.07376", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07376", "abs": "https://arxiv.org/abs/2507.07376", "authors": ["Hengrui Liu", "Yi Feng", "Qilong Zhang"], "title": "PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments", "comment": null, "summary": "Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster\nresponse, exploration, and reconnaissance. However, dynamic and unknown\nenvironments pose significant challenges due to target unpredictability and\nenvironmental uncertainty. To tackle these issues, we propose PILOC, a\nframework that operates without global prior knowledge, leveraging local\nperception and communication. It introduces a pheromone inverse guidance\nmechanism to enable efficient coordination and dynamic target localization.\nPILOC promotes decentralized cooperation through local communication,\nsignificantly reducing reliance on global channels. Unlike conventional\nheuristics, the pheromone mechanism is embedded into the observation space of\nDeep Reinforcement Learning (DRL), supporting indirect agent coordination based\non environmental cues. We further integrate this strategy into a DRL-based\nmulti-agent architecture and conduct extensive experiments. Results show that\ncombining local communication with pheromone-based guidance significantly\nboosts search efficiency, adaptability, and system robustness. Compared to\nexisting methods, PILOC performs better under dynamic and\ncommunication-constrained scenarios, offering promising directions for future\nMASAR applications.", "AI": {"tldr": "PILOC\u6846\u67b6\u901a\u8fc7\u5c40\u90e8\u611f\u77e5\u548c\u901a\u4fe1\uff0c\u7ed3\u5408\u4fe1\u606f\u7d20\u9006\u5411\u5f15\u5bfc\u673a\u5236\uff0c\u63d0\u5347\u591a\u667a\u80fd\u4f53\u641c\u7d22\u4e0e\u6551\u63f4\u4efb\u52a1\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u52a8\u6001\u548c\u672a\u77e5\u73af\u5883\u4e2d\u76ee\u6807\u4e0d\u53ef\u9884\u6d4b\u548c\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u5bf9\u591a\u667a\u80fd\u4f53\u641c\u7d22\u4e0e\u6551\u63f4\u4efb\u52a1\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51faPILOC\u6846\u67b6\uff0c\u5229\u7528\u5c40\u90e8\u611f\u77e5\u548c\u901a\u4fe1\uff0c\u5f15\u5165\u4fe1\u606f\u7d20\u9006\u5411\u5f15\u5bfc\u673a\u5236\uff0c\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u95f4\u63a5\u534f\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPILOC\u5728\u52a8\u6001\u548c\u901a\u4fe1\u53d7\u9650\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u641c\u7d22\u6548\u7387\u548c\u7cfb\u7edf\u9c81\u68d2\u6027\u3002", "conclusion": "PILOC\u4e3a\u672a\u6765\u591a\u667a\u80fd\u4f53\u641c\u7d22\u4e0e\u6551\u63f4\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.07147", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.07147", "abs": "https://arxiv.org/abs/2507.07147", "authors": ["Sua Lee", "Kyubum Shin", "Jung Ho Park"], "title": "Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation", "comment": "Published as a conference paper at ICLR 2025", "summary": "Recent advances in pre-trained Vision Language Models (VLM) have shown\npromising potential for effectively adapting to downstream tasks through prompt\nlearning, without the need for additional annotated paired datasets. To\nsupplement the text information in VLM trained on correlations with vision\ndata, new approaches leveraging Large Language Models (LLM) in prompts have\nbeen proposed, enhancing robustness to unseen and diverse data. Existing\nmethods typically extract text-based responses (i.e., descriptions) from LLM to\nincorporate into prompts; however, this approach suffers from high variability\nand low reliability. In this work, we propose Description-free Multi-prompt\nLearning(DeMul), a novel method that eliminates the process of extracting\ndescriptions and instead directly distills knowledge from LLM into prompts. By\nadopting a description-free approach, prompts can encapsulate richer semantics\nwhile still being represented as continuous vectors for optimization, thereby\neliminating the need for discrete pre-defined templates. Additionally, in a\nmulti-prompt setting, we empirically demonstrate the potential of prompt\nweighting in reflecting the importance of different prompts during training.\nExperimental results show that our approach achieves superior performance\nacross 11 recognition datasets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDeMul\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u84b8\u998fLLM\u77e5\u8bc6\u5230\u63d0\u793a\u4e2d\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u63d0\u53d6\u63cf\u8ff0\u7684\u4e0d\u53ef\u9760\u6027\uff0c\u63d0\u5347\u4e86\u591a\u63d0\u793a\u5b66\u4e60\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u63d0\u53d6LLM\u7684\u6587\u672c\u63cf\u8ff0\u6765\u589e\u5f3a\u63d0\u793a\uff0c\u4f46\u5b58\u5728\u9ad8\u53d8\u5f02\u6027\u548c\u4f4e\u53ef\u9760\u6027\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDescription-free Multi-prompt Learning (DeMul)\uff0c\u76f4\u63a5\u84b8\u998fLLM\u77e5\u8bc6\u5230\u63d0\u793a\u4e2d\uff0c\u907f\u514d\u4e86\u63cf\u8ff0\u63d0\u53d6\u8fc7\u7a0b\uff0c\u5e76\u91c7\u7528\u591a\u63d0\u793a\u52a0\u6743\u673a\u5236\u3002", "result": "\u572811\u4e2a\u8bc6\u522b\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "DeMul\u65b9\u6cd5\u901a\u8fc7\u63cf\u8ff0\u65e0\u5173\u7684\u591a\u63d0\u793a\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2507.07444", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07444", "abs": "https://arxiv.org/abs/2507.07444", "authors": ["Korbinian Moller", "Rafael Neher", "Marvin Seegert", "Johannes Betz"], "title": "Towards Safe Autonomous Driving: A Real-Time Safeguarding Concept for Motion Planning Algorithms", "comment": "7 pages, submitted to the IEEE ICVES 2025, Coventry, UK", "summary": "Ensuring the functional safety of motion planning modules in autonomous\nvehicles remains a critical challenge, especially when dealing with complex or\nlearning-based software. Online verification has emerged as a promising\napproach to monitor such systems at runtime, yet its integration into embedded\nreal-time environments remains limited. This work presents a safeguarding\nconcept for motion planning that extends prior approaches by introducing a time\nsafeguard. While existing methods focus on geometric and dynamic feasibility,\nour approach additionally monitors the temporal consistency of planning outputs\nto ensure timely system response. A prototypical implementation on a real-time\noperating system evaluates trajectory candidates using constraint-based\nfeasibility checks and cost-based plausibility metrics. Preliminary results\nshow that the safeguarding module operates within real-time bounds and\neffectively detects unsafe trajectories. However, the full integration of the\ntime safeguard logic and fallback strategies is ongoing. This study contributes\na modular and extensible framework for runtime trajectory verification and\nhighlights key aspects for deployment on automotive-grade hardware. Future work\nincludes completing the safeguarding logic and validating its effectiveness\nthrough hardware-in-the-loop simulations and vehicle-based testing. The code is\navailable at: https://github.com/TUM-AVS/motion-planning-supervisor", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8fd0\u52a8\u89c4\u5212\u6a21\u5757\u7684\u5b89\u5168\u4fdd\u969c\u6982\u5ff5\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u4fdd\u62a4\u673a\u5236\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u786e\u4fdd\u7cfb\u7edf\u54cd\u5e94\u7684\u53ca\u65f6\u6027\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u4e2d\u8fd0\u52a8\u89c4\u5212\u6a21\u5757\u7684\u529f\u80fd\u5b89\u5168\u6027\u662f\u5173\u952e\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u6216\u57fa\u4e8e\u5b66\u4e60\u7684\u8f6f\u4ef6\u4e2d\u3002\u5728\u7ebf\u9a8c\u8bc1\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u4f46\u5176\u5728\u5d4c\u5165\u5f0f\u5b9e\u65f6\u73af\u5883\u4e2d\u7684\u96c6\u6210\u4ecd\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65f6\u95f4\u4fdd\u62a4\u673a\u5236\uff0c\u76d1\u63a7\u89c4\u5212\u8f93\u51fa\u7684\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u5e76\u7ed3\u5408\u7ea6\u675f\u53ef\u884c\u6027\u68c0\u67e5\u548c\u57fa\u4e8e\u6210\u672c\u7684\u5408\u7406\u6027\u8bc4\u4f30\uff0c\u5728\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u539f\u578b\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u5b89\u5168\u4fdd\u969c\u6a21\u5757\u5728\u5b9e\u65f6\u8303\u56f4\u5185\u8fd0\u884c\uff0c\u5e76\u80fd\u6709\u6548\u68c0\u6d4b\u4e0d\u5b89\u5168\u8f68\u8ff9\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u8fd0\u884c\u65f6\u8f68\u8ff9\u9a8c\u8bc1\u6846\u67b6\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u6c7d\u8f66\u7ea7\u786c\u4ef6\u4e0a\u90e8\u7f72\u7684\u5173\u952e\u65b9\u9762\u3002\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u5b8c\u5584\u4fdd\u62a4\u903b\u8f91\u5e76\u901a\u8fc7\u786c\u4ef6\u5728\u73af\u4eff\u771f\u548c\u8f66\u8f86\u6d4b\u8bd5\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.07192", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07192", "abs": "https://arxiv.org/abs/2507.07192", "authors": ["Huibo Xu", "Runlong Yu", "Likang Wu", "Xianquan Wang", "Qi Liu"], "title": "Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching", "comment": null, "summary": "Diffusion models, a type of generative model, have shown promise in time\nseries forecasting. But they face limitations like rigid source distributions\nand limited sampling paths, which hinder their performance. Flow matching\noffers faster generation, higher-quality outputs, and greater flexibility,\nwhile also possessing the ability to utilize valuable information from the\nprediction errors of prior models, which were previously inaccessible yet\ncritically important. To address these challenges and fully unlock the untapped\npotential of flow matching, we propose Conditional Guided Flow Matching (CGFM).\nCGFM extends flow matching by incorporating the outputs of an auxiliary model,\nenabling a previously unattainable capability in the field: learning from the\nerrors of the auxiliary model. For time series forecasting tasks, it integrates\nhistorical data as conditions and guidance, constructs two-sided conditional\nprobability paths, and uses a general affine path to expand the space of\nprobability paths, ultimately leading to improved predictions. Extensive\nexperiments show that CGFM consistently enhances and outperforms\nstate-of-the-art models, highlighting its effectiveness in advancing\nforecasting methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCGFM\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u8f85\u52a9\u6a21\u578b\u7684\u8f93\u51fa\u548c\u6d41\u5339\u914d\u6280\u672f\uff0c\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6027\u80fd\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u521a\u6027\u6e90\u5206\u5e03\u548c\u6709\u9650\u91c7\u6837\u8def\u5f84\uff0c\u800c\u6d41\u5339\u914d\u6280\u672f\u63d0\u4f9b\u4e86\u66f4\u5feb\u7684\u751f\u6210\u548c\u66f4\u9ad8\u8d28\u91cf\u7684\u8f93\u51fa\u3002", "method": "CGFM\u901a\u8fc7\u6574\u5408\u8f85\u52a9\u6a21\u578b\u7684\u8f93\u51fa\u548c\u5386\u53f2\u6570\u636e\uff0c\u6784\u5efa\u53cc\u9762\u6761\u4ef6\u6982\u7387\u8def\u5f84\uff0c\u5e76\u4f7f\u7528\u4e00\u822c\u4eff\u5c04\u8def\u5f84\u6269\u5c55\u6982\u7387\u8def\u5f84\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCGFM\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "CGFM\u901a\u8fc7\u5229\u7528\u8f85\u52a9\u6a21\u578b\u7684\u9519\u8bef\u4fe1\u606f\u548c\u66f4\u7075\u6d3b\u7684\u6982\u7387\u8def\u5f84\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6548\u679c\u3002"}}
{"id": "2507.07467", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07467", "abs": "https://arxiv.org/abs/2507.07467", "authors": ["Juyeop Han", "Lukas Lao Beyer", "Guilherme V. Cavalheiro", "Sertac Karaman"], "title": "SCREP: Scene Coordinate Regression and Evidential Learning-based Perception-Aware Trajectory Generation", "comment": "8 pages, 7 figures, 3 tables", "summary": "Autonomous flight in GPS denied indoor spaces requires trajectories that keep\nvisual localization error tightly bounded across varied missions. Whereas\nvisual inertial odometry (VIO) accumulates drift over time, scene coordinate\nregression (SCR) yields drift-free, high accuracy absolute pose estimation. We\npresent a perception-aware framework that couples an evidential learning-based\nSCR pose estimator with a receding horizon trajectory optimizer. The optimizer\nsteers the onboard camera toward pixels whose uncertainty predicts reliable\nscene coordinates, while a fixed-lag smoother fuses the low rate SCR stream\nwith high rate IMU data to close the perception control loop in real time. In\nsimulation, our planner reduces translation (rotation) mean error by 54% / 15%\n(40% / 31%) relative to yaw fixed and forward-looking baselines, respectively.\nMoreover, hardware in the loop experiment validates the feasibility of our\nproposed framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u573a\u666f\u5750\u6807\u56de\u5f52\uff08SCR\uff09\u548c\u8f68\u8ff9\u4f18\u5316\u7684\u611f\u77e5\u611f\u77e5\u6846\u67b6\uff0c\u7528\u4e8eGPS\u7f3a\u5931\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u98de\u884c\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b9a\u4f4d\u8bef\u5dee\u3002", "motivation": "\u89e3\u51b3GPS\u7f3a\u5931\u73af\u5883\u4e0b\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\uff08VIO\uff09\u56e0\u6f02\u79fb\u7d2f\u79ef\u5bfc\u81f4\u7684\u5b9a\u4f4d\u8bef\u5dee\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u8bc1\u636e\u5b66\u4e60\u7684SCR\u59ff\u6001\u4f30\u8ba1\u5668\u548c\u540e\u9000\u6c34\u5e73\u8f68\u8ff9\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u4f18\u5316\u76f8\u673a\u89c6\u89d2\u9009\u62e9\u4f4e\u4e0d\u786e\u5b9a\u6027\u50cf\u7d20\uff0c\u5e76\u878d\u5408SCR\u4e0eIMU\u6570\u636e\u5b9e\u73b0\u5b9e\u65f6\u95ed\u73af\u3002", "result": "\u4eff\u771f\u4e2d\uff0c\u5e73\u79fb\u548c\u65cb\u8f6c\u5e73\u5747\u8bef\u5dee\u5206\u522b\u964d\u4f4e\u4e8654%/15%\u548c40%/31%\uff1b\u786c\u4ef6\u5728\u73af\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u51cf\u5c11\u4e86\u5b9a\u4f4d\u8bef\u5dee\uff0c\u9002\u7528\u4e8eGPS\u7f3a\u5931\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u98de\u884c\u3002"}}
{"id": "2507.07197", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07197", "abs": "https://arxiv.org/abs/2507.07197", "authors": ["Elia Piccoli", "Malio Li", "Giacomo Carf\u00ec", "Vincenzo Lomonaco", "Davide Bacciu"], "title": "Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning", "comment": "Published at 4th Conference on Lifelong Learning Agents (CoLLAs),\n  2025", "summary": "The recent focus and release of pre-trained models have been a key components\nto several advancements in many fields (e.g. Natural Language Processing and\nComputer Vision), as a matter of fact, pre-trained models learn disparate\nlatent embeddings sharing insightful representations. On the other hand,\nReinforcement Learning (RL) focuses on maximizing the cumulative reward\nobtained via agent's interaction with the environment. RL agents do not have\nany prior knowledge about the world, and they either learn from scratch an\nend-to-end mapping between the observation and action spaces or, in more recent\nworks, are paired with monolithic and computationally expensive Foundational\nModels. How to effectively combine and leverage the hidden information of\ndifferent pre-trained models simultaneously in RL is still an open and\nunderstudied question. In this work, we propose Weight Sharing Attention (WSA),\na new architecture to combine embeddings of multiple pre-trained models to\nshape an enriched state representation, balancing the tradeoff between\nefficiency and performance. We run an extensive comparison between several\ncombination modes showing that WSA obtains comparable performance on multiple\nAtari games compared to end-to-end models. Furthermore, we study the\ngeneralization capabilities of this approach and analyze how scaling the number\nof models influences agents' performance during and after training.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faWeight Sharing Attention (WSA)\u67b6\u6784\uff0c\u7528\u4e8e\u7ed3\u5408\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5d4c\u5165\u4fe1\u606f\uff0c\u4ee5\u4e30\u5bcc\u5f3a\u5316\u5b66\u4e60\u7684\u72b6\u6001\u8868\u793a\uff0c\u5e73\u8861\u6548\u7387\u4e0e\u6027\u80fd\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u901a\u5e38\u7f3a\u4e4f\u5148\u9a8c\u77e5\u8bc6\uff0c\u800c\u9884\u8bad\u7ec3\u6a21\u578b\u80fd\u63d0\u4f9b\u4e30\u5bcc\u7684\u6f5c\u5728\u8868\u793a\u3002\u5982\u4f55\u6709\u6548\u7ed3\u5408\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4fe1\u606f\u4ee5\u63d0\u5347RL\u6027\u80fd\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u63d0\u51faWSA\u67b6\u6784\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u7ed3\u5408\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5d4c\u5165\u4fe1\u606f\uff0c\u5f62\u6210\u66f4\u4e30\u5bcc\u7684\u72b6\u6001\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2aAtari\u6e38\u620f\u4e2d\uff0cWSA\u8868\u73b0\u4e0e\u7aef\u5230\u7aef\u6a21\u578b\u76f8\u5f53\uff0c\u5e76\u7814\u7a76\u4e86\u6a21\u578b\u6570\u91cf\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "WSA\u6709\u6548\u7ed3\u5408\u9884\u8bad\u7ec3\u6a21\u578b\u4fe1\u606f\uff0c\u4e3aRL\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07661", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.07661", "abs": "https://arxiv.org/abs/2507.07661", "authors": ["Daria Trinitatova", "Dzmitry Tsetserukou"], "title": "FiDTouch: A 3D Wearable Haptic Display for the Finger Pad", "comment": "Accepted to the IEEE World Haptics Conference 2025 (IEEE WHC 2025), 7\n  pages, 8 figures, 3 tables", "summary": "The applications of fingertip haptic devices have spread to various fields\nfrom revolutionizing virtual reality and medical training simulations to\nfacilitating remote robotic operations, proposing great potential for enhancing\nuser experiences, improving training outcomes, and new forms of interaction. In\nthis work, we present FiDTouch, a 3D wearable haptic device that delivers\ncutaneous stimuli to the finger pad, such as contact, pressure, encounter, skin\nstretch, and vibrotactile feedback. The application of a tiny inverted Delta\nrobot in the mechanism design allows providing accurate contact and fast\nchanging dynamic stimuli to the finger pad surface. The performance of the\ndeveloped display was evaluated in a two-stage user study of the perception of\nstatic spatial contact stimuli and skin stretch stimuli generated on the finger\npad. The proposed display, by providing users with precise touch and force\nstimuli, can enhance user immersion and efficiency in the fields of\nhuman-computer and human-robot interactions.", "AI": {"tldr": "FiDTouch\u662f\u4e00\u79cd3D\u53ef\u7a7f\u6234\u89e6\u89c9\u8bbe\u5907\uff0c\u901a\u8fc7\u5fae\u578b\u5012\u7f6eDelta\u673a\u5668\u4eba\u63d0\u4f9b\u7cbe\u786e\u7684\u89e6\u89c9\u53cd\u9988\uff0c\u589e\u5f3a\u4eba\u673a\u4ea4\u4e92\u4f53\u9a8c\u3002", "motivation": "\u63a2\u7d22\u6307\u5c16\u89e6\u89c9\u8bbe\u5907\u5728\u865a\u62df\u73b0\u5b9e\u3001\u533b\u7597\u57f9\u8bad\u548c\u8fdc\u7a0b\u673a\u5668\u4eba\u64cd\u4f5c\u7b49\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u8bbe\u8ba1FiDTouch\u8bbe\u5907\uff0c\u5229\u7528\u5012\u7f6eDelta\u673a\u5668\u4eba\u63d0\u4f9b\u63a5\u89e6\u3001\u538b\u529b\u3001\u76ae\u80a4\u62c9\u4f38\u548c\u632f\u52a8\u53cd\u9988\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8bbe\u5907\u80fd\u7cbe\u786e\u4f20\u9012\u9759\u6001\u7a7a\u95f4\u63a5\u89e6\u548c\u76ae\u80a4\u62c9\u4f38\u523a\u6fc0\uff0c\u63d0\u5347\u6c89\u6d78\u611f\u548c\u4ea4\u4e92\u6548\u7387\u3002", "conclusion": "FiDTouch\u901a\u8fc7\u7cbe\u786e\u89e6\u89c9\u53cd\u9988\uff0c\u4e3a\u4eba\u673a\u548c\u4eba\u7c7b-\u673a\u5668\u4eba\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.07207", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.07207", "abs": "https://arxiv.org/abs/2507.07207", "authors": ["Florian Redhardt", "Yassir Akram", "Simon Schug"], "title": "Scale leads to compositional generalization", "comment": "Code available at https://github.com/smonsays/scale-compositionality", "summary": "Can neural networks systematically capture discrete, compositional task\nstructure despite their continuous, distributed nature? The impressive\ncapabilities of large-scale neural networks suggest that the answer to this\nquestion is yes. However, even for the most capable models, there are still\nfrequent failure cases that raise doubts about their compositionality. Here, we\nseek to understand what it takes for a standard neural network to generalize\nover tasks that share compositional structure. We find that simply scaling data\nand model size leads to compositional generalization. We show that this holds\nacross different task encodings as long as the training distribution\nsufficiently covers the task space. In line with this finding, we prove that\nstandard multilayer perceptrons can approximate a general class of\ncompositional task families to arbitrary precision using only a linear number\nof neurons with respect to the number of task modules. Finally, we uncover that\nif networks successfully compositionally generalize, the constituents of a task\ncan be linearly decoded from their hidden activations. We show that this metric\ncorrelates with failures of text-to-image generation models to compose known\nconcepts.", "AI": {"tldr": "\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u6269\u5c55\u6570\u636e\u548c\u6a21\u578b\u89c4\u6a21\u53ef\u4ee5\u5b9e\u73b0\u7ec4\u5408\u6cdb\u5316\uff0c\u4e14\u5728\u4e0d\u540c\u4efb\u52a1\u7f16\u7801\u4e0b\u5747\u6709\u6548\u3002", "motivation": "\u63a2\u8ba8\u795e\u7ecf\u7f51\u7edc\u662f\u5426\u80fd\u7cfb\u7edf\u6027\u6355\u6349\u79bb\u6563\u3001\u7ec4\u5408\u7684\u4efb\u52a1\u7ed3\u6784\uff0c\u5c3d\u7ba1\u5176\u672c\u8d28\u662f\u8fde\u7eed\u548c\u5206\u5e03\u5f0f\u7684\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u6570\u636e\u548c\u6a21\u578b\u89c4\u6a21\uff0c\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5728\u4e0d\u540c\u4efb\u52a1\u7f16\u7801\u4e0b\u7684\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u6807\u51c6\u591a\u5c42\u611f\u77e5\u5668\u80fd\u4ee5\u7ebf\u6027\u795e\u7ecf\u5143\u6570\u91cf\u8fd1\u4f3c\u7ec4\u5408\u4efb\u52a1\u65cf\uff0c\u4e14\u6210\u529f\u7ec4\u5408\u6cdb\u5316\u65f6\u4efb\u52a1\u6210\u5206\u53ef\u4ece\u9690\u85cf\u6fc0\u6d3b\u4e2d\u7ebf\u6027\u89e3\u7801\u3002", "conclusion": "\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\u4e0e\u6570\u636e\u548c\u6a21\u578b\u89c4\u6a21\u76f8\u5173\uff0c\u4e14\u53ef\u901a\u8fc7\u9690\u85cf\u6fc0\u6d3b\u7684\u89e3\u7801\u6027\u8861\u91cf\u3002"}}
{"id": "2507.07714", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07714", "abs": "https://arxiv.org/abs/2507.07714", "authors": ["Julio Garrido", "Javier Vales", "Diego Silva-Mu\u00f1iz", "Enrique Riveiro", "Pablo L\u00f3pez-Matencio", "Josu\u00e9 Rivera-Andrade"], "title": "Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots", "comment": "14 pages, 8 figures, 1 table, to be submitted to Advanced Intelligent\n  Systems", "summary": "Cable-Driven Parallel Robots (CDPRs) are increasingly used for load\nmanipulation tasks involving predefined toolpaths with intermediate stops. At\neach stop, where the platform maintains a fixed pose and the motors keep the\ncables under tension, the system must evaluate whether it is safe to proceed by\ndetecting anomalies that could compromise performance (e.g., wind gusts or\ncable impacts). This paper investigates whether anomalies can be detected using\nonly motor torque data, without additional sensors. It introduces an adaptive,\nunsupervised outlier detection algorithm based on Gaussian Mixture Models\n(GMMs) to identify anomalies from torque signals. The method starts with a\nbrief calibration period, just a few seconds, during which a GMM is fit on\nknown anomaly-free data. Real-time torque measurements are then evaluated using\nMahalanobis distance from the GMM, with statistically derived thresholds\ntriggering anomaly flags. Model parameters are periodically updated using the\nlatest segments identified as anomaly-free to adapt to changing conditions.\nValidation includes 14 long-duration test sessions simulating varied wind\nintensities. The proposed method achieves a 100% true positive rate and 95.4%\naverage true negative rate, with 1-second detection latency. Comparative\nevaluation against power threshold and non-adaptive GMM methods indicates\nhigher robustness to drift and environmental variation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u7684\u81ea\u9002\u5e94\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\uff0c\u4ec5\u5229\u7528\u7535\u673a\u626d\u77e9\u6570\u636e\u68c0\u6d4b\u7535\u7f06\u9a71\u52a8\u5e76\u8054\u673a\u5668\u4eba\uff08CDPRs\uff09\u4e2d\u7684\u5f02\u5e38\u3002", "motivation": "\u5728CDPRs\u7684\u8d1f\u8f7d\u64cd\u7eb5\u4efb\u52a1\u4e2d\uff0c\u9700\u5728\u56fa\u5b9a\u59ff\u6001\u4e0b\u68c0\u6d4b\u5f02\u5e38\u4ee5\u786e\u4fdd\u5b89\u5168\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u989d\u5916\u4f20\u611f\u5668\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4ec5\u7528\u7535\u673a\u626d\u77e9\u6570\u636e\u7684\u53ef\u884c\u6027\u3002", "method": "\u901a\u8fc7\u77ed\u65f6\u95f4\u6821\u51c6\u62df\u5408GMM\uff0c\u5b9e\u65f6\u4f7f\u7528\u9a6c\u6c0f\u8ddd\u79bb\u8bc4\u4f30\u626d\u77e9\u4fe1\u53f7\uff0c\u52a8\u6001\u66f4\u65b0\u6a21\u578b\u53c2\u6570\u4ee5\u9002\u5e94\u73af\u5883\u53d8\u5316\u3002", "result": "\u572814\u6b21\u957f\u65f6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u5b9e\u73b0\u4e86100%\u771f\u9633\u6027\u7387\u548c95.4%\u5e73\u5747\u771f\u9634\u6027\u7387\uff0c\u68c0\u6d4b\u5ef6\u8fdf\u4ec51\u79d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u4f20\u611f\u5668\uff0c\u5bf9\u6f02\u79fb\u548c\u73af\u5883\u53d8\u5316\u5177\u6709\u66f4\u9ad8\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u529f\u7387\u9608\u503c\u548c\u975e\u81ea\u9002\u5e94GMM\u65b9\u6cd5\u3002"}}
{"id": "2507.07216", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.07216", "abs": "https://arxiv.org/abs/2507.07216", "authors": ["Yunyi Li", "Maria De-Arteaga", "Maytal Saar-Tsechansky"], "title": "Bias-Aware Mislabeling Detection via Decoupled Confident Learning", "comment": null, "summary": "Reliable data is a cornerstone of modern organizational systems. A notable\ndata integrity challenge stems from label bias, which refers to systematic\nerrors in a label, a covariate that is central to a quantitative analysis, such\nthat its quality differs across social groups. This type of bias has been\nconceptually and empirically explored and is widely recognized as a pressing\nissue across critical domains. However, effective methodologies for addressing\nit remain scarce. In this work, we propose Decoupled Confident Learning\n(DeCoLe), a principled machine learning based framework specifically designed\nto detect mislabeled instances in datasets affected by label bias, enabling\nbias aware mislabelling detection and facilitating data quality improvement. We\ntheoretically justify the effectiveness of DeCoLe and evaluate its performance\nin the impactful context of hate speech detection, a domain where label bias is\na well documented challenge. Empirical results demonstrate that DeCoLe excels\nat bias aware mislabeling detection, consistently outperforming alternative\napproaches for label error detection. Our work identifies and addresses the\nchallenge of bias aware mislabeling detection and offers guidance on how DeCoLe\ncan be integrated into organizational data management practices as a powerful\ntool to enhance data reliability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDeCoLe\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u6807\u7b7e\u504f\u5dee\u5bfc\u81f4\u7684\u6570\u636e\u9519\u8bef\u6807\u8bb0\u95ee\u9898\uff0c\u5e76\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u9886\u57df\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6807\u7b7e\u504f\u5dee\u662f\u73b0\u4ee3\u7ec4\u7ec7\u7cfb\u7edf\u4e2d\u6570\u636e\u5b8c\u6574\u6027\u7684\u4e3b\u8981\u6311\u6218\u4e4b\u4e00\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Decoupled Confident Learning (DeCoLe)\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u68c0\u6d4b\u53d7\u6807\u7b7e\u504f\u5dee\u5f71\u54cd\u7684\u6570\u636e\u96c6\u4e2d\u7684\u9519\u8bef\u6807\u8bb0\u5b9e\u4f8b\u3002", "result": "\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u9886\u57df\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cDeCoLe\u5728\u504f\u5dee\u611f\u77e5\u7684\u9519\u8bef\u6807\u8bb0\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "DeCoLe\u4e3a\u504f\u5dee\u611f\u77e5\u7684\u9519\u8bef\u6807\u8bb0\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53ef\u4f5c\u4e3a\u63d0\u5347\u6570\u636e\u53ef\u9760\u6027\u7684\u5de5\u5177\u5e94\u7528\u4e8e\u7ec4\u7ec7\u6570\u636e\u7ba1\u7406\u5b9e\u8df5\u4e2d\u3002"}}
{"id": "2507.07718", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07718", "abs": "https://arxiv.org/abs/2507.07718", "authors": ["Alberto Rota", "Ke Fan", "Elena De Momi"], "title": "Implementation and Assessment of an Augmented Training Curriculum for Surgical Robotics", "comment": null, "summary": "The integration of high-level assistance algorithms in surgical robotics\ntraining curricula may be beneficial in establishing a more comprehensive and\nrobust skillset for aspiring surgeons, improving their clinical performance as\na consequence. This work presents the development and validation of a\nhaptic-enhanced Virtual Reality simulator for surgical robotics training,\nfeaturing 8 surgical tasks that the trainee can interact with thanks to the\nembedded physics engine. This virtual simulated environment is augmented by the\nintroduction of high-level haptic interfaces for robotic assistance that aim at\nre-directing the motion of the trainee's hands and wrists toward targets or\naway from obstacles, and providing a quantitative performance score after the\nexecution of each training exercise.An experimental study shows that the\nintroduction of enhanced robotic assistance into a surgical robotics training\ncurriculum improves performance during the training process and, crucially,\npromotes the transfer of the acquired skills to an unassisted surgical\nscenario, like the clinical one.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u89e6\u89c9\u589e\u5f3a\u7684\u865a\u62df\u73b0\u5b9e\u624b\u672f\u673a\u5668\u4eba\u8bad\u7ec3\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u5f15\u5165\u9ad8\u7ea7\u89e6\u89c9\u8f85\u52a9\u7b97\u6cd5\uff0c\u63d0\u5347\u57f9\u8bad\u6548\u679c\u5e76\u4fc3\u8fdb\u6280\u80fd\u5411\u65e0\u8f85\u52a9\u4e34\u5e8a\u573a\u666f\u7684\u8fc1\u79fb\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u6574\u5408\u9ad8\u7ea7\u8f85\u52a9\u7b97\u6cd5\uff0c\u4e3a\u5916\u79d1\u533b\u751f\u57f9\u8bad\u63d0\u4f9b\u66f4\u5168\u9762\u548c\u7a33\u5065\u7684\u6280\u80fd\u8bad\u7ec3\uff0c\u4ece\u800c\u63d0\u5347\u5176\u4e34\u5e8a\u8868\u73b0\u3002", "method": "\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u89e6\u89c9\u589e\u5f3a\u7684\u865a\u62df\u73b0\u5b9e\u6a21\u62df\u5668\uff0c\u5305\u542b8\u4e2a\u624b\u672f\u4efb\u52a1\uff0c\u901a\u8fc7\u7269\u7406\u5f15\u64ce\u548c\u9ad8\u7ea7\u89e6\u89c9\u63a5\u53e3\u5b9e\u73b0\u8fd0\u52a8\u5f15\u5bfc\u548c\u6027\u80fd\u8bc4\u5206\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f15\u5165\u589e\u5f3a\u673a\u5668\u4eba\u8f85\u52a9\u663e\u8457\u63d0\u9ad8\u4e86\u57f9\u8bad\u8fc7\u7a0b\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4fc3\u8fdb\u4e86\u6280\u80fd\u5411\u65e0\u8f85\u52a9\u4e34\u5e8a\u573a\u666f\u7684\u8fc1\u79fb\u3002", "conclusion": "\u8be5\u6a21\u62df\u5668\u901a\u8fc7\u9ad8\u7ea7\u89e6\u89c9\u8f85\u52a9\u6709\u6548\u63d0\u5347\u4e86\u5916\u79d1\u673a\u5668\u4eba\u57f9\u8bad\u7684\u6548\u679c\u548c\u6280\u80fd\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2507.07222", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.07222", "abs": "https://arxiv.org/abs/2507.07222", "authors": ["Minchan Jeong", "J. Jon Ryu", "Se-Young Yun", "Gregory W. Wornell"], "title": "Efficient Parametric SVD of Koopman Operator for Stochastic Dynamical Systems", "comment": "28 pages, 4 figures. Under review for NeurIPS 2025. The first two\n  authors contributed equally", "summary": "The Koopman operator provides a principled framework for analyzing nonlinear\ndynamical systems through linear operator theory. Recent advances in dynamic\nmode decomposition (DMD) have shown that trajectory data can be used to\nidentify dominant modes of a system in a data-driven manner. Building on this\nidea, deep learning methods such as VAMPnet and DPNet have been proposed to\nlearn the leading singular subspaces of the Koopman operator. However, these\nmethods require backpropagation through potentially numerically unstable\noperations on empirical second moment matrices, such as singular value\ndecomposition and matrix inversion, during objective computation, which can\nintroduce biased gradient estimates and hinder scalability to large systems. In\nthis work, we propose a scalable and conceptually simple method for learning\nthe top-k singular functions of the Koopman operator for stochastic dynamical\nsystems based on the idea of low-rank approximation. Our approach eliminates\nthe need for unstable linear algebraic operations and integrates easily into\nmodern deep learning pipelines. Empirical results demonstrate that the learned\nsingular subspaces are both reliable and effective for downstream tasks such as\neigen-analysis and multi-step prediction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4f4e\u79e9\u8fd1\u4f3c\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b66\u4e60Koopman\u7b97\u5b50\u7684\u524dk\u4e2a\u5947\u5f02\u51fd\u6570\uff0c\u907f\u514d\u4e86\u4e0d\u7a33\u5b9a\u7684\u7ebf\u6027\u4ee3\u6570\u64cd\u4f5c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982VAMPnet\u548cDPNet\uff09\u5728\u8ba1\u7b97\u76ee\u6807\u65f6\u9700\u901a\u8fc7\u6570\u503c\u4e0d\u7a33\u5b9a\u7684\u64cd\u4f5c\uff08\u5982\u5947\u5f02\u503c\u5206\u89e3\u548c\u77e9\u9635\u6c42\u9006\uff09\uff0c\u53ef\u80fd\u5bfc\u81f4\u68af\u5ea6\u4f30\u8ba1\u504f\u5dee\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u5927\u7cfb\u7edf\u3002", "method": "\u57fa\u4e8e\u4f4e\u79e9\u8fd1\u4f3c\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4e0d\u7a33\u5b9a\u7684\u7ebf\u6027\u4ee3\u6570\u64cd\u4f5c\uff0c\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u6d41\u7a0b\u4e2d\u3002", "result": "\u5b66\u4e60\u5230\u7684\u5947\u5f02\u5b50\u7a7a\u95f4\u5728\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u7279\u5f81\u5206\u6790\u548c\u591a\u6b65\u9884\u6d4b\uff09\u4e2d\u53ef\u9760\u4e14\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u968f\u673a\u52a8\u529b\u7cfb\u7edf\u3002"}}
{"id": "2507.07724", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07724", "abs": "https://arxiv.org/abs/2507.07724", "authors": ["Thiemen Siemensma", "Niels de Boer", "Bahar Haghighat"], "title": "Distributed Surface Inspection via Operational Modal Analysis by a Swarm of Miniaturized Vibration-Sensing Robots", "comment": null, "summary": "Robot swarms offer the potential to serve a variety of distributed sensing\napplications. An interesting real-world application that stands to benefit\nsignificantly from deployment of swarms is structural monitoring, where\ntraditional sensor networks face challenges in structural coverage due to their\nstatic nature. This paper investigates the deployment of a swarm of\nminiaturized vibration sensing robots to inspect and localize structural\ndamages on a surface section within a high-fidelity simulation environment. In\nparticular, we consider a 1 m x 1 m x 3 mm steel surface section and utilize\nfinite element analysis using Abaqus to obtain realistic structural vibration\ndata. The resulting vibration data is imported into the physics-based robotic\nsimulator Webots, where we simulate the dynamics of our surface inspecting\nrobot swarm. We employ (i) Gaussian process estimators to guide the robots'\nexploration as they collect vibration samples across the surface and (ii)\noperational modal analysis to detect structural damages by estimating and\ncomparing existing and intact structural vibration patterns. We analyze the\ninfluence of exploration radii on estimation uncertainty and assess the\neffectiveness of our method across 10 randomized scenarios, where the number,\nlocations, surface area, and depth of structural damages vary. Our simulation\nstudies validate the efficacy of our miniaturized robot swarm for\nvibration-based structural inspection.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5229\u7528\u5fae\u578b\u632f\u52a8\u4f20\u611f\u673a\u5668\u4eba\u7fa4\u4f53\u5728\u4eff\u771f\u73af\u5883\u4e2d\u68c0\u6d4b\u548c\u5b9a\u4f4d\u7ed3\u6784\u635f\u4f24\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u4f30\u8ba1\u5668\u548c\u6a21\u6001\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u4f20\u611f\u5668\u7f51\u7edc\u5728\u7ed3\u6784\u76d1\u6d4b\u4e2d\u5b58\u5728\u8986\u76d6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u673a\u5668\u4eba\u7fa4\u4f53\u56e0\u5176\u52a8\u6001\u6027\u6709\u671b\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5728Abaqus\u4e2d\u901a\u8fc7\u6709\u9650\u5143\u5206\u6790\u83b7\u53d6\u632f\u52a8\u6570\u636e\uff0c\u5bfc\u5165Webots\u6a21\u62df\u673a\u5668\u4eba\u7fa4\u4f53\u52a8\u6001\uff0c\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u4f30\u8ba1\u5668\u5f15\u5bfc\u63a2\u7d22\uff0c\u5e76\u901a\u8fc7\u6a21\u6001\u5206\u6790\u68c0\u6d4b\u635f\u4f24\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u673a\u5668\u4eba\u7fa4\u4f53\u5728\u632f\u52a8\u68c0\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5206\u6790\u4e86\u63a2\u7d22\u534a\u5f84\u5bf9\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u5fae\u578b\u673a\u5668\u4eba\u7fa4\u4f53\u5728\u632f\u52a8\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\uff0c\u4e3a\u7ed3\u6784\u76d1\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.07236", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07236", "abs": "https://arxiv.org/abs/2507.07236", "authors": ["Maya Kruse", "Majid Afshar", "Saksham Khatwani", "Anoop Mayampurath", "Guanhua Chen", "Yanjun Gao"], "title": "An Information-Theoretic Perspective on Multi-LLM Uncertainty Estimation", "comment": "Under review", "summary": "Large language models (LLMs) often behave inconsistently across inputs,\nindicating uncertainty and motivating the need for its quantification in\nhigh-stakes settings. Prior work on calibration and uncertainty quantification\noften focuses on individual models, overlooking the potential of model\ndiversity. We hypothesize that LLMs make complementary predictions due to\ndifferences in training and the Zipfian nature of language, and that\naggregating their outputs leads to more reliable uncertainty estimates. To\nleverage this, we propose MUSE (Multi-LLM Uncertainty via Subset Ensembles), a\nsimple information-theoretic method that uses Jensen-Shannon Divergence to\nidentify and aggregate well-calibrated subsets of LLMs. Experiments on binary\nprediction tasks demonstrate improved calibration and predictive performance\ncompared to single-model and naive ensemble baselines.", "AI": {"tldr": "MUSE\u65b9\u6cd5\u901a\u8fc7\u96c6\u6210\u591a\u4e2aLLM\u7684\u5b50\u96c6\uff0c\u5229\u7528Jensen-Shannon\u6563\u5ea6\u63d0\u9ad8\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u53ef\u9760\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u6821\u51c6\u548c\u9884\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u5355\u6a21\u578b\u548c\u7b80\u5355\u96c6\u6210\u57fa\u7ebf\u3002", "motivation": "LLMs\u5728\u8f93\u5165\u4e0a\u8868\u73b0\u4e0d\u4e00\u81f4\uff0c\u8868\u660e\u9700\u8981\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5355\u6a21\u578b\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u591a\u6837\u6027\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faMUSE\u65b9\u6cd5\uff0c\u5229\u7528Jensen-Shannon\u6563\u5ea6\u9009\u62e9\u548c\u96c6\u6210\u6821\u51c6\u826f\u597d\u7684LLM\u5b50\u96c6\u3002", "result": "\u5728\u4e8c\u5143\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cMUSE\u5728\u6821\u51c6\u548c\u9884\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u5355\u6a21\u578b\u548c\u7b80\u5355\u96c6\u6210\u57fa\u7ebf\u3002", "conclusion": "MUSE\u901a\u8fc7\u5229\u7528\u6a21\u578b\u591a\u6837\u6027\uff0c\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u573a\u666f\u3002"}}
{"id": "2507.07745", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07745", "abs": "https://arxiv.org/abs/2507.07745", "authors": ["Eleni Konstantinidou", "Nikolaos Kounalakis", "Nikolaos Efstathopoulos", "Dimitrios Papageorgiou"], "title": "On the capabilities of LLMs for classifying and segmenting time series of fruit picking motions into primitive actions", "comment": "This paper is a Late Breaking Results report and it will be presented\n  through a poster at the 34th IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN), 2025 at Eindhoven, the Netherlands", "summary": "Despite their recent introduction to human society, Large Language Models\n(LLMs) have significantly affected the way we tackle mental challenges in our\neveryday lives. From optimizing our linguistic communication to assisting us in\nmaking important decisions, LLMs, such as ChatGPT, are notably reducing our\ncognitive load by gradually taking on an increasing share of our mental\nactivities. In the context of Learning by Demonstration (LbD), classifying and\nsegmenting complex motions into primitive actions, such as pushing, pulling,\ntwisting etc, is considered to be a key-step towards encoding a task. In this\nwork, we investigate the capabilities of LLMs to undertake this task,\nconsidering a finite set of predefined primitive actions found in fruit picking\noperations. By utilizing LLMs instead of simple supervised learning or analytic\nmethods, we aim at making the method easily applicable and deployable in a\nreal-life scenario. Three different fine-tuning approaches are investigated,\ncompared on datasets captured kinesthetically, using a UR10e robot, during a\nfruit-picking scenario.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6c34\u679c\u91c7\u6458\u4efb\u52a1\u4e2d\u5206\u7c7b\u548c\u5206\u5272\u590d\u6742\u52a8\u4f5c\u7684\u80fd\u529b\uff0c\u6bd4\u8f83\u4e86\u4e09\u79cd\u5fae\u8c03\u65b9\u6cd5\u3002", "motivation": "LLMs\u5982ChatGPT\u5df2\u663e\u8457\u5f71\u54cd\u4eba\u7c7b\u5904\u7406\u65e5\u5e38\u5fc3\u7406\u6311\u6218\u7684\u65b9\u5f0f\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5176\u5728\u5b66\u4e60\u793a\u8303\uff08LbD\uff09\u4e2d\u5206\u7c7b\u548c\u5206\u5272\u52a8\u4f5c\u7684\u6f5c\u529b\uff0c\u4ee5\u7b80\u5316\u4efb\u52a1\u7f16\u7801\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u4e0d\u540c\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5229\u7528UR10e\u673a\u5668\u4eba\u91c7\u96c6\u7684\u6570\u636e\u96c6\uff0c\u5728\u6c34\u679c\u91c7\u6458\u573a\u666f\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u901a\u8fc7LLMs\u800c\u975e\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u6216\u5206\u6790\u65b9\u6cd5\uff0c\u4f7f\u65b9\u6cd5\u66f4\u6613\u4e8e\u5b9e\u9645\u5e94\u7528\u548c\u90e8\u7f72\u3002", "conclusion": "LLMs\u5728\u52a8\u4f5c\u5206\u7c7b\u548c\u5206\u5272\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4e3a\u5b9e\u9645\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07237", "categories": ["cs.LG", "physics.data-an", "74R10, 74B20, 74A40, 68T07", "J.2; I.6.3; I.6.5"], "pdf": "https://arxiv.org/pdf/2507.07237", "abs": "https://arxiv.org/abs/2507.07237", "authors": ["Erfan Hamdi", "Emma Lejeune"], "title": "Towards Robust Surrogate Models: Benchmarking Machine Learning Approaches to Expediting Phase Field Simulations of Brittle Fracture", "comment": "29 pages, 13 figures", "summary": "Data driven approaches have the potential to make modeling complex, nonlinear\nphysical phenomena significantly more computationally tractable. For example,\ncomputational modeling of fracture is a core challenge where machine learning\ntechniques have the potential to provide a much needed speedup that would\nenable progress in areas such as mutli-scale modeling and uncertainty\nquantification. Currently, phase field modeling (PFM) of fracture is one such\napproach that offers a convenient variational formulation to model crack\nnucleation, branching and propagation. To date, machine learning techniques\nhave shown promise in approximating PFM simulations. However, most studies rely\non overly simple benchmarks that do not reflect the true complexity of the\nfracture processes where PFM excels as a method. To address this gap, we\nintroduce a challenging dataset based on PFM simulations designed to benchmark\nand advance ML methods for fracture modeling. This dataset includes three\nenergy decomposition methods, two boundary conditions, and 1,000 random initial\ncrack configurations for a total of 6,000 simulations. Each sample contains 100\ntime steps capturing the temporal evolution of the crack field. Alongside this\ndataset, we also implement and evaluate Physics Informed Neural Networks\n(PINN), Fourier Neural Operators (FNO) and UNet models as baselines, and\nexplore the impact of ensembling strategies on prediction accuracy. With this\ncombination of our dataset and baseline models drawn from the literature we aim\nto provide a standardized and challenging benchmark for evaluating machine\nlearning approaches to solid mechanics. Our results highlight both the promise\nand limitations of popular current models, and demonstrate the utility of this\ndataset as a testbed for advancing machine learning in fracture mechanics\nresearch.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u76f8\u573a\u65ad\u88c2\u6a21\u578b\uff08PFM\uff09\u7684\u590d\u6742\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u65ad\u88c2\u529b\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u6d4b\u8bd5\u4e86\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u65ad\u88c2\u529b\u5b66\u4e2d\u7684\u5e94\u7528\u591a\u57fa\u4e8e\u7b80\u5355\u57fa\u51c6\uff0c\u672a\u80fd\u53cd\u6620\u5b9e\u9645\u65ad\u88c2\u8fc7\u7a0b\u7684\u590d\u6742\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5177\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u901a\u8fc7\u76f8\u573a\u65ad\u88c2\u6a21\u578b\u751f\u6210\u5305\u542b\u591a\u79cd\u80fd\u91cf\u5206\u89e3\u65b9\u6cd5\u3001\u8fb9\u754c\u6761\u4ef6\u548c\u521d\u59cb\u88c2\u7eb9\u914d\u7f6e\u7684\u6570\u636e\u96c6\uff0c\u5e76\u6d4b\u8bd5\u4e86PINN\u3001FNO\u548cUNet\u7b49\u57fa\u7ebf\u6a21\u578b\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86\u5f53\u524d\u6d41\u884c\u6a21\u578b\u7684\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u4f5c\u4e3a\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u65ad\u88c2\u529b\u5b66\u4e2d\u5e94\u7528\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u548c\u57fa\u7ebf\u6a21\u578b\u4e3a\u65ad\u88c2\u529b\u5b66\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u5c55\u3002"}}
{"id": "2507.07752", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07752", "abs": "https://arxiv.org/abs/2507.07752", "authors": ["Thanh Nguyen Canh", "Bao Nguyen Quoc", "Haolan Zhang", "Bupesh Rethinam Veeraiah", "Xiem HoangVan", "Nak Young Chong"], "title": "IRAF-SLAM: An Illumination-Robust and Adaptive Feature-Culling Front-End for Visual SLAM in Challenging Environments", "comment": "In the European Conference on Mobile Robots 2025", "summary": "Robust Visual SLAM (vSLAM) is essential for autonomous systems operating in\nreal-world environments, where challenges such as dynamic objects, low texture,\nand critically, varying illumination conditions often degrade performance.\nExisting feature-based SLAM systems rely on fixed front-end parameters, making\nthem vulnerable to sudden lighting changes and unstable feature tracking. To\naddress these challenges, we propose ``IRAF-SLAM'', an Illumination-Robust and\nAdaptive Feature-Culling front-end designed to enhance vSLAM resilience in\ncomplex and challenging environments. Our approach introduces: (1) an image\nenhancement scheme to preprocess and adjust image quality under varying\nlighting conditions; (2) an adaptive feature extraction mechanism that\ndynamically adjusts detection sensitivity based on image entropy, pixel\nintensity, and gradient analysis; and (3) a feature culling strategy that\nfilters out unreliable feature points using density distribution analysis and a\nlighting impact factor. Comprehensive evaluations on the TUM-VI and European\nRobotics Challenge (EuRoC) datasets demonstrate that IRAF-SLAM significantly\nreduces tracking failures and achieves superior trajectory accuracy compared to\nstate-of-the-art vSLAM methods under adverse illumination conditions. These\nresults highlight the effectiveness of adaptive front-end strategies in\nimproving vSLAM robustness without incurring significant computational\noverhead. The implementation of IRAF-SLAM is publicly available at\nhttps://thanhnguyencanh. github.io/IRAF-SLAM/.", "AI": {"tldr": "IRAF-SLAM\u662f\u4e00\u79cd\u9488\u5bf9\u590d\u6742\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u89c6\u89c9SLAM\u7cfb\u7edf\uff0c\u901a\u8fc7\u56fe\u50cf\u589e\u5f3a\u3001\u81ea\u9002\u5e94\u7279\u5f81\u63d0\u53d6\u548c\u7279\u5f81\u7b5b\u9009\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u8f68\u8ff9\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709SLAM\u7cfb\u7edf\u5728\u52a8\u6001\u7269\u4f53\u3001\u4f4e\u7eb9\u7406\u548c\u5149\u7167\u53d8\u5316\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u524d\u7aef\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51faIRAF-SLAM\uff0c\u5305\u542b\u56fe\u50cf\u589e\u5f3a\u3001\u81ea\u9002\u5e94\u7279\u5f81\u63d0\u53d6\u548c\u7279\u5f81\u7b5b\u9009\u7b56\u7565\u3002", "result": "\u5728TUM-VI\u548cEuRoC\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u8ddf\u8e2a\u5931\u8d25\u5e76\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u3002", "conclusion": "\u81ea\u9002\u5e94\u524d\u7aef\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347SLAM\u9c81\u68d2\u6027\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u4f4e\u3002"}}
{"id": "2507.07247", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.07247", "abs": "https://arxiv.org/abs/2507.07247", "authors": ["Zhengyu Tian", "Anantha Padmanaban Krishna Kumar", "Hemant Krishnakumar", "Reza Rawassizadeh"], "title": "Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention", "comment": "6 pages, 8 figures", "summary": "As large language models (LLMs) and visual language models (VLMs) grow in\nscale and application, attention mechanisms have become a central computational\nbottleneck due to their high memory and time complexity. While many efficient\nattention variants have been proposed, there remains a lack of rigorous\nevaluation on their actual energy usage and hardware resource demands during\ntraining. In this work, we benchmark eight attention mechanisms in training\nGPT-2 architecture, measuring key metrics including training time, GPU memory\nusage, FLOPS, CPU usage, and power consumption. Our results reveal that\nattention mechanisms with optimized kernel implementations, including Flash\nAttention, Locality-Sensitive Hashing (LSH) Attention, and Multi-Head Latent\nAttention (MLA), achieve the best energy efficiency. We further show that lower\nGPU power alone does not guarantee reduced energy use, as training time plays\nan equally important role. Our study highlights the importance of energy-aware\nbenchmarking in attention design and provides a practical insight for selecting\nresource-efficient mechanisms. All our codes are available at GitHub.", "AI": {"tldr": "\u8bba\u6587\u5bf9\u516b\u79cd\u6ce8\u610f\u529b\u673a\u5236\u5728GPT-2\u67b6\u6784\u8bad\u7ec3\u4e2d\u7684\u80fd\u6e90\u6548\u7387\u548c\u786c\u4ef6\u8d44\u6e90\u9700\u6c42\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u4f18\u5316\u5185\u6838\u5b9e\u73b0\u7684\u6ce8\u610f\u529b\u673a\u5236\uff08\u5982Flash Attention\u3001LSH Attention\u548cMLA\uff09\u80fd\u6548\u6700\u4f73\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u89c4\u6a21\u548c\u5e94\u7528\u589e\u957f\uff0c\u6ce8\u610f\u529b\u673a\u5236\u56e0\u5176\u9ad8\u5185\u5b58\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u6210\u4e3a\u8ba1\u7b97\u74f6\u9888\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u5b9e\u9645\u80fd\u6e90\u4f7f\u7528\u548c\u786c\u4ef6\u9700\u6c42\u7684\u4e25\u683c\u8bc4\u4f30\u3002", "method": "\u5728GPT-2\u67b6\u6784\u8bad\u7ec3\u4e2d\uff0c\u5bf9\u516b\u79cd\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6d4b\u91cf\u8bad\u7ec3\u65f6\u95f4\u3001GPU\u5185\u5b58\u4f7f\u7528\u3001FLOPS\u3001CPU\u4f7f\u7528\u548c\u529f\u8017\u7b49\u5173\u952e\u6307\u6807\u3002", "result": "\u4f18\u5316\u5185\u6838\u5b9e\u73b0\u7684\u6ce8\u610f\u529b\u673a\u5236\uff08\u5982Flash Attention\u3001LSH Attention\u548cMLA\uff09\u80fd\u6548\u6700\u4f73\uff0c\u4e14\u4ec5\u964d\u4f4eGPU\u529f\u8017\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u51cf\u5c11\u80fd\u6e90\u4f7f\u7528\uff0c\u8bad\u7ec3\u65f6\u95f4\u540c\u6837\u91cd\u8981\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u80fd\u6e90\u611f\u77e5\u57fa\u51c6\u6d4b\u8bd5\u5728\u6ce8\u610f\u529b\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u9009\u62e9\u8d44\u6e90\u9ad8\u6548\u673a\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2507.07794", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07794", "abs": "https://arxiv.org/abs/2507.07794", "authors": ["Zhe Han", "Huanyu Tian", "Tom Vercauteren", "Da Liu", "Changsheng Li", "Xingguang Duan"], "title": "Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy: Optical Tracking based Approach", "comment": null, "summary": "Mandibular Angle Split Osteotomy (MASO) is a significant procedure in oral\nand maxillofacial surgery. Despite advances in technique and instrumentation,\nits success still relies heavily on the surgeon's experience. In this work, a\nhuman-robot collaborative system is proposed to perform MASO according to a\npreoperative plan and under guidance of a surgeon. A task decomposition\nmethodology is used to divide the collaborative surgical procedure into three\nsubtasks: (1) positional control and (2) orientation control, both led by the\nrobot for precise alignment; and (3) force-control, managed by surgeon to\nensure safety. Additionally, to achieve patient tracking without the need for a\nskull clamp, an optical tracking system (OTS) is utilized. Movement of the\npatient mandibular is measured with an optical-based tracker mounted on a\ndental occlusal splint. A registration method and Robot-OTS calibration method\nare introduced to achieve reliable navigation within our framework. The\nexperiments of drilling were conducted on the realistic phantom model, which\ndemonstrated that the average error between the planned and actual drilling\npoints is 1.85mm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4eba\u673a\u534f\u4f5c\u7cfb\u7edf\u7528\u4e8e\u4e0b\u988c\u89d2\u5288\u5f00\u622a\u9aa8\u672f\uff08MASO\uff09\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u548c\u5149\u5b66\u8ddf\u8e2a\u7cfb\u7edf\uff08OTS\uff09\u63d0\u9ad8\u624b\u672f\u7cbe\u786e\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u5c3d\u7ba1MASO\u6280\u672f\u548c\u5668\u68b0\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u5176\u6210\u529f\u4ecd\u9ad8\u5ea6\u4f9d\u8d56\u5916\u79d1\u533b\u751f\u7684\u7ecf\u9a8c\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u786e\u548c\u5b89\u5168\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u624b\u672f\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u4efb\u52a1\uff1a\u673a\u5668\u4eba\u4e3b\u5bfc\u7684\u4f4d\u7f6e\u548c\u65b9\u5411\u63a7\u5236\uff0c\u4ee5\u53ca\u5916\u79d1\u533b\u751f\u4e3b\u5bfc\u7684\u529b\u63a7\u5236\uff1b\u4f7f\u7528OTS\u8fdb\u884c\u60a3\u8005\u8ddf\u8e2a\uff0c\u65e0\u9700\u9885\u9aa8\u5939\u3002", "result": "\u5728\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0c\u8ba1\u5212\u4e0e\u5b9e\u9645\u94bb\u5b54\u70b9\u7684\u5e73\u5747\u8bef\u5dee\u4e3a1.85mm\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u548cOTS\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684MASO\u624b\u672f\uff0c\u51cf\u5c11\u4e86\u5bf9\u5916\u79d1\u533b\u751f\u7ecf\u9a8c\u7684\u4f9d\u8d56\u3002"}}
{"id": "2507.07259", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07259", "abs": "https://arxiv.org/abs/2507.07259", "authors": ["Giulio Rossolini", "Fabio Brau", "Alessandro Biondi", "Battista Biggio", "Giorgio Buttazzo"], "title": "Exploiting Edge Features for Transferable Adversarial Attacks in Distributed Machine Learning", "comment": "under review", "summary": "As machine learning models become increasingly deployed across the edge of\ninternet of things environments, a partitioned deep learning paradigm in which\nmodels are split across multiple computational nodes introduces a new dimension\nof security risk. Unlike traditional inference setups, these distributed\npipelines span the model computation across heterogeneous nodes and\ncommunication layers, thereby exposing a broader attack surface to potential\nadversaries. Building on these motivations, this work explores a previously\noverlooked vulnerability: even when both the edge and cloud components of the\nmodel are inaccessible (i.e., black-box), an adversary who intercepts the\nintermediate features transmitted between them can still pose a serious threat.\nWe demonstrate that, under these mild and realistic assumptions, an attacker\ncan craft highly transferable proxy models, making the entire deep learning\nsystem significantly more vulnerable to evasion attacks. In particular, the\nintercepted features can be effectively analyzed and leveraged to distill\nsurrogate models capable of crafting highly transferable adversarial examples\nagainst the target model. To this end, we propose an exploitation strategy\nspecifically designed for distributed settings, which involves reconstructing\nthe original tensor shape from vectorized transmitted features using simple\nstatistical analysis, and adapting surrogate architectures accordingly to\nenable effective feature distillation. A comprehensive and systematic\nexperimental evaluation has been conducted to demonstrate that surrogate models\ntrained with the proposed strategy, i.e., leveraging intermediate features,\ntremendously improve the transferability of adversarial attacks. These findings\nunderscore the urgent need to account for intermediate feature leakage in the\ndesign of secure distributed deep learning systems.", "AI": {"tldr": "\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u5b58\u5728\u4e2d\u95f4\u7279\u5f81\u6cc4\u9732\u7684\u5b89\u5168\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u62e6\u622a\u548c\u5206\u6790\u4e2d\u95f4\u7279\u5f81\u6784\u5efa\u4ee3\u7406\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u6297\u653b\u51fb\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7269\u8054\u7f51\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u8ba1\u7b97\u5206\u5272\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5c24\u5176\u662f\u4e2d\u95f4\u7279\u5f81\u6cc4\u9732\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u5206\u5e03\u5f0f\u73af\u5883\u7684\u653b\u51fb\u7b56\u7565\uff0c\u901a\u8fc7\u7edf\u8ba1\u5206\u6790\u91cd\u6784\u4f20\u8f93\u4e2d\u7684\u4e2d\u95f4\u7279\u5f81\u5f20\u91cf\u5f62\u72b6\uff0c\u5e76\u8bbe\u8ba1\u4ee3\u7406\u6a21\u578b\u67b6\u6784\u4ee5\u6709\u6548\u84b8\u998f\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5229\u7528\u4e2d\u95f4\u7279\u5f81\u8bad\u7ec3\u7684\u4ee3\u7406\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u6297\u653b\u51fb\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "conclusion": "\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u4e9f\u9700\u8003\u8651\u4e2d\u95f4\u7279\u5f81\u6cc4\u9732\u7684\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2507.07825", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07825", "abs": "https://arxiv.org/abs/2507.07825", "authors": ["Leixin Chang", "Yuxuan Nai", "Hua Chen", "Liangjing Yang"], "title": "Beyond Robustness: Learning Unknown Dynamic Load Adaptation for Quadruped Locomotion on Rough Terrain", "comment": "Accepted to the 2025 IEEE International Conference on Robotics &\n  Automation (ICRA). 8 pages, 8 figures", "summary": "Unknown dynamic load carrying is one important practical application for\nquadruped robots. Such a problem is non-trivial, posing three major challenges\nin quadruped locomotion control. First, how to model or represent the dynamics\nof the load in a generic manner. Second, how to make the robot capture the\ndynamics without any external sensing. Third, how to enable the robot to\ninteract with load handling the mutual effect and stabilizing the load. In this\nwork, we propose a general load modeling approach called load characteristics\nmodeling to capture the dynamics of the load. We integrate this proposed\nmodeling technique and leverage recent advances in Reinforcement Learning (RL)\nbased locomotion control to enable the robot to infer the dynamics of load\nmovement and interact with the load indirectly to stabilize it and realize the\nsim-to-real deployment to verify its effectiveness in real scenarios. We\nconduct extensive comparative simulation experiments to validate the\neffectiveness and superiority of our proposed method. Results show that our\nmethod outperforms other methods in sudden load resistance, load stabilizing\nand locomotion with heavy load on rough terrain.\n\\href{https://leixinjonaschang.github.io/leggedloadadapt.github.io/}{Project\nPage}.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u8d1f\u8f7d\u5efa\u6a21\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\uff0c\u4f7f\u56db\u8db3\u673a\u5668\u4eba\u80fd\u591f\u63a8\u65ad\u8d1f\u8f7d\u52a8\u6001\u5e76\u7a33\u5b9a\u8d1f\u8f7d\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u89e3\u51b3\u56db\u8db3\u673a\u5668\u4eba\u5728\u672a\u77e5\u52a8\u6001\u8d1f\u8f7d\u4e0b\u7684\u5efa\u6a21\u3001\u611f\u77e5\u548c\u4ea4\u4e92\u95ee\u9898\uff0c\u63d0\u5347\u5176\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u8d1f\u8f7d\u7279\u6027\u5efa\u6a21\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\uff0c\u5b9e\u73b0\u8d1f\u8f7d\u52a8\u6001\u63a8\u65ad\u548c\u7a33\u5b9a\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7a81\u7136\u8d1f\u8f7d\u62b5\u6297\u3001\u8d1f\u8f7d\u7a33\u5b9a\u548c\u590d\u6742\u5730\u5f62\u91cd\u8f7d\u8fd0\u52a8\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u56db\u8db3\u673a\u5668\u4eba\u5728\u672a\u77e5\u52a8\u6001\u8d1f\u8f7d\u4e0b\u7684\u63a7\u5236\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u4ece\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u90e8\u7f72\u3002"}}
{"id": "2507.07261", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.07261", "abs": "https://arxiv.org/abs/2507.07261", "authors": ["Chunzhuo Wang", "Hans Hallez", "Bart Vanrumste"], "title": "Robust Multimodal Learning Framework For Intake Gesture Detection Using Contactless Radar and Wearable IMU Sensors", "comment": "This manuscript has been submitted to a peer-reviewed journal and is\n  currently under review", "summary": "Automated food intake gesture detection plays a vital role in dietary\nmonitoring, enabling objective and continuous tracking of eating behaviors to\nsupport better health outcomes. Wrist-worn inertial measurement units (IMUs)\nhave been widely used for this task with promising results. More recently,\ncontactless radar sensors have also shown potential. This study explores\nwhether combining wearable and contactless sensing modalities through\nmultimodal learning can further improve detection performance. We also address\na major challenge in multimodal learning: reduced robustness when one modality\nis missing. To this end, we propose a robust multimodal temporal convolutional\nnetwork with cross-modal attention (MM-TCN-CMA), designed to integrate IMU and\nradar data, enhance gesture detection, and maintain performance under missing\nmodality conditions. A new dataset comprising 52 meal sessions (3,050 eating\ngestures and 797 drinking gestures) from 52 participants is developed and made\npublicly available. Experimental results show that the proposed framework\nimproves the segmental F1-score by 4.3% and 5.2% over unimodal Radar and IMU\nmodels, respectively. Under missing modality scenarios, the framework still\nachieves gains of 1.3% and 2.4% for missing radar and missing IMU inputs. This\nis the first study to demonstrate a robust multimodal learning framework that\neffectively fuses IMU and radar data for food intake gesture detection.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408IMU\u548c\u96f7\u8fbe\u6570\u636e\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff08MM-TCN-CMA\uff09\uff0c\u7528\u4e8e\u98df\u7269\u6444\u5165\u624b\u52bf\u68c0\u6d4b\uff0c\u5e76\u5728\u7f3a\u5931\u6a21\u6001\u60c5\u51b5\u4e0b\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u901a\u8fc7\u591a\u6a21\u6001\u5b66\u4e60\u7ed3\u5408\u53ef\u7a7f\u6234\u548c\u63a5\u89e6\u5f0f\u4f20\u611f\u5668\uff0c\u63d0\u5347\u98df\u7269\u6444\u5165\u624b\u52bf\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faMM-TCN-CMA\u6846\u67b6\uff0c\u6574\u5408IMU\u548c\u96f7\u8fbe\u6570\u636e\uff0c\u91c7\u7528\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u7f3a\u5931\u6a21\u6001\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u6bd4\u5355\u6a21\u6001\u6a21\u578b\u6027\u80fd\u63d0\u53474.3%-5.2%\uff0c\u5728\u7f3a\u5931\u6a21\u6001\u65f6\u4ecd\u4fdd\u63011.3%-2.4%\u7684\u589e\u76ca\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5c55\u793a\u4e86\u7ed3\u5408IMU\u548c\u96f7\u8fbe\u6570\u636e\u7684\u9c81\u68d2\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u98df\u7269\u6444\u5165\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2507.07845", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07845", "abs": "https://arxiv.org/abs/2507.07845", "authors": ["David Warutumo", "Ciira wa Maina"], "title": "Perceptual Distortions and Autonomous Representation Learning in a Minimal Robotic System", "comment": "2 authors, 23 pages, 11 figures", "summary": "Autonomous agents, particularly in the field of robotics, rely on sensory\ninformation to perceive and navigate their environment. However, these sensory\ninputs are often imperfect, leading to distortions in the agent's internal\nrepresentation of the world. This paper investigates the nature of these\nperceptual distortions and how they influence autonomous representation\nlearning using a minimal robotic system. We utilize a simulated two-wheeled\nrobot equipped with distance sensors and a compass, operating within a simple\nsquare environment. Through analysis of the robot's sensor data during random\nexploration, we demonstrate how a distorted perceptual space emerges. Despite\nthese distortions, we identify emergent structures within the perceptual space\nthat correlate with the physical environment, revealing how the robot\nautonomously learns a structured representation for navigation without explicit\nspatial information. This work contributes to the understanding of embodied\ncognition, minimal agency, and the role of perception in self-generated\nnavigation strategies in artificial life.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u611f\u77e5\u5931\u771f\u5982\u4f55\u5f71\u54cd\u81ea\u4e3b\u673a\u5668\u4eba\u7684\u8868\u793a\u5b66\u4e60\uff0c\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u5c55\u793a\u4e86\u673a\u5668\u4eba\u5982\u4f55\u5728\u5931\u771f\u611f\u77e5\u4e2d\u5b66\u4e60\u5bfc\u822a\u7b56\u7565\u3002", "motivation": "\u63a2\u7d22\u611f\u77e5\u5931\u771f\u5bf9\u81ea\u4e3b\u673a\u5668\u4eba\u5185\u90e8\u4e16\u754c\u8868\u793a\u7684\u5f71\u54cd\uff0c\u4ee5\u7406\u89e3\u5176\u5728\u5bfc\u822a\u4e2d\u7684\u89d2\u8272\u3002", "method": "\u4f7f\u7528\u6a21\u62df\u53cc\u8f6e\u673a\u5668\u4eba\uff0c\u914d\u5907\u8ddd\u79bb\u4f20\u611f\u5668\u548c\u6307\u5357\u9488\uff0c\u5728\u65b9\u5f62\u73af\u5883\u4e2d\u968f\u673a\u63a2\u7d22\uff0c\u5206\u6790\u5176\u4f20\u611f\u5668\u6570\u636e\u3002", "result": "\u53d1\u73b0\u5c3d\u7ba1\u5b58\u5728\u611f\u77e5\u5931\u771f\uff0c\u673a\u5668\u4eba\u4ecd\u80fd\u81ea\u4e3b\u5b66\u4e60\u4e0e\u7269\u7406\u73af\u5883\u76f8\u5173\u7684\u7ed3\u6784\u5316\u8868\u793a\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5177\u8eab\u8ba4\u77e5\u548c\u6700\u5c0f\u4ee3\u7406\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u63ed\u793a\u4e86\u611f\u77e5\u5728\u81ea\u4e3b\u5bfc\u822a\u7b56\u7565\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2507.07271", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07271", "abs": "https://arxiv.org/abs/2507.07271", "authors": ["Julianna Piskorz", "Krzysztof Kacprzyk", "Mihaela van der Schaar"], "title": "Beyond the ATE: Interpretable Modelling of Treatment Effects over Dose and Time", "comment": "Presented at the Actionable Interpretability Workshop at ICML 2025", "summary": "The Average Treatment Effect (ATE) is a foundational metric in causal\ninference, widely used to assess intervention efficacy in randomized controlled\ntrials (RCTs). However, in many applications -- particularly in healthcare --\nthis static summary fails to capture the nuanced dynamics of treatment effects\nthat vary with both dose and time. We propose a framework for modelling\ntreatment effect trajectories as smooth surfaces over dose and time, enabling\nthe extraction of clinically actionable insights such as onset time, peak\neffect, and duration of benefit. To ensure interpretability, robustness, and\nverifiability -- key requirements in high-stakes domains -- we adapt\nSemanticODE, a recent framework for interpretable trajectory modelling, to the\ncausal setting where treatment effects are never directly observed. Our\napproach decouples the estimation of trajectory shape from the specification of\nclinically relevant properties (e.g., maxima, inflection points), supporting\ndomain-informed priors, post-hoc editing, and transparent analysis. We show\nthat our method yields accurate, interpretable, and editable models of\ntreatment dynamics, facilitating both rigorous causal analysis and practical\ndecision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5efa\u6a21\u5242\u91cf\u548c\u65f6\u95f4\u53d8\u5316\u7684\u6cbb\u7597\u6548\u679c\u8f68\u8ff9\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u7a33\u5065\u6027\uff0c\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u7684\u533b\u7597\u9886\u57df\u3002", "motivation": "\u4f20\u7edf\u7684\u5e73\u5747\u6cbb\u7597\u6548\u679c\uff08ATE\uff09\u65e0\u6cd5\u6355\u6349\u5242\u91cf\u548c\u65f6\u95f4\u53d8\u5316\u7684\u52a8\u6001\u6548\u679c\uff0c\u9650\u5236\u4e86\u5728\u533b\u7597\u7b49\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528SemanticODE\u6846\u67b6\uff0c\u5c06\u5176\u9002\u914d\u5230\u56e0\u679c\u63a8\u65ad\u573a\u666f\uff0c\u652f\u6301\u9886\u57df\u5148\u9a8c\u548c\u540e\u9a8c\u7f16\u8f91\uff0c\u5206\u79bb\u8f68\u8ff9\u5f62\u72b6\u4f30\u8ba1\u4e0e\u4e34\u5e8a\u76f8\u5173\u5c5e\u6027\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u7f16\u8f91\u5730\u5efa\u6a21\u6cbb\u7597\u52a8\u6001\uff0c\u652f\u6301\u4e25\u683c\u7684\u56e0\u679c\u5206\u6790\u548c\u5b9e\u9645\u51b3\u7b56\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u52a8\u6001\u6cbb\u7597\u6548\u679c\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u517c\u5177\u79d1\u5b66\u4e25\u8c28\u6027\u548c\u4e34\u5e8a\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.07846", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07846", "abs": "https://arxiv.org/abs/2507.07846", "authors": ["Kavindie Katuwandeniya", "Samith Rajapaksha Jayasekara Widhanapathirana"], "title": "ROS Help Desk: GenAI Powered, User-Centric Framework for ROS Error Diagnosis and Debugging", "comment": null, "summary": "As the robotics systems increasingly integrate into daily life, from smart\nhome assistants to the new-wave of industrial automation systems (Industry\n4.0), there's an increasing need to bridge the gap between complex robotic\nsystems and everyday users. The Robot Operating System (ROS) is a flexible\nframework often utilised in writing robot software, providing tools and\nlibraries for building complex robotic systems. However, ROS's distributed\narchitecture and technical messaging system create barriers for understanding\nrobot status and diagnosing errors. This gap can lead to extended maintenance\ndowntimes, as users with limited ROS knowledge may struggle to quickly diagnose\nand resolve system issues. Moreover, this deficit in expertise often delays\nproactive maintenance and troubleshooting, further increasing the frequency and\nduration of system interruptions. ROS Help Desk provides intuitive error\nexplanations and debugging support, dynamically customized to users of varying\nexpertise levels. It features user-centric debugging tools that simplify error\ndiagnosis, implements proactive error detection capabilities to reduce\ndowntime, and integrates multimodal data processing for comprehensive system\nstate understanding across multi-sensor data (e.g., lidar, RGB). Testing\nqualitatively and quantitatively with artificially induced errors demonstrates\nthe system's ability to proactively and accurately diagnose problems,\nultimately reducing maintenance time and fostering more effective human-robot\ncollaboration.", "AI": {"tldr": "ROS Help Desk\u901a\u8fc7\u76f4\u89c2\u7684\u9519\u8bef\u89e3\u91ca\u548c\u8c03\u8bd5\u652f\u6301\uff0c\u964d\u4f4e\u4e86ROS\u7cfb\u7edf\u7684\u7ef4\u62a4\u65f6\u95f4\uff0c\u63d0\u5347\u4e86\u4eba\u673a\u534f\u4f5c\u6548\u7387\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u7cfb\u7edf\u878d\u5165\u65e5\u5e38\u751f\u6d3b\u548c\u5de5\u4e1a\u81ea\u52a8\u5316\uff0cROS\u7684\u590d\u6742\u67b6\u6784\u548c\u6280\u672f\u6d88\u606f\u7cfb\u7edf\u5bf9\u666e\u901a\u7528\u6237\u6784\u6210\u969c\u788d\uff0c\u5bfc\u81f4\u7ef4\u62a4\u65f6\u95f4\u5ef6\u957f\u548c\u7cfb\u7edf\u4e2d\u65ad\u589e\u52a0\u3002", "method": "ROS Help Desk\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684\u8c03\u8bd5\u5de5\u5177\u3001\u4e3b\u52a8\u9519\u8bef\u68c0\u6d4b\u529f\u80fd\uff0c\u5e76\u96c6\u6210\u591a\u6a21\u6001\u6570\u636e\u5904\u7406\uff0c\u4ee5\u5168\u9762\u7406\u89e3\u7cfb\u7edf\u72b6\u6001\u3002", "result": "\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u4e3b\u52a8\u51c6\u786e\u8bca\u65ad\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u7ef4\u62a4\u65f6\u95f4\u3002", "conclusion": "ROS Help Desk\u6709\u6548\u89e3\u51b3\u4e86ROS\u7cfb\u7edf\u7684\u7528\u6237\u53cb\u597d\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u4eba\u673a\u534f\u4f5c\u6548\u7387\u3002"}}
{"id": "2507.07276", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.07276", "abs": "https://arxiv.org/abs/2507.07276", "authors": ["Aaron Foote", "Danny Krizanc"], "title": "TRIP: A Nonparametric Test to Diagnose Biased Feature Importance Scores", "comment": "Accepted at the Workshop on Explainable Artificial Intelligence (XAI)\n  at IJCAI 2025", "summary": "Along with accurate prediction, understanding the contribution of each\nfeature to the making of the prediction, i.e., the importance of the feature,\nis a desirable and arguably necessary component of a machine learning model.\nFor a complex model such as a random forest, such importances are not innate --\nas they are, e.g., with linear regression. Efficient methods have been created\nto provide such capabilities, with one of the most popular among them being\npermutation feature importance due to its efficiency, model-agnostic nature,\nand perceived intuitiveness. However, permutation feature importance has been\nshown to be misleading in the presence of dependent features as a result of the\ncreation of unrealistic observations when permuting the dependent features. In\nthis work, we develop TRIP (Test for Reliable Interpretation via Permutation),\na test requiring minimal assumptions that is able to detect unreliable\npermutation feature importance scores that are the result of model\nextrapolation. To build on this, we demonstrate how the test can be\ncomplemented in order to allow its use in high dimensional settings. Through\ntesting on simulated data and applications, our results show that the test can\nbe used to reliably detect when permutation feature importance scores are\nunreliable.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86TRIP\u6d4b\u8bd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u56e0\u7279\u5f81\u4f9d\u8d56\u5bfc\u81f4\u7684\u4e0d\u53ef\u9760\u7684\u7f6e\u6362\u7279\u5f81\u91cd\u8981\u6027\u5206\u6570\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u9ad8\u7ef4\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7406\u89e3\u7279\u5f81\u5bf9\u9884\u6d4b\u7684\u8d21\u732e\u662f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u91cd\u8981\u9700\u6c42\uff0c\u4f46\u7f6e\u6362\u7279\u5f81\u91cd\u8981\u6027\u5728\u7279\u5f81\u4f9d\u8d56\u65f6\u53ef\u80fd\u8bef\u5bfc\u3002", "method": "\u5f00\u53d1\u4e86TRIP\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5047\u8bbe\u68c0\u6d4b\u4e0d\u53ef\u9760\u7684\u7f6e\u6362\u7279\u5f81\u91cd\u8981\u6027\u5206\u6570\uff0c\u5e76\u6269\u5c55\u81f3\u9ad8\u7ef4\u8bbe\u7f6e\u3002", "result": "\u5728\u6a21\u62df\u6570\u636e\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cTRIP\u6d4b\u8bd5\u80fd\u53ef\u9760\u68c0\u6d4b\u7f6e\u6362\u7279\u5f81\u91cd\u8981\u6027\u7684\u4e0d\u53ef\u9760\u6027\u3002", "conclusion": "TRIP\u6d4b\u8bd5\u4e3a\u7f6e\u6362\u7279\u5f81\u91cd\u8981\u6027\u63d0\u4f9b\u4e86\u53ef\u9760\u6027\u9a8c\u8bc1\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u3002"}}
{"id": "2507.07872", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07872", "abs": "https://arxiv.org/abs/2507.07872", "authors": ["Daniel Betschinske", "Steven Peters"], "title": "Improving AEBS Validation Through Objective Intervention Classification Leveraging the Prediction Divergence Principle", "comment": "This work has been accepted for publication at the 2025 IEEE\n  International Automated Vehicle Validation Conference (IAVVC)", "summary": "The safety validation of automatic emergency braking system (AEBS) requires\naccurately distinguishing between false positive (FP) and true positive (TP)\nsystem activations. While simulations allow straightforward differentiation by\ncomparing scenarios with and without interventions, analyzing activations from\nopen-loop resimulations - such as those from field operational testing (FOT) -\nis more complex. This complexity arises from scenario parameter uncertainty and\nthe influence of driver interventions in the recorded data. Human labeling is\nfrequently used to address these challenges, relying on subjective assessments\nof intervention necessity or situational criticality, potentially introducing\nbiases and limitations. This work proposes a rule-based classification approach\nleveraging the Prediction Divergence Principle (PDP) to address those issues.\nApplied to a simplified AEBS, the proposed method reveals key strengths,\nlimitations, and system requirements for effective implementation. The findings\nsuggest that combining this approach with human labeling may enhance the\ntransparency and consistency of classification, thereby improving the overall\nvalidation process. While the rule set for classification derived in this work\nadopts a conservative approach, the paper outlines future directions for\nrefinement and broader applicability. Finally, this work highlights the\npotential of such methods to complement existing practices, paving the way for\nmore reliable and reproducible AEBS validation frameworks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u5206\u7c7b\u7684\u65b9\u6cd5\uff08PDP\uff09\u6765\u533a\u5206\u81ea\u52a8\u7d27\u6025\u5236\u52a8\u7cfb\u7edf\uff08AEBS\uff09\u7684\u8bef\u62a5\u548c\u771f\u5b9e\u6fc0\u6d3b\uff0c\u4ee5\u51cf\u5c11\u4eba\u4e3a\u6807\u6ce8\u7684\u4e3b\u89c2\u6027\uff0c\u5e76\u63d0\u9ad8\u9a8c\u8bc1\u7684\u900f\u660e\u5ea6\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u4e3a\u6807\u6ce8\uff0c\u5b58\u5728\u4e3b\u89c2\u6027\u548c\u504f\u5dee\uff0c\u9700\u8981\u66f4\u5ba2\u89c2\u7684\u5206\u7c7b\u65b9\u6cd5\u4ee5\u63d0\u9ad8AEBS\u9a8c\u8bc1\u7684\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u9884\u6d4b\u5206\u6b67\u539f\u5219\uff08PDP\uff09\u7684\u89c4\u5219\u5206\u7c7b\u65b9\u6cd5\uff0c\u5206\u6790AEBS\u7684\u6fc0\u6d3b\u60c5\u51b5\uff0c\u5e76\u7ed3\u5408\u4eba\u4e3a\u6807\u6ce8\u4ee5\u63d0\u9ad8\u5206\u7c7b\u6548\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5176\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u7cfb\u7edf\u5b9e\u73b0\u7684\u5173\u952e\u8981\u6c42\uff0c\u8868\u660e\u7ed3\u5408\u4eba\u4e3a\u6807\u6ce8\u53ef\u63d0\u5347\u5206\u7c7b\u7684\u900f\u660e\u5ea6\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aAEBS\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u91cd\u590d\u7684\u6846\u67b6\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u6269\u5c55\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2507.07288", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.07288", "abs": "https://arxiv.org/abs/2507.07288", "authors": ["Pierre Osselin", "Masaki Adachi", "Xiaowen Dong", "Michael A. Osborne"], "title": "Natural Evolutionary Search meets Probabilistic Numerics", "comment": "8 pages, 5 figures (24 pages, 11 figures including references and\n  appendices)", "summary": "Zeroth-order local optimisation algorithms are essential for solving\nreal-valued black-box optimisation problems. Among these, Natural Evolution\nStrategies (NES) represent a prominent class, particularly well-suited for\nscenarios where prior distributions are available. By optimising the objective\nfunction in the space of search distributions, NES algorithms naturally\nintegrate prior knowledge during initialisation, making them effective in\nsettings such as semi-supervised learning and user-prior belief frameworks.\nHowever, due to their reliance on random sampling and Monte Carlo estimates,\nNES algorithms can suffer from limited sample efficiency. In this paper, we\nintroduce a novel class of algorithms, termed Probabilistic Natural\nEvolutionary Strategy Algorithms (ProbNES), which enhance the NES framework\nwith Bayesian quadrature. We show that ProbNES algorithms consistently\noutperforms their non-probabilistic counterparts as well as global sample\nefficient methods such as Bayesian Optimisation (BO) or $\\pi$BO across a wide\nrange of tasks, including benchmark test functions, data-driven optimisation\ntasks, user-informed hyperparameter tuning tasks and locomotion tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5ProbNES\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u79ef\u5206\u589e\u5f3aNES\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u5e76\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u4f18\u4e8e\u975e\u6982\u7387\u65b9\u6cd5\u548c\u5168\u5c40\u6837\u672c\u9ad8\u6548\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfNES\u7b97\u6cd5\u56e0\u4f9d\u8d56\u968f\u673a\u91c7\u6837\u548c\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u800c\u5bfc\u81f4\u7684\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8d1d\u53f6\u65af\u79ef\u5206\u5230NES\u6846\u67b6\u4e2d\uff0c\u5f62\u6210ProbNES\u7b97\u6cd5\u3002", "result": "ProbNES\u5728\u57fa\u51c6\u6d4b\u8bd5\u51fd\u6570\u3001\u6570\u636e\u9a71\u52a8\u4f18\u5316\u3001\u7528\u6237\u4fe1\u606f\u8d85\u53c2\u6570\u8c03\u4f18\u548c\u8fd0\u52a8\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u975e\u6982\u7387\u65b9\u6cd5\u548c\u5168\u5c40\u6837\u672c\u9ad8\u6548\u65b9\u6cd5\u3002", "conclusion": "ProbNES\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u3002"}}
{"id": "2507.07980", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.07980", "abs": "https://arxiv.org/abs/2507.07980", "authors": ["Wanjia Fu", "Hongyu Li", "Ivy X. He", "Stefanie Tellex", "Srinath Sridhar"], "title": "UniTac: Whole-Robot Touch Sensing Without Tactile Sensors", "comment": null, "summary": "Robots can better interact with humans and unstructured environments through\ntouch sensing. However, most commercial robots are not equipped with tactile\nskins, making it challenging to achieve even basic touch-sensing functions,\nsuch as contact localization. We present UniTac, a data-driven whole-body\ntouch-sensing approach that uses only proprioceptive joint sensors and does not\nrequire the installation of additional sensors. Our approach enables a robot\nequipped solely with joint sensors to localize contacts. Our goal is to\ndemocratize touch sensing and provide an off-the-shelf tool for HRI researchers\nto provide their robots with touch-sensing capabilities. We validate our\napproach on two platforms: the Franka robot arm and the Spot quadruped. On\nFranka, we can localize contact to within 8.0 centimeters, and on Spot, we can\nlocalize to within 7.2 centimeters at around 2,000 Hz on an RTX 3090 GPU\nwithout adding any additional sensors to the robot. Project website:\nhttps://ivl.cs.brown.edu/research/unitac.", "AI": {"tldr": "UniTac\u662f\u4e00\u79cd\u4ec5\u4f7f\u7528\u672c\u4f53\u611f\u53d7\u5173\u8282\u4f20\u611f\u5668\u7684\u6570\u636e\u9a71\u52a8\u5168\u8eab\u89e6\u89c9\u611f\u77e5\u65b9\u6cd5\uff0c\u65e0\u9700\u989d\u5916\u4f20\u611f\u5668\u5373\u53ef\u5b9e\u73b0\u63a5\u89e6\u5b9a\u4f4d\u3002", "motivation": "\u5546\u7528\u673a\u5668\u4eba\u901a\u5e38\u7f3a\u4e4f\u89e6\u89c9\u76ae\u80a4\uff0c\u96be\u4ee5\u5b9e\u73b0\u57fa\u672c\u7684\u89e6\u89c9\u529f\u80fd\uff0c\u5982\u63a5\u89e6\u5b9a\u4f4d\u3002", "method": "\u5229\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u4ec5\u4f9d\u8d56\u5173\u8282\u4f20\u611f\u5668\u5b9e\u73b0\u89e6\u89c9\u611f\u77e5\u3002", "result": "\u5728Franka\u673a\u68b0\u81c2\u4e0a\u5b9a\u4f4d\u7cbe\u5ea6\u4e3a8.0\u5398\u7c73\uff0c\u5728Spot\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u4e3a7.2\u5398\u7c73\uff0c\u9891\u7387\u8fbe2000Hz\u3002", "conclusion": "UniTac\u4e3aHRI\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u4f20\u611f\u5668\u7684\u89e6\u89c9\u611f\u77e5\u5de5\u5177\u3002"}}
{"id": "2507.07291", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07291", "abs": "https://arxiv.org/abs/2507.07291", "authors": ["Paola Causin", "Alessio Marta"], "title": "Estimating Dataset Dimension via Singular Metrics under the Manifold Hypothesis: Application to Inverse Problems", "comment": null, "summary": "High-dimensional datasets often exhibit low-dimensional geometric structures,\nas suggested by the manifold hypothesis, which implies that data lie on a\nsmooth manifold embedded in a higher-dimensional ambient space. While this\ninsight underpins many advances in machine learning and inverse problems, fully\nleveraging it requires to deal with three key tasks: estimating the intrinsic\ndimension (ID) of the manifold, constructing appropriate local coordinates, and\nlearning mappings between ambient and manifold spaces. In this work, we propose\na framework that addresses all these challenges using a Mixture of Variational\nAutoencoders (VAEs) and tools from Riemannian geometry. We specifically focus\non estimating the ID of datasets by analyzing the numerical rank of the VAE\ndecoder pullback metric. The estimated ID guides the construction of an atlas\nof local charts using a mixture of invertible VAEs, enabling accurate manifold\nparameterization and efficient inference. We how this approach enhances\nsolutions to ill-posed inverse problems, particularly in biomedical imaging, by\nenforcing that reconstructions lie on the learned manifold. Lastly, we explore\nthe impact of network pruning on manifold geometry and reconstruction quality,\nshowing that the intrinsic dimension serves as an effective proxy for\nmonitoring model capacity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u548c\u9ece\u66fc\u51e0\u4f55\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f30\u8ba1\u6570\u636e\u96c6\u7684\u56fa\u6709\u7ef4\u5ea6\uff08ID\uff09\uff0c\u6784\u5efa\u5c40\u90e8\u5750\u6807\uff0c\u5e76\u5b66\u4e60\u73af\u5883\u4e0e\u6d41\u5f62\u7a7a\u95f4\u4e4b\u95f4\u7684\u6620\u5c04\uff0c\u4ee5\u89e3\u51b3\u9ad8\u7ef4\u6570\u636e\u4e2d\u7684\u4f4e\u7ef4\u51e0\u4f55\u7ed3\u6784\u95ee\u9898\u3002", "motivation": "\u9ad8\u7ef4\u6570\u636e\u901a\u5e38\u5177\u6709\u4f4e\u7ef4\u51e0\u4f55\u7ed3\u6784\uff08\u6d41\u5f62\u5047\u8bbe\uff09\uff0c\u4f46\u5982\u4f55\u6709\u6548\u5229\u7528\u8fd9\u4e00\u7ed3\u6784\u9700\u8981\u89e3\u51b3\u56fa\u6709\u7ef4\u5ea6\u4f30\u8ba1\u3001\u5c40\u90e8\u5750\u6807\u6784\u5efa\u548c\u7a7a\u95f4\u6620\u5c04\u5b66\u4e60\u7b49\u5173\u952e\u4efb\u52a1\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u548c\u9ece\u66fc\u51e0\u4f55\u5de5\u5177\uff0c\u901a\u8fc7\u5206\u6790VAE\u89e3\u7801\u5668\u56de\u62c9\u5ea6\u91cf\u7684\u6570\u503c\u79e9\u6765\u4f30\u8ba1\u56fa\u6709\u7ef4\u5ea6\uff0c\u5e76\u6784\u5efa\u5c40\u90e8\u5750\u6807\u56fe\u96c6\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u751f\u7269\u533b\u5b66\u6210\u50cf\u7b49\u4e0d\u9002\u5b9a\u9006\u95ee\u9898\u4e2d\u63d0\u9ad8\u4e86\u91cd\u5efa\u8d28\u91cf\uff0c\u5e76\u8868\u660e\u56fa\u6709\u7ef4\u5ea6\u53ef\u4f5c\u4e3a\u6a21\u578b\u5bb9\u91cf\u7684\u6709\u6548\u6307\u6807\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528\u6d41\u5f62\u7ed3\u6784\uff0c\u63d0\u5347\u9006\u95ee\u9898\u7684\u89e3\u51b3\u6548\u679c\uff0c\u540c\u65f6\u56fa\u6709\u7ef4\u5ea6\u7684\u4f30\u8ba1\u4e3a\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.07969", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.07969", "abs": "https://arxiv.org/abs/2507.07969", "authors": ["Qiyang Li", "Zhiyuan Zhou", "Sergey Levine"], "title": "Reinforcement Learning with Action Chunking", "comment": "25 pages, 15 figures", "summary": "We present Q-chunking, a simple yet effective recipe for improving\nreinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks.\nOur recipe is designed for the offline-to-online RL setting, where the goal is\nto leverage an offline prior dataset to maximize the sample-efficiency of\nonline learning. Effective exploration and sample-efficient learning remain\ncentral challenges in this setting, as it is not obvious how the offline data\nshould be utilized to acquire a good exploratory policy. Our key insight is\nthat action chunking, a technique popularized in imitation learning where\nsequences of future actions are predicted rather than a single action at each\ntimestep, can be applied to temporal difference (TD)-based RL methods to\nmitigate the exploration challenge. Q-chunking adopts action chunking by\ndirectly running RL in a 'chunked' action space, enabling the agent to (1)\nleverage temporally consistent behaviors from offline data for more effective\nonline exploration and (2) use unbiased $n$-step backups for more stable and\nefficient TD learning. Our experimental results demonstrate that Q-chunking\nexhibits strong offline performance and online sample efficiency, outperforming\nprior best offline-to-online methods on a range of long-horizon, sparse-reward\nmanipulation tasks.", "AI": {"tldr": "Q-chunking\u662f\u4e00\u79cd\u6539\u8fdb\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u6280\u672f\uff0c\u901a\u8fc7\u52a8\u4f5c\u5206\u5757\u63d0\u5347\u957f\u65f6\u7a0b\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u7684\u63a2\u7d22\u548c\u6837\u672c\u6548\u7387\u3002", "motivation": "\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5982\u4f55\u5229\u7528\u79bb\u7ebf\u6570\u636e\u63d0\u5347\u5728\u7ebf\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u548c\u63a2\u7d22\u80fd\u529b\u662f\u5173\u952e\u6311\u6218\u3002", "method": "Q-chunking\u5c06\u52a8\u4f5c\u5206\u5757\u6280\u672f\u5e94\u7528\u4e8e\u57fa\u4e8e\u65f6\u95f4\u5dee\u5206\uff08TD\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u76f4\u63a5\u5728\u5206\u5757\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u8fd0\u884cRL\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cQ-chunking\u5728\u79bb\u7ebf\u6027\u80fd\u548c\u5728\u7ebf\u6837\u672c\u6548\u7387\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Q-chunking\u4e3a\u957f\u65f6\u7a0b\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07292", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07292", "abs": "https://arxiv.org/abs/2507.07292", "authors": ["Jacob Hauck", "Yanzhi Zhang"], "title": "Discretization-independent multifidelity operator learning for partial differential equations", "comment": "33 pages, 9 figures, submitted to the Journal of Machine Learning\n  Research", "summary": "We develop a new and general encode-approximate-reconstruct operator learning\nmodel that leverages learned neural representations of bases for input and\noutput function distributions. We introduce the concepts of \\textit{numerical\noperator learning} and \\textit{discretization independence}, which clarify the\nrelationship between theoretical formulations and practical realizations of\noperator learning models. Our model is discretization-independent, making it\nparticularly effective for multifidelity learning. We establish theoretical\napproximation guarantees, demonstrating uniform universal approximation under\nstrong assumptions on the input functions and statistical approximation under\nweaker conditions. To our knowledge, this is the first comprehensive study that\ninvestigates how discretization independence enables robust and efficient\nmultifidelity operator learning. We validate our method through extensive\nnumerical experiments involving both local and nonlocal PDEs, including\ntime-independent and time-dependent problems. The results show that\nmultifidelity training significantly improves accuracy and computational\nefficiency. Moreover, multifidelity training further enhances empirical\ndiscretization independence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f16\u7801-\u8fd1\u4f3c-\u91cd\u6784\u7b97\u5b50\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528\u795e\u7ecf\u8868\u793a\u5b66\u4e60\u8f93\u5165\u548c\u8f93\u51fa\u51fd\u6570\u5206\u5e03\u7684\u57fa\uff0c\u652f\u6301\u79bb\u6563\u5316\u72ec\u7acb\u6027\u548c\u591a\u4fdd\u771f\u5ea6\u5b66\u4e60\u3002", "motivation": "\u7814\u7a76\u79bb\u6563\u5316\u72ec\u7acb\u6027\u5982\u4f55\u652f\u6301\u7a33\u5065\u9ad8\u6548\u7684\u591a\u4fdd\u771f\u5ea6\u7b97\u5b50\u5b66\u4e60\uff0c\u586b\u8865\u7406\u8bba\u4e0e\u5b9e\u9645\u5b9e\u73b0\u4e4b\u95f4\u7684\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u8868\u793a\u7684\u7f16\u7801-\u8fd1\u4f3c-\u91cd\u6784\u6a21\u578b\uff0c\u652f\u6301\u79bb\u6563\u5316\u72ec\u7acb\u6027\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u591a\u4fdd\u771f\u5ea6\u8bad\u7ec3\u663e\u8457\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u589e\u5f3a\u4e86\u79bb\u6563\u5316\u72ec\u7acb\u6027\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u591a\u4fdd\u771f\u5ea6\u7b97\u5b50\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u79bb\u6563\u5316\u72ec\u7acb\u6027\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.07316", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.07316", "abs": "https://arxiv.org/abs/2507.07316", "authors": ["Md Abrar Jahin", "Taufikur Rahman Fuad", "M. F. Mridha", "Nafiz Fahad", "Md. Jakir Hossen"], "title": "AdeptHEQ-FL: Adaptive Homomorphic Encryption for Federated Learning of Hybrid Classical-Quantum Models with Dynamic Layer Sparing", "comment": "Accepted in 1st International Workshop on ICCV'25 BISCUIT (Biomedical\n  Image and Signal Computing for Unbiasedness, Interpretability, and\n  Trustworthiness)", "summary": "Federated Learning (FL) faces inherent challenges in balancing model\nperformance, privacy preservation, and communication efficiency, especially in\nnon-IID decentralized environments. Recent approaches either sacrifice formal\nprivacy guarantees, incur high overheads, or overlook quantum-enhanced\nexpressivity. We introduce AdeptHEQ-FL, a unified hybrid classical-quantum FL\nframework that integrates (i) a hybrid CNN-PQC architecture for expressive\ndecentralized learning, (ii) an adaptive accuracy-weighted aggregation scheme\nleveraging differentially private validation accuracies, (iii) selective\nhomomorphic encryption (HE) for secure aggregation of sensitive model layers,\nand (iv) dynamic layer-wise adaptive freezing to minimize communication\noverhead while preserving quantum adaptability. We establish formal privacy\nguarantees, provide convergence analysis, and conduct extensive experiments on\nthe CIFAR-10, SVHN, and Fashion-MNIST datasets. AdeptHEQ-FL achieves a $\\approx\n25.43\\%$ and $\\approx 14.17\\%$ accuracy improvement over Standard-FedQNN and\nFHE-FedQNN, respectively, on the CIFAR-10 dataset. Additionally, it reduces\ncommunication overhead by freezing less important layers, demonstrating the\nefficiency and practicality of our privacy-preserving, resource-aware design\nfor FL.", "AI": {"tldr": "AdeptHEQ-FL\u662f\u4e00\u4e2a\u7ed3\u5408\u7ecf\u5178\u4e0e\u91cf\u5b50\u8ba1\u7b97\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408CNN-PQC\u67b6\u6784\u3001\u5dee\u5206\u9690\u79c1\u9a8c\u8bc1\u7cbe\u5ea6\u3001\u9009\u62e9\u6027\u540c\u6001\u52a0\u5bc6\u548c\u52a8\u6001\u5c42\u51bb\u7ed3\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u901a\u4fe1\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u73af\u5883\u4e2d\u6a21\u578b\u6027\u80fd\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u901a\u4fe1\u6548\u7387\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df7\u5408CNN-PQC\u67b6\u6784\u3001\u5dee\u5206\u9690\u79c1\u9a8c\u8bc1\u7cbe\u5ea6\u3001\u9009\u62e9\u6027\u540c\u6001\u52a0\u5bc6\u548c\u52a8\u6001\u5c42\u51bb\u7ed3\u6280\u672f\u3002", "result": "\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\uff0cAdeptHEQ-FL\u6bd4Standard-FedQNN\u548cFHE-FedQNN\u5206\u522b\u63d0\u9ad8\u4e86\u7ea625.43%\u548c14.17%\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "AdeptHEQ-FL\u5c55\u793a\u4e86\u9690\u79c1\u4fdd\u62a4\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u8bbe\u8ba1\u7684\u5b9e\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2507.07320", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07320", "abs": "https://arxiv.org/abs/2507.07320", "authors": ["Dongyu Wei", "Xiaoren Xu", "Shiwen Mao", "Mingzhe Chen"], "title": "Optimizing Communication and Device Clustering for Clustered Federated Learning with Differential Privacy", "comment": null, "summary": "In this paper, a secure and communication-efficient clustered federated\nlearning (CFL) design is proposed. In our model, several base stations (BSs)\nwith heterogeneous task-handling capabilities and multiple users with\nnon-independent and identically distributed (non-IID) data jointly perform CFL\ntraining incorporating differential privacy (DP) techniques. Since each BS can\nprocess only a subset of the learning tasks and has limited wireless resource\nblocks (RBs) to allocate to users for federated learning (FL) model parameter\ntransmission, it is necessary to jointly optimize RB allocation and user\nscheduling for CFL performance optimization. Meanwhile, our considered CFL\nmethod requires devices to use their limited data and FL model information to\ndetermine their task identities, which may introduce additional communication\noverhead. We formulate an optimization problem whose goal is to minimize the\ntraining loss of all learning tasks while considering device clustering, RB\nallocation, DP noise, and FL model transmission delay. To solve the problem, we\npropose a novel dynamic penalty function assisted value decomposed multi-agent\nreinforcement learning (DPVD-MARL) algorithm that enables distributed BSs to\nindependently determine their connected users, RBs, and DP noise of the\nconnected users but jointly minimize the training loss of all learning tasks\nacross all BSs. Different from the existing MARL methods that assign a large\npenalty for invalid actions, we propose a novel penalty assignment scheme that\nassigns penalty depending on the number of devices that cannot meet\ncommunication constraints (e.g., delay), which can guide the MARL scheme to\nquickly find valid actions, thus improving the convergence speed. Simulation\nresults show that the DPVD-MARL can improve the convergence rate by up to 20%\nand the ultimate accumulated rewards by 15% compared to independent Q-learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b89\u5168\u4e14\u901a\u4fe1\u9ad8\u6548\u7684\u96c6\u7fa4\u8054\u90a6\u5b66\u4e60\uff08CFL\uff09\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u6280\u672f\uff0c\u4f18\u5316\u8d44\u6e90\u5757\u5206\u914d\u548c\u7528\u6237\u8c03\u5ea6\uff0c\u5e76\u91c7\u7528\u52a8\u6001\u60e9\u7f5a\u51fd\u6570\u8f85\u52a9\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08DPVD-MARL\uff09\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6536\u655b\u901f\u5ea6\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u5f02\u6784\u57fa\u7ad9\u548c\u7528\u6237\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u4e0b\uff0c\u5982\u4f55\u4f18\u5316\u8d44\u6e90\u5206\u914d\u548c\u7528\u6237\u8c03\u5ea6\u4ee5\u63d0\u5347CFL\u6027\u80fd\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faDPVD-MARL\u7b97\u6cd5\uff0c\u52a8\u6001\u5206\u914d\u60e9\u7f5a\u51fd\u6570\uff0c\u5206\u5e03\u5f0f\u4f18\u5316\u8d44\u6e90\u5757\u5206\u914d\u3001\u7528\u6237\u8c03\u5ea6\u548cDP\u566a\u58f0\u3002", "result": "\u4eff\u771f\u663e\u793a\uff0cDPVD-MARL\u6bd4\u72ec\u7acbQ\u5b66\u4e60\u6536\u655b\u901f\u5ea6\u5feb20%\uff0c\u7d2f\u8ba1\u5956\u52b1\u9ad815%\u3002", "conclusion": "DPVD-MARL\u80fd\u6709\u6548\u4f18\u5316CFL\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5f02\u6784\u73af\u5883\u4e0b\u7684\u8054\u90a6\u5b66\u4e60\u4efb\u52a1\u3002"}}
{"id": "2507.07323", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07323", "abs": "https://arxiv.org/abs/2507.07323", "authors": ["Dongyu Wei", "Xiaoren Xu", "Yuchen Liu", "H. Vincent Poor", "Mingzhe Chen"], "title": "Optimizing Model Splitting and Device Task Assignment for Deceptive Signal Assisted Private Multi-hop Split Learning", "comment": null, "summary": "In this paper, deceptive signal-assisted private split learning is\ninvestigated. In our model, several edge devices jointly perform collaborative\ntraining, and some eavesdroppers aim to collect the model and data information\nfrom devices. To prevent the eavesdroppers from collecting model and data\ninformation, a subset of devices can transmit deceptive signals. Therefore, it\nis necessary to determine the subset of devices used for deceptive signal\ntransmission, the subset of model training devices, and the models assigned to\neach model training device. This problem is formulated as an optimization\nproblem whose goal is to minimize the information leaked to eavesdroppers while\nmeeting the model training energy consumption and delay constraints. To solve\nthis problem, we propose a soft actor-critic deep reinforcement learning\nframework with intrinsic curiosity module and cross-attention (ICM-CA) that\nenables a centralized agent to determine the model training devices, the\ndeceptive signal transmission devices, the transmit power, and sub-models\nassigned to each model training device without knowing the position and\nmonitoring probability of eavesdroppers. The proposed method uses an ICM module\nto encourage the server to explore novel actions and states and a CA module to\ndetermine the importance of each historical state-action pair thus improving\ntraining efficiency. Simulation results demonstrate that the proposed method\nimproves the convergence rate by up to 3x and reduces the information leaked to\neavesdroppers by up to 13% compared to the traditional SAC algorithm.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8fb9\u7f18\u8bbe\u5907\u534f\u4f5c\u8bad\u7ec3\u4e2d\uff0c\u901a\u8fc7\u53d1\u9001\u6b3a\u9a97\u4fe1\u53f7\u9632\u6b62\u7a83\u542c\u8005\u83b7\u53d6\u6a21\u578b\u548c\u6570\u636e\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u6846\u67b6\u3002", "motivation": "\u5728\u534f\u4f5c\u8bad\u7ec3\u4e2d\uff0c\u7a83\u542c\u8005\u53ef\u80fd\u83b7\u53d6\u654f\u611f\u4fe1\u606f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u4fdd\u62a4\u6a21\u578b\u548c\u6570\u636e\u7684\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5185\u5728\u597d\u5947\u5fc3\u6a21\u5757\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u7684\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff08ICM-CA\uff09\uff0c\u7528\u4e8e\u4f18\u5316\u8bbe\u5907\u9009\u62e9\u548c\u8d44\u6e90\u5206\u914d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edfSAC\u7b97\u6cd5\u6536\u655b\u901f\u5ea6\u5feb3\u500d\uff0c\u4fe1\u606f\u6cc4\u9732\u51cf\u5c1113%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u4fdd\u62a4\u534f\u4f5c\u8bad\u7ec3\u4e2d\u7684\u4fe1\u606f\u5b89\u5168\uff0c\u540c\u65f6\u6ee1\u8db3\u80fd\u8017\u548c\u5ef6\u8fdf\u7ea6\u675f\u3002"}}
{"id": "2507.07328", "categories": ["cs.LG", "cs.AI", "cs.CE", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2507.07328", "abs": "https://arxiv.org/abs/2507.07328", "authors": ["Malikussaid", "Hilal Hudan Nuha"], "title": "Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery", "comment": "42 pages, 8 figures, 1 equation, 2 algorithms, 31 tables, to be\n  published in ISPACS Conference 2025, unabridged version", "summary": "Large Language Models (LLMs) often generate scientifically plausible but\nfactually invalid information, a challenge we term the \"plausibility-validity\ngap,\" particularly in specialized domains like chemistry. This paper presents a\nsystematic methodology to bridge this gap by developing a specialized\nscientific assistant. We utilized the Magistral Small model, noted for its\nintegrated reasoning capabilities, and fine-tuned it using Low-Rank Adaptation\n(LoRA). A key component of our approach was the creation of a \"dual-domain\ndataset,\" a comprehensive corpus curated from various sources encompassing both\nmolecular properties and chemical reactions, which was standardized to ensure\nquality. Our evaluation demonstrates that the fine-tuned model achieves\nsignificant improvements over the baseline model in format adherence, chemical\nvalidity of generated molecules, and the feasibility of proposed synthesis\nroutes. The results indicate a hierarchical learning pattern, where syntactic\ncorrectness is learned more readily than chemical possibility and synthesis\nfeasibility. While a comparative analysis with human experts revealed\ncompetitive performance in areas like chemical creativity and reasoning, it\nalso highlighted key limitations, including persistent errors in\nstereochemistry, a static knowledge cutoff, and occasional reference\nhallucination. This work establishes a viable framework for adapting generalist\nLLMs into reliable, specialized tools for chemical research, while also\ndelineating critical areas for future improvement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03LLM\uff08Magistral Small\u6a21\u578b\uff09\u548c\u521b\u5efa\u53cc\u9886\u57df\u6570\u636e\u96c6\uff0c\u89e3\u51b3LLM\u5728\u5316\u5b66\u9886\u57df\u751f\u6210\u79d1\u5b66\u4e0a\u5408\u7406\u4f46\u4e8b\u5b9e\u65e0\u6548\u4fe1\u606f\u7684\u201c\u5408\u7406\u6027-\u6709\u6548\u6027\u5dee\u8ddd\u201d\u95ee\u9898\u3002", "motivation": "LLM\u5728\u4e13\u4e1a\u9886\u57df\uff08\u5982\u5316\u5b66\uff09\u4e2d\u5e38\u751f\u6210\u770b\u4f3c\u5408\u7406\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u4fe1\u606f\uff0c\u8fd9\u88ab\u79f0\u4e3a\u201c\u5408\u7406\u6027-\u6709\u6548\u6027\u5dee\u8ddd\u201d\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f00\u53d1\u4e13\u4e1a\u79d1\u5b66\u52a9\u624b\u6765\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528Magistral Small\u6a21\u578b\uff0c\u901a\u8fc7LoRA\u5fae\u8c03\uff0c\u5e76\u521b\u5efa\u53cc\u9886\u57df\u6570\u636e\u96c6\uff08\u6db5\u76d6\u5206\u5b50\u6027\u8d28\u548c\u5316\u5b66\u53cd\u5e94\uff09\uff0c\u6807\u51c6\u5316\u6570\u636e\u4ee5\u786e\u4fdd\u8d28\u91cf\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u683c\u5f0f\u4e00\u81f4\u6027\u3001\u5206\u5b50\u5316\u5b66\u6709\u6548\u6027\u53ca\u5408\u6210\u8def\u7ebf\u53ef\u884c\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u8868\u73b0\u51fa\u5c42\u6b21\u5b66\u4e60\u6a21\u5f0f\uff08\u8bed\u6cd5\u6b63\u786e\u6027\u4f18\u5148\u4e8e\u5316\u5b66\u53ef\u80fd\u6027\uff09\u3002\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u6bd4\uff0c\u6a21\u578b\u5728\u5316\u5b66\u521b\u9020\u529b\u548c\u63a8\u7406\u4e0a\u8868\u73b0\u7ade\u4e89\u6027\uff0c\u4f46\u4ecd\u5b58\u5728\u7acb\u4f53\u5316\u5b66\u9519\u8bef\u3001\u9759\u6001\u77e5\u8bc6\u622a\u6b62\u548c\u5076\u5c14\u7684\u53c2\u8003\u5e7b\u89c9\u7b49\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u4e3a\u5c06\u901a\u7528LLM\u8f6c\u5316\u4e3a\u53ef\u9760\u7684\u5316\u5b66\u7814\u7a76\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u884c\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u6539\u8fdb\u7684\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2507.07335", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07335", "abs": "https://arxiv.org/abs/2507.07335", "authors": ["Ankit Jyothish", "Ali Jannesari"], "title": "Leveraging Manifold Embeddings for Enhanced Graph Transformer Representations and Learning", "comment": null, "summary": "Graph transformers typically embed every node in a single Euclidean space,\nblurring heterogeneous topologies. We prepend a lightweight Riemannian\nmixture-of-experts layer that routes each node to various kinds of manifold,\nmixture of spherical, flat, hyperbolic - best matching its local structure.\nThese projections provide intrinsic geometric explanations to the latent space.\nInserted into a state-of-the-art ensemble graph transformer, this projector\nlifts accuracy by up to 3% on four node-classification benchmarks. The ensemble\nmakes sure that both euclidean and non-euclidean features are captured.\nExplicit, geometry-aware projection thus sharpens predictive power while making\ngraph representations more interpretable.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u9ece\u66fc\u6df7\u5408\u4e13\u5bb6\u5c42\uff0c\u5c06\u8282\u70b9\u6295\u5f71\u5230\u591a\u79cd\u6d41\u5f62\uff08\u7403\u5f62\u3001\u5e73\u5766\u3001\u53cc\u66f2\uff09\u4ee5\u5339\u914d\u5176\u5c40\u90e8\u7ed3\u6784\uff0c\u63d0\u5347\u4e86\u56fe\u53d8\u6362\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u56fe\u53d8\u6362\u5668\u5c06\u6240\u6709\u8282\u70b9\u5d4c\u5165\u5355\u4e00\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u6a21\u7cca\u4e86\u5f02\u6784\u62d3\u6251\u7ed3\u6784\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u51e0\u4f55\u8868\u793a\u3002", "method": "\u5728\u73b0\u6709\u56fe\u53d8\u6362\u5668\u524d\u6dfb\u52a0\u9ece\u66fc\u6df7\u5408\u4e13\u5bb6\u5c42\uff0c\u5c06\u8282\u70b9\u8def\u7531\u5230\u6700\u9002\u5408\u5176\u5c40\u90e8\u7ed3\u6784\u7684\u6d41\u5f62\uff08\u7403\u5f62\u3001\u5e73\u5766\u3001\u53cc\u66f2\uff09\u3002", "result": "\u5728\u56db\u4e2a\u8282\u70b9\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe3%\u3002", "conclusion": "\u51e0\u4f55\u611f\u77e5\u7684\u6295\u5f71\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u80fd\u529b\uff0c\u8fd8\u4f7f\u56fe\u8868\u793a\u66f4\u5177\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.07348", "categories": ["cs.LG", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2507.07348", "abs": "https://arxiv.org/abs/2507.07348", "authors": ["James Chapman", "Kedar Karhadkar", "Guido Montufar"], "title": "Zero-Shot Context Generalization in Reinforcement Learning from Few Training Contexts", "comment": "10 pages, 8 figures, 3 tables, submitted to Neurips 2025", "summary": "Deep reinforcement learning (DRL) has achieved remarkable success across\nmultiple domains, including competitive games, natural language processing, and\nrobotics. Despite these advancements, policies trained via DRL often struggle\nto generalize to evaluation environments with different parameters. This\nchallenge is typically addressed by training with multiple contexts and/or by\nleveraging additional structure in the problem. However, obtaining sufficient\ntraining data across diverse contexts can be impractical in real-world\napplications. In this work, we consider contextual Markov decision processes\n(CMDPs) with transition and reward functions that exhibit regularity in context\nparameters. We introduce the context-enhanced Bellman equation (CEBE) to\nimprove generalization when training on a single context. We prove both\nanalytically and empirically that the CEBE yields a first-order approximation\nto the Q-function trained across multiple contexts. We then derive context\nsample enhancement (CSE) as an efficient data augmentation method for\napproximating the CEBE in deterministic control environments. We numerically\nvalidate the performance of CSE in simulation environments, showcasing its\npotential to improve generalization in DRL.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff08CEBE\uff09\u548c\u4e0a\u4e0b\u6587\u6837\u672c\u589e\u5f3a\uff08CSE\uff09\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u5728\u5355\u4e00\u4e0a\u4e0b\u6587\u8bad\u7ec3\u4e2d\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1DRL\u5728\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5176\u7b56\u7565\u5728\u4e0d\u540c\u53c2\u6570\u8bc4\u4f30\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u4ecd\u7136\u6709\u9650\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u591a\u6837\u5316\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u901a\u8fc7\u5f15\u5165CEBE\u65b9\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5355\u4e00\u4e0a\u4e0b\u6587\u8bad\u7ec3\u4e2d\u8fd1\u4f3c\u591a\u4e0a\u4e0b\u6587Q\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u5e76\u8fdb\u4e00\u6b65\u5f00\u53d1\u4e86CSE\u4f5c\u4e3a\u6570\u636e\u589e\u5f3a\u6280\u672f\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0cCEBE\u80fd\u591f\u63d0\u4f9b\u591a\u4e0a\u4e0b\u6587Q\u51fd\u6570\u7684\u4e00\u9636\u8fd1\u4f3c\uff0cCSE\u5728\u786e\u5b9a\u6027\u63a7\u5236\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "CEBE\u548cCSE\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86DRL\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u5728\u6570\u636e\u6709\u9650\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.07354", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07354", "abs": "https://arxiv.org/abs/2507.07354", "authors": ["Farnam Mansouri", "Shai Ben-David"], "title": "Learning from positive and unlabeled examples -Finite size sample bounds", "comment": null, "summary": "PU (Positive Unlabeled) learning is a variant of supervised classification\nlearning in which the only labels revealed to the learner are of positively\nlabeled instances. PU learning arises in many real-world applications. Most\nexisting work relies on the simplifying assumptions that the positively labeled\ntraining data is drawn from the restriction of the data generating distribution\nto positively labeled instances and/or that the proportion of positively\nlabeled points (a.k.a. the class prior) is known apriori to the learner. This\npaper provides a theoretical analysis of the statistical complexity of PU\nlearning under a wider range of setups. Unlike most prior work, our study does\nnot assume that the class prior is known to the learner. We prove upper and\nlower bounds on the required sample sizes (of both the positively labeled and\nthe unlabeled samples).", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86PU\uff08\u6b63\u65e0\u6807\u8bb0\uff09\u5b66\u4e60\u7684\u7edf\u8ba1\u590d\u6742\u6027\uff0c\u653e\u5bbd\u4e86\u5df2\u77e5\u7c7b\u522b\u5148\u9a8c\u7684\u5047\u8bbe\uff0c\u5e76\u63d0\u4f9b\u4e86\u6837\u672c\u91cf\u7684\u4e0a\u4e0b\u754c\u3002", "motivation": "PU\u5b66\u4e60\u5728\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5047\u8bbe\u7c7b\u522b\u5148\u9a8c\u5df2\u77e5\u6216\u6b63\u6807\u8bb0\u6570\u636e\u5206\u5e03\u53d7\u9650\u3002\u672c\u6587\u65e8\u5728\u653e\u5bbd\u8fd9\u4e9b\u5047\u8bbe\uff0c\u7814\u7a76\u66f4\u5e7f\u6cdb\u573a\u666f\u4e0b\u7684\u7edf\u8ba1\u590d\u6742\u6027\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u4e86PU\u5b66\u4e60\u5728\u4e0d\u540c\u8bbe\u5b9a\u4e0b\u7684\u6837\u672c\u91cf\u9700\u6c42\uff0c\u672a\u5047\u8bbe\u7c7b\u522b\u5148\u9a8c\u5df2\u77e5\u3002", "result": "\u8bc1\u660e\u4e86\u6b63\u6807\u8bb0\u548c\u65e0\u6807\u8bb0\u6837\u672c\u91cf\u7684\u4e0a\u4e0b\u754c\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86PU\u5b66\u4e60\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.07359", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.07359", "abs": "https://arxiv.org/abs/2507.07359", "authors": ["Zheyu Zhang", "Jiayuan Dong", "Jie Liu", "Xun Huan"], "title": "Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning", "comment": "10 pages, 6 figures", "summary": "We present GO-CBED, a goal-oriented Bayesian framework for sequential causal\nexperimental design. Unlike conventional approaches that select interventions\naimed at inferring the full causal model, GO-CBED directly maximizes the\nexpected information gain (EIG) on user-specified causal quantities of\ninterest, enabling more targeted and efficient experimentation. The framework\nis both non-myopic, optimizing over entire intervention sequences, and\ngoal-oriented, targeting only model aspects relevant to the causal query. To\naddress the intractability of exact EIG computation, we introduce a variational\nlower bound estimator, optimized jointly through a transformer-based policy\nnetwork and normalizing flow-based variational posteriors. The resulting policy\nenables real-time decision-making via an amortized network. We demonstrate that\nGO-CBED consistently outperforms existing baselines across various causal\nreasoning and discovery tasks-including synthetic structural causal models and\nsemi-synthetic gene regulatory networks-particularly in settings with limited\nexperimental budgets and complex causal mechanisms. Our results highlight the\nbenefits of aligning experimental design objectives with specific research\ngoals and of forward-looking sequential planning.", "AI": {"tldr": "GO-CBED\u662f\u4e00\u4e2a\u76ee\u6807\u5bfc\u5411\u7684\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u7528\u4e8e\u5e8f\u5217\u56e0\u679c\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u76f4\u63a5\u6700\u5927\u5316\u7528\u6237\u6307\u5b9a\u56e0\u679c\u91cf\u7684\u4fe1\u606f\u589e\u76ca\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u65e8\u5728\u63a8\u65ad\u5b8c\u6574\u7684\u56e0\u679c\u6a21\u578b\uff0c\u800cGO-CBED\u4e13\u6ce8\u4e8e\u7528\u6237\u611f\u5174\u8da3\u7684\u56e0\u679c\u91cf\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u548c\u9488\u5bf9\u6027\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u53d8\u5206\u4e0b\u754c\u4f30\u8ba1\u5668\u548c\u57fa\u4e8eTransformer\u7684\u7b56\u7565\u7f51\u7edc\uff0c\u7ed3\u5408\u5f52\u4e00\u5316\u6d41\u53d8\u5206\u540e\u9a8c\uff0c\u5b9e\u73b0\u5b9e\u65f6\u51b3\u7b56\u3002", "result": "\u5728\u591a\u79cd\u56e0\u679c\u63a8\u7406\u548c\u53d1\u73b0\u4efb\u52a1\u4e2d\uff0cGO-CBED\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u5b9e\u9a8c\u9884\u7b97\u6709\u9650\u548c\u56e0\u679c\u673a\u5236\u590d\u6742\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "GO-CBED\u5c55\u793a\u4e86\u5c06\u5b9e\u9a8c\u8bbe\u8ba1\u76ee\u6807\u4e0e\u5177\u4f53\u7814\u7a76\u76ee\u6807\u5bf9\u9f50\u7684\u4f18\u52bf\uff0c\u4ee5\u53ca\u524d\u77bb\u6027\u5e8f\u5217\u89c4\u5212\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.07373", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07373", "abs": "https://arxiv.org/abs/2507.07373", "authors": ["Irsyad Adam", "Steven Swee", "Erika Yilin", "Ethan Ji", "William Speier", "Dean Wang", "Alex Bui", "Wei Wang", "Karol Watson", "Peipei Ping"], "title": "Atherosclerosis through Hierarchical Explainable Neural Network Analysis", "comment": null, "summary": "In this work, we study the problem pertaining to personalized classification\nof subclinical atherosclerosis by developing a hierarchical graph neural\nnetwork framework to leverage two characteristic modalities of a patient:\nclinical features within the context of the cohort, and molecular data unique\nto individual patients. Current graph-based methods for disease classification\ndetect patient-specific molecular fingerprints, but lack consistency and\ncomprehension regarding cohort-wide features, which are an essential\nrequirement for understanding pathogenic phenotypes across diverse\natherosclerotic trajectories. Furthermore, understanding patient subtypes often\nconsiders clinical feature similarity in isolation, without integration of\nshared pathogenic interdependencies among patients. To address these\nchallenges, we introduce ATHENA: Atherosclerosis Through Hierarchical\nExplainable Neural Network Analysis, which constructs a novel hierarchical\nnetwork representation through integrated modality learning; subsequently, it\noptimizes learned patient-specific molecular fingerprints that reflect\nindividual omics data, enforcing consistency with cohort-wide patterns. With a\nprimary clinical dataset of 391 patients, we demonstrate that this\nheterogeneous alignment of clinical features with molecular interaction\npatterns has significantly boosted subclinical atherosclerosis classification\nperformance across various baselines by up to 13% in area under the receiver\noperating curve (AUC) and 20% in F1 score. Taken together, ATHENA enables\nmechanistically-informed patient subtype discovery through explainable AI\n(XAI)-driven subnetwork clustering; this novel integration framework\nstrengthens personalized intervention strategies, thereby improving the\nprediction of atherosclerotic disease progression and management of their\nclinical actionable outcomes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6ATHENA\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u5206\u7c7b\u4e9a\u4e34\u5e8a\u52a8\u8109\u7ca5\u6837\u786c\u5316\uff0c\u6574\u5408\u4e34\u5e8a\u7279\u5f81\u548c\u5206\u5b50\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u75be\u75c5\u5206\u7c7b\u4e2d\u7f3a\u4e4f\u5bf9\u961f\u5217\u7279\u5f81\u7684\u4e00\u81f4\u6027\u548c\u7406\u89e3\uff0c\u4e14\u672a\u6574\u5408\u60a3\u8005\u95f4\u7684\u5171\u4eab\u81f4\u75c5\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u5f00\u53d1\u4e86ATHENA\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u7f51\u7edc\u8868\u793a\u548c\u6574\u5408\u6a21\u6001\u5b66\u4e60\uff0c\u4f18\u5316\u60a3\u8005\u7279\u5f02\u6027\u5206\u5b50\u6307\u7eb9\u3002", "result": "\u5728391\u540d\u60a3\u8005\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u5206\u7c7b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff08AUC\u63d0\u9ad813%\uff0cF1\u5206\u6570\u63d0\u9ad820%\uff09\u3002", "conclusion": "ATHENA\u901a\u8fc7\u53ef\u89e3\u91caAI\u9a71\u52a8\u7684\u5b50\u7f51\u7edc\u805a\u7c7b\uff0c\u652f\u6301\u4e2a\u6027\u5316\u5e72\u9884\u7b56\u7565\uff0c\u6539\u5584\u75be\u75c5\u9884\u6d4b\u548c\u7ba1\u7406\u3002"}}
{"id": "2507.07375", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.07375", "abs": "https://arxiv.org/abs/2507.07375", "authors": ["Zhiwei Zhang", "Hui Liu", "Xiaomin Li", "Zhenwei Dai", "Jingying Zeng", "Fali Wang", "Minhua Lin", "Ramraj Chandradevan", "Zhen Li", "Chen Luo", "Xianfeng Tang", "Qi He", "Suhang Wang"], "title": "Bradley-Terry and Multi-Objective Reward Modeling Are Complementary", "comment": null, "summary": "Reward models trained on human preference data have demonstrated strong\neffectiveness in aligning Large Language Models (LLMs) with human intent under\nthe framework of Reinforcement Learning from Human Feedback (RLHF). However,\nRLHF remains vulnerable to reward hacking, where the policy exploits\nimperfections in the reward function rather than genuinely learning the\nintended behavior. Although significant efforts have been made to mitigate\nreward hacking, they predominantly focus on and evaluate in-distribution\nscenarios, where the training and testing data for the reward model share the\nsame distribution. In this paper, we empirically show that state-of-the-art\nmethods struggle in more challenging out-of-distribution (OOD) settings. We\nfurther demonstrate that incorporating fine-grained multi-attribute scores\nhelps address this challenge. However, the limited availability of high-quality\ndata often leads to weak performance of multi-objective reward functions, which\ncan negatively impact overall performance and become the bottleneck. To address\nthis issue, we propose a unified reward modeling framework that jointly trains\nBradley--Terry (BT) single-objective and multi-objective regression-based\nreward functions using a shared embedding space. We theoretically establish a\nconnection between the BT loss and the regression objective and highlight their\ncomplementary benefits. Specifically, the regression task enhances the\nsingle-objective reward function's ability to mitigate reward hacking in\nchallenging OOD settings, while BT-based training improves the scoring\ncapability of the multi-objective reward function, enabling a 7B model to\noutperform a 70B baseline. Extensive experimental results demonstrate that our\nframework significantly improves both the robustness and the scoring\nperformance of reward models.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u5355\u76ee\u6807\u548c\u591a\u76ee\u6807\u5956\u52b1\u51fd\u6570\u6765\u63d0\u5347\u5956\u52b1\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u8bc4\u5206\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u5916\uff08OOD\uff09\u573a\u666f\u4e2d\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u4eba\u7c7b\u504f\u597d\u7684\u5956\u52b1\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff08RLHF\uff09\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u653b\u51fb\uff08reward hacking\uff09\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u5206\u5e03\u5916\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5956\u52b1\u5efa\u6a21\u6846\u67b6\uff0c\u8054\u5408\u8bad\u7ec3\u57fa\u4e8eBradley-Terry\uff08BT\uff09\u7684\u5355\u76ee\u6807\u5956\u52b1\u51fd\u6570\u548c\u57fa\u4e8e\u56de\u5f52\u7684\u591a\u76ee\u6807\u5956\u52b1\u51fd\u6570\uff0c\u5171\u4eab\u5d4c\u5165\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u8bc4\u5206\u6027\u80fd\uff0c7B\u6a21\u578b\u751a\u81f3\u4f18\u4e8e70B\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u5355\u76ee\u6807\u548c\u591a\u76ee\u6807\u5956\u52b1\u51fd\u6570\uff0c\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u5956\u52b1\u653b\u51fb\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u6a21\u578b\u5728\u5206\u5e03\u5916\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2507.07388", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07388", "abs": "https://arxiv.org/abs/2507.07388", "authors": ["Zesheng Liu", "Maryam Rahnemoonfar"], "title": "GRIT: Graph Transformer For Internal Ice Layer Thickness Prediction", "comment": "Accepted for 2025 IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS 2025)", "summary": "Gaining a deeper understanding of the thickness and variability of internal\nice layers in Radar imagery is essential in monitoring the snow accumulation,\nbetter evaluating ice dynamics processes, and minimizing uncertainties in\nclimate models. Radar sensors, capable of penetrating ice, capture detailed\nradargram images of internal ice layers. In this work, we introduce GRIT, graph\ntransformer for ice layer thickness. GRIT integrates an inductive geometric\ngraph learning framework with an attention mechanism, designed to map the\nrelationships between shallow and deeper ice layers. Compared to baseline graph\nneural networks, GRIT demonstrates consistently lower prediction errors. These\nresults highlight the attention mechanism's effectiveness in capturing temporal\nchanges across ice layers, while the graph transformer combines the strengths\nof transformers for learning long-range dependencies with graph neural networks\nfor capturing spatial patterns, enabling robust modeling of complex\nspatiotemporal dynamics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faGRIT\uff0c\u4e00\u79cd\u7ed3\u5408\u56fe\u5b66\u4e60\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u56fe\u53d8\u6362\u5668\uff0c\u7528\u4e8e\u9884\u6d4b\u51b0\u5c42\u539a\u5ea6\uff0c\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u56fe\u795e\u7ecf\u7f51\u7edc\u3002", "motivation": "\u901a\u8fc7\u96f7\u8fbe\u56fe\u50cf\u6df1\u5165\u4e86\u89e3\u51b0\u5c42\u539a\u5ea6\u548c\u53d8\u5316\u6027\uff0c\u5bf9\u76d1\u6d4b\u79ef\u96ea\u3001\u8bc4\u4f30\u51b0\u52a8\u529b\u5b66\u8fc7\u7a0b\u53ca\u51cf\u5c11\u6c14\u5019\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "GRIT\u7ed3\u5408\u5f52\u7eb3\u51e0\u4f55\u56fe\u5b66\u4e60\u6846\u67b6\u4e0e\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6620\u5c04\u6d45\u5c42\u4e0e\u6df1\u5c42\u51b0\u5c42\u5173\u7cfb\u3002", "result": "GRIT\u9884\u6d4b\u8bef\u5dee\u4f4e\u4e8e\u57fa\u7ebf\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u6355\u6349\u51b0\u5c42\u65f6\u95f4\u53d8\u5316\u3002", "conclusion": "\u56fe\u53d8\u6362\u5668\u7ed3\u5408\u4e86\u53d8\u6362\u5668\u7684\u957f\u7a0b\u4f9d\u8d56\u5b66\u4e60\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u7a7a\u95f4\u6a21\u5f0f\u6355\u6349\u80fd\u529b\uff0c\u80fd\u7a33\u5065\u5efa\u6a21\u590d\u6742\u65f6\u7a7a\u52a8\u6001\u3002"}}
{"id": "2507.07389", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.07389", "abs": "https://arxiv.org/abs/2507.07389", "authors": ["Zesheng Liu", "Maryam Rahnemoonfar"], "title": "ST-GRIT: Spatio-Temporal Graph Transformer For Internal Ice Layer Thickness Prediction", "comment": "Accepted for 2025 IEEE International Conference on Image Processing\n  (ICIP)", "summary": "Understanding the thickness and variability of internal ice layers in radar\nimagery is crucial for monitoring snow accumulation, assessing ice dynamics,\nand reducing uncertainties in climate models. Radar sensors, capable of\npenetrating ice, provide detailed radargram images of these internal layers. In\nthis work, we present ST-GRIT, a spatio-temporal graph transformer for ice\nlayer thickness, designed to process these radargrams and capture the\nspatiotemporal relationships between shallow and deep ice layers. ST-GRIT\nleverages an inductive geometric graph learning framework to extract local\nspatial features as feature embeddings and employs a series of temporal and\nspatial attention blocks separately to model long-range dependencies\neffectively in both dimensions. Experimental evaluation on radargram data from\nthe Greenland ice sheet demonstrates that ST-GRIT consistently outperforms\ncurrent state-of-the-art methods and other baseline graph neural networks by\nachieving lower root mean-squared error. These results highlight the advantages\nof self-attention mechanisms on graphs over pure graph neural networks,\nincluding the ability to handle noise, avoid oversmoothing, and capture\nlong-range dependencies. Moreover, the use of separate spatial and temporal\nattention blocks allows for distinct and robust learning of spatial\nrelationships and temporal patterns, providing a more comprehensive and\neffective approach.", "AI": {"tldr": "ST-GRIT\u662f\u4e00\u79cd\u65f6\u7a7a\u56fe\u53d8\u6362\u5668\uff0c\u7528\u4e8e\u4ece\u96f7\u8fbe\u56fe\u50cf\u4e2d\u63d0\u53d6\u51b0\u5c42\u539a\u5ea6\u4fe1\u606f\uff0c\u901a\u8fc7\u7a7a\u95f4\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u5757\u5206\u522b\u5efa\u6a21\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u51b0\u5c42\u539a\u5ea6\u53ca\u5176\u53d8\u5f02\u6027\u5bf9\u76d1\u6d4b\u79ef\u96ea\u3001\u8bc4\u4f30\u51b0\u52a8\u6001\u548c\u51cf\u5c11\u6c14\u5019\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faST-GRIT\uff0c\u7ed3\u5408\u51e0\u4f55\u56fe\u5b66\u4e60\u6846\u67b6\u63d0\u53d6\u5c40\u90e8\u7a7a\u95f4\u7279\u5f81\uff0c\u5e76\u5206\u522b\u4f7f\u7528\u65f6\u7a7a\u6ce8\u610f\u529b\u5757\u5efa\u6a21\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u683c\u9675\u5170\u51b0\u76d6\u96f7\u8fbe\u6570\u636e\u4e0a\uff0cST-GRIT\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5747\u65b9\u6839\u8bef\u5dee\u66f4\u4f4e\u3002", "conclusion": "ST-GRIT\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u6709\u6548\u5904\u7406\u566a\u58f0\u3001\u907f\u514d\u8fc7\u5e73\u6ed1\uff0c\u5e76\u80fd\u6355\u6349\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2507.07390", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07390", "abs": "https://arxiv.org/abs/2507.07390", "authors": ["Seonghyun Park", "Kiyoung Seong", "Soojung Yang", "Rafael G\u00f3mez-Bombarelli", "Sungsoo Ahn"], "title": "Learning Collective Variables from Time-lagged Generation", "comment": null, "summary": "Rare events such as state transitions are difficult to observe directly with\nmolecular dynamics simulations due to long timescales. Enhanced sampling\ntechniques overcome this by introducing biases along carefully chosen\nlow-dimensional features, known as collective variables (CVs), which capture\nthe slow degrees of freedom. Machine learning approaches (MLCVs) have automated\nCV discovery, but existing methods typically focus on discriminating\nmeta-stable states without fully encoding the detailed dynamics essential for\naccurate sampling. We propose TLC, a framework that learns CVs directly from\ntime-lagged conditions of a generative model. Instead of modeling the static\nBoltzmann distribution, TLC models a time-lagged conditional distribution\nyielding CVs to capture the slow dynamic behavior. We validate TLC on the\nAlanine Dipeptide system using two CV-based enhanced sampling tasks: (i)\nsteered molecular dynamics (SMD) and (ii) on-the-fly probability enhanced\nsampling (OPES), demonstrating equal or superior performance compared to\nexisting MLCV methods in both transition path sampling and state\ndiscrimination.", "AI": {"tldr": "TLC\u6846\u67b6\u901a\u8fc7\u4ece\u751f\u6210\u6a21\u578b\u7684\u65f6\u95f4\u6ede\u540e\u6761\u4ef6\u4e2d\u5b66\u4e60\u96c6\u4f53\u53d8\u91cf\uff08CVs\uff09\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u6355\u6349\u6162\u52a8\u6001\u884c\u4e3a\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u96be\u4ee5\u76f4\u63a5\u89c2\u5bdf\u7f55\u89c1\u4e8b\u4ef6\uff08\u5982\u72b6\u6001\u8f6c\u53d8\uff09\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728CV\u53d1\u73b0\u4e2d\u672a\u80fd\u5b8c\u5168\u7f16\u7801\u8be6\u7ec6\u52a8\u6001\u4fe1\u606f\u3002", "method": "TLC\u901a\u8fc7\u5efa\u6a21\u65f6\u95f4\u6ede\u540e\u6761\u4ef6\u5206\u5e03\u800c\u975e\u9759\u6001Boltzmann\u5206\u5e03\uff0c\u5b66\u4e60CVs\u4ee5\u6355\u6349\u6162\u52a8\u6001\u884c\u4e3a\uff0c\u5e76\u5728Alanine Dipeptide\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u3002", "result": "\u5728SMD\u548cOPES\u4efb\u52a1\u4e2d\uff0cTLC\u8868\u73b0\u51fa\u4e0e\u73b0\u6709MLCV\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "TLC\u4e3aCV\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u6355\u6349\u52a8\u6001\u884c\u4e3a\uff0c\u9002\u7528\u4e8e\u589e\u5f3a\u91c7\u6837\u4efb\u52a1\u3002"}}
{"id": "2507.07399", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07399", "abs": "https://arxiv.org/abs/2507.07399", "authors": ["Yuntian Liu", "Tao Zhu", "Xiaoyang Liu", "Yu Chen", "Zhaoxuan Liu", "Qingfeng Guo", "Jiashuo Zhang", "Kangjie Bao", "Tao Luo"], "title": "Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization", "comment": "Accepted to AI4Math@ICML25", "summary": "Statement autoformalization, the automated translation of statement from\nnatural language into formal languages, has become a subject of extensive\nresearch, yet the development of robust automated evaluation metrics remains\nlimited. Existing evaluation methods often lack semantic understanding, face\nchallenges with high computational costs, and are constrained by the current\nprogress of automated theorem proving. To address these issues, we propose GTED\n(Generalized Tree Edit Distance), a novel evaluation framework that first\nstandardizes formal statements and converts them into operator trees, then\ndetermines the semantic similarity using the eponymous GTED metric. On the\nminiF2F and ProofNet benchmarks, GTED outperforms all baseline metrics by\nachieving the highest accuracy and Kappa scores, thus providing the community\nwith a more faithful metric for automated evaluation. The code and experimental\nresults are available at https://github.com/XiaoyangLiu-sjtu/GTED.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGTED\u7684\u65b0\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5c06\u81ea\u7136\u8bed\u8a00\u8bed\u53e5\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u8bed\u8a00\uff0c\u5e76\u5728\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u53d7\u9650\u4e8e\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u7684\u8fdb\u5c55\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9c81\u68d2\u7684\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u3002", "method": "\u63d0\u51faGTED\u6846\u67b6\uff0c\u5c06\u5f62\u5f0f\u5316\u8bed\u53e5\u6807\u51c6\u5316\u5e76\u8f6c\u5316\u4e3a\u64cd\u4f5c\u6811\uff0c\u4f7f\u7528GTED\u5ea6\u91cf\u8ba1\u7b97\u8bed\u4e49\u76f8\u4f3c\u5ea6\u3002", "result": "\u5728miniF2F\u548cProofNet\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGTED\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u51c6\u786e\u7387\u548cKappa\u5206\u6570\u3002", "conclusion": "GTED\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u53ef\u9760\u7684\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\uff0c\u4ee3\u7801\u548c\u5b9e\u9a8c\u7ed3\u679c\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.07405", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07405", "abs": "https://arxiv.org/abs/2507.07405", "authors": ["Pengfei Jiao", "Jialong Ni", "Di Jin", "Xuan Guo", "Huan Liu", "Hongjiang Chen", "Yanxian Bi"], "title": "HGMP:Heterogeneous Graph Multi-Task Prompt Learning", "comment": "The 25th International Joint Conference on Artificial Intelligence\n  (IJCAI-25)", "summary": "The pre-training and fine-tuning methods have gained widespread attention in\nthe field of heterogeneous graph neural networks due to their ability to\nleverage large amounts of unlabeled data during the pre-training phase,\nallowing the model to learn rich structural features. However, these methods\nface the issue of a mismatch between the pre-trained model and downstream\ntasks, leading to suboptimal performance in certain application scenarios.\nPrompt learning methods have emerged as a new direction in heterogeneous graph\ntasks, as they allow flexible adaptation of task representations to address\ntarget inconsistency. Building on this idea, this paper proposes a novel\nmulti-task prompt framework for the heterogeneous graph domain, named HGMP.\nFirst, to bridge the gap between the pre-trained model and downstream tasks, we\nreformulate all downstream tasks into a unified graph-level task format. Next,\nwe address the limitations of existing graph prompt learning methods, which\nstruggle to integrate contrastive pre-training strategies in the heterogeneous\ngraph domain. We design a graph-level contrastive pre-training strategy to\nbetter leverage heterogeneous information and enhance performance in multi-task\nscenarios. Finally, we introduce heterogeneous feature prompts, which enhance\nmodel performance by refining the representation of input graph features.\nExperimental results on public datasets show that our proposed method adapts\nwell to various tasks and significantly outperforms baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHGMP\u7684\u591a\u4efb\u52a1\u63d0\u793a\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u9884\u8bad\u7ec3\u4e0e\u4e0b\u6e38\u4efb\u52a1\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7edf\u4e00\u4efb\u52a1\u683c\u5f0f\u3001\u5bf9\u6bd4\u9884\u8bad\u7ec3\u7b56\u7565\u548c\u7279\u5f81\u63d0\u793a\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u9884\u8bad\u7ec3\u4e0e\u5fae\u8c03\u65b9\u6cd5\u5728\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u4e0e\u4e0b\u6e38\u4efb\u52a1\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u63d0\u793a\u5b66\u4e60\u65b9\u6cd5\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "method": "\u63d0\u51faHGMP\u6846\u67b6\uff0c\u5305\u62ec\u7edf\u4e00\u4efb\u52a1\u683c\u5f0f\u3001\u8bbe\u8ba1\u56fe\u7ea7\u5bf9\u6bd4\u9884\u8bad\u7ec3\u7b56\u7565\u548c\u5f15\u5165\u5f02\u6784\u56fe\u7279\u5f81\u63d0\u793a\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHGMP\u80fd\u9002\u5e94\u591a\u79cd\u4efb\u52a1\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "HGMP\u901a\u8fc7\u591a\u4efb\u52a1\u63d0\u793a\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6784\u56fe\u4e2d\u7684\u4efb\u52a1\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.07432", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.07432", "abs": "https://arxiv.org/abs/2507.07432", "authors": ["Paul M. Riechers", "Thomas J. Elliott", "Adam S. Shai"], "title": "Neural networks leverage nominally quantum and post-quantum representations", "comment": null, "summary": "We show that deep neural networks, including transformers and RNNs,\npretrained as usual on next-token prediction, intrinsically discover and\nrepresent beliefs over 'quantum' and 'post-quantum' low-dimensional generative\nmodels of their training data -- as if performing iterative Bayesian updates\nover the latent state of this world model during inference as they observe more\ncontext. Notably, neural nets easily find these representation whereas there is\nno finite classical circuit that would do the job. The corresponding geometric\nrelationships among neural activations induced by different input sequences are\nfound to be largely independent of neural-network architecture. Each point in\nthis geometry corresponds to a history-induced probability density over all\npossible futures, and the relative displacement of these points reflects the\ndifference in mechanism and magnitude for how these distinct pasts affect the\nfuture.", "AI": {"tldr": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08\u5982Transformer\u548cRNN\uff09\u901a\u8fc7\u5e38\u89c4\u7684\u4e0b\u4e00\u8bcd\u9884\u6d4b\u9884\u8bad\u7ec3\uff0c\u80fd\u591f\u53d1\u73b0\u5e76\u8868\u8fbe\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u4f4e\u7ef4\u751f\u6210\u6a21\u578b\u7684\u4fe1\u5ff5\uff0c\u7c7b\u4f3c\u4e8e\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5bf9\u6f5c\u5728\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u8fed\u4ee3\u8d1d\u53f6\u65af\u66f4\u65b0\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u901a\u8fc7\u9884\u8bad\u7ec3\u5b66\u4e60\u5e76\u8868\u8fbe\u5bf9\u6570\u636e\u751f\u6210\u6a21\u578b\u7684\u4fe1\u5ff5\uff0c\u4ee5\u53ca\u8fd9\u79cd\u8868\u8fbe\u662f\u5426\u5177\u6709\u666e\u9002\u6027\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08\u5982Transformer\u548cRNN\uff09\u8fdb\u884c\u4e0b\u4e00\u8bcd\u9884\u6d4b\u9884\u8bad\u7ec3\uff0c\u5206\u6790\u5176\u6fc0\u6d3b\u51e0\u4f55\u5173\u7cfb\u3002", "result": "\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u53d1\u73b0\u4f4e\u7ef4\u751f\u6210\u6a21\u578b\u7684\u4fe1\u5ff5\u8868\u8fbe\uff0c\u4e14\u8fd9\u79cd\u8868\u8fbe\u4e0e\u67b6\u6784\u65e0\u5173\uff1b\u6fc0\u6d3b\u51e0\u4f55\u5173\u7cfb\u53cd\u6620\u4e86\u4e0d\u540c\u5386\u53f2\u5bf9\u672a\u6765\u5f71\u54cd\u7684\u673a\u5236\u548c\u7a0b\u5ea6\u5dee\u5f02\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u9884\u8bad\u7ec3\u80fd\u591f\u81ea\u7136\u53d1\u73b0\u5e76\u8868\u8fbe\u5bf9\u6570\u636e\u751f\u6210\u6a21\u578b\u7684\u4fe1\u5ff5\uff0c\u4e14\u8fd9\u79cd\u8868\u8fbe\u5177\u6709\u666e\u9002\u6027\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u3002"}}
{"id": "2507.07456", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2507.07456", "abs": "https://arxiv.org/abs/2507.07456", "authors": ["Nawaf Alampara", "Anagha Aneesh", "Marti\u00f1o R\u00edos-Garc\u00eda", "Adrian Mirza", "Mara Schilling-Wilhelmi", "Ali Asghar Aghajani", "Meiling Sun", "Gordan Prastalo", "Kevin Maik Jablonka"], "title": "General purpose models for the chemical sciences", "comment": null, "summary": "Data-driven techniques have a large potential to transform and accelerate the\nchemical sciences. However, chemical sciences also pose the unique challenge of\nvery diverse, small, fuzzy datasets that are difficult to leverage in\nconventional machine learning approaches completely. A new class of models,\ngeneral-purpose models (GPMs) such as large language models, have shown the\nability to solve tasks they have not been directly trained on, and to flexibly\noperate with low amounts of data in different formats. In this review, we\ndiscuss fundamental building principles of GPMs and review recent applications\nof those models in the chemical sciences across the entire scientific process.\nWhile many of these applications are still in the prototype phase, we expect\nthat the increasing interest in GPMs will make many of them mature in the\ncoming years.", "AI": {"tldr": "\u7efc\u8ff0\u8ba8\u8bba\u4e86\u901a\u7528\u6a21\u578b\uff08GPMs\uff09\u5728\u5316\u5b66\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5c3d\u7ba1\u6570\u636e\u591a\u6837\u4e14\u6a21\u7cca\uff0c\u4f46GPMs\u80fd\u7075\u6d3b\u5904\u7406\u5c0f\u6570\u636e\u96c6\u3002", "motivation": "\u5316\u5b66\u79d1\u5b66\u9762\u4e34\u6570\u636e\u591a\u6837\u3001\u6a21\u7cca\u4e14\u89c4\u6a21\u5c0f\u7684\u6311\u6218\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u96be\u4ee5\u5b8c\u5168\u5e94\u5bf9\uff0c\u800cGPMs\u5c55\u73b0\u51fa\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u7684\u6f5c\u529b\u3002", "method": "\u7efc\u8ff0\u4e86GPMs\u7684\u57fa\u672c\u6784\u5efa\u539f\u5219\u53ca\u5176\u5728\u5316\u5b66\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u672a\u76f4\u63a5\u8bad\u7ec3\u7684\u4efb\u52a1\u548c\u4f4e\u6570\u636e\u91cf\u7684\u7075\u6d3b\u64cd\u4f5c\u3002", "result": "\u5c3d\u7ba1\u8bb8\u591a\u5e94\u7528\u4ecd\u5904\u4e8e\u539f\u578b\u9636\u6bb5\uff0c\u4f46GPMs\u5728\u5316\u5b66\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u524d\u666f\u5e7f\u9614\u3002", "conclusion": "\u968f\u7740\u5bf9GPMs\u5174\u8da3\u7684\u589e\u52a0\uff0c\u9884\u8ba1\u5176\u5e94\u7528\u5c06\u5728\u672a\u6765\u51e0\u5e74\u6210\u719f\u3002"}}
{"id": "2507.07485", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.07485", "abs": "https://arxiv.org/abs/2507.07485", "authors": ["Wooseong Jeong", "Kuk-Jin Yoon"], "title": "Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning", "comment": "Accepted at ICCV 2025", "summary": "Multi-Task Learning (MTL) enables multiple tasks to be learned within a\nshared network, but differences in objectives across tasks can cause negative\ntransfer, where the learning of one task degrades another task's performance.\nWhile pre-trained transformers significantly improve MTL performance, their\nfixed network capacity and rigid structure limit adaptability. Previous dynamic\nnetwork architectures attempt to address this but are inefficient as they\ndirectly convert shared parameters into task-specific ones. We propose Dynamic\nToken Modulation and Expansion (DTME-MTL), a framework applicable to any\ntransformer-based MTL architecture. DTME-MTL enhances adaptability and reduces\noverfitting by identifying gradient conflicts in token space and applying\nadaptive solutions based on conflict type. Unlike prior methods that mitigate\nnegative transfer by duplicating network parameters, DTME-MTL operates entirely\nin token space, enabling efficient adaptation without excessive parameter\ngrowth. Extensive experiments demonstrate that DTME-MTL consistently improves\nmulti-task performance with minimal computational overhead, offering a scalable\nand effective solution for enhancing transformer-based MTL models.", "AI": {"tldr": "DTME-MTL\u662f\u4e00\u79cd\u52a8\u6001\u4ee4\u724c\u8c03\u5236\u4e0e\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u4ee4\u724c\u7a7a\u95f4\u4e2d\u7684\u68af\u5ea6\u51b2\u7a81\u5e76\u81ea\u9002\u5e94\u89e3\u51b3\uff0c\u63d0\u5347\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u6027\u80fd\u3002", "motivation": "\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u4e2d\u4efb\u52a1\u95f4\u76ee\u6807\u5dee\u5f02\u53ef\u80fd\u5bfc\u81f4\u8d1f\u8fc1\u79fb\uff0c\u73b0\u6709\u9884\u8bad\u7ec3Transformer\u7684\u56fa\u5b9a\u7ed3\u6784\u548c\u5bb9\u91cf\u9650\u5236\u4e86\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51faDTME-MTL\u6846\u67b6\uff0c\u5728\u4ee4\u724c\u7a7a\u95f4\u4e2d\u52a8\u6001\u8bc6\u522b\u68af\u5ea6\u51b2\u7a81\u5e76\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u907f\u514d\u76f4\u63a5\u590d\u5236\u7f51\u7edc\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDTME-MTL\u80fd\u663e\u8457\u63d0\u5347\u591a\u4efb\u52a1\u6027\u80fd\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u4f4e\u3002", "conclusion": "DTME-MTL\u4e3aTransformer-based MTL\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07511", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07511", "abs": "https://arxiv.org/abs/2507.07511", "authors": ["Joris Suurmeijer", "Ivo Pascal de Jong", "Matias Valdenegro-Toro", "Andreea Ioana Sburlea"], "title": "Uncertainty Quantification for Motor Imagery BCI -- Machine Learning vs. Deep Learning", "comment": "6 pages, 3 figures", "summary": "Brain-computer interfaces (BCIs) turn brain signals into functionally useful\noutput, but they are not always accurate. A good Machine Learning classifier\nshould be able to indicate how confident it is about a given classification, by\ngiving a probability for its classification. Standard classifiers for Motor\nImagery BCIs do give such probabilities, but research on uncertainty\nquantification has been limited to Deep Learning. We compare the uncertainty\nquantification ability of established BCI classifiers using Common Spatial\nPatterns (CSP-LDA) and Riemannian Geometry (MDRM) to specialized methods in\nDeep Learning (Deep Ensembles and Direct Uncertainty Quantification) as well as\nstandard Convolutional Neural Networks (CNNs).\n  We found that the overconfidence typically seen in Deep Learning is not a\nproblem in CSP-LDA and MDRM. We found that MDRM is underconfident, which we\nsolved by adding Temperature Scaling (MDRM-T). CSP-LDA and MDRM-T give the best\nuncertainty estimates, but Deep Ensembles and standard CNNs give the best\nclassifications. We show that all models are able to separate between easy and\ndifficult estimates, so that we can increase the accuracy of a Motor Imagery\nBCI by rejecting samples that are ambiguous.", "AI": {"tldr": "\u6bd4\u8f83\u4e86\u591a\u79cd\u8111\u673a\u63a5\u53e3\u5206\u7c7b\u5668\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\uff08CSP-LDA\u548cMDRM-T\uff09\u5728\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08Deep Ensembles\u548cCNN\uff09\u5728\u5206\u7c7b\u51c6\u786e\u6027\u4e0a\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u8111\u673a\u63a5\u53e3\u5206\u7c7b\u5668\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u4ee5\u63d0\u9ad8\u5206\u7c7b\u7684\u53ef\u9760\u6027\u3002", "method": "\u6bd4\u8f83\u4e86\u4f20\u7edf\u65b9\u6cd5\uff08CSP-LDA\u548cMDRM\uff09\u4e0e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08Deep Ensembles\u3001Direct Uncertainty Quantification\u548cCNN\uff09\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\u3002", "result": "CSP-LDA\u548cMDRM-T\u5728\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u5206\u7c7b\u51c6\u786e\u6027\u4e0a\u66f4\u4f18\u3002\u6240\u6709\u6a21\u578b\u90fd\u80fd\u533a\u5206\u96be\u6613\u6837\u672c\u3002", "conclusion": "\u901a\u8fc7\u62d2\u7edd\u6a21\u7cca\u6837\u672c\u53ef\u4ee5\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0a\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2507.07532", "categories": ["cs.LG", "cs.AI", "68T01, 68T07", "I.2.6"], "pdf": "https://arxiv.org/pdf/2507.07532", "abs": "https://arxiv.org/abs/2507.07532", "authors": ["Berkant Turan", "Suhrab Asadulla", "David Steinmann", "Wolfgang Stammer", "Sebastian Pokutta"], "title": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings", "comment": "16 pages, 4 figures, 8 tables", "summary": "While Prover-Verifier Games (PVGs) offer a promising path toward\nverifiability in nonlinear classification models, they have not yet been\napplied to complex inputs such as high-dimensional images. Conversely, Concept\nBottleneck Models (CBMs) effectively translate such data into interpretable\nconcepts but are limited by their reliance on low-capacity linear predictors.\nIn this work, we introduce the Neural Concept Verifier (NCV), a unified\nframework combining PVGs with concept encodings for interpretable, nonlinear\nclassification in high-dimensional settings. NCV achieves this by utilizing\nrecent minimally supervised concept discovery models to extract structured\nconcept encodings from raw inputs. A prover then selects a subset of these\nencodings, which a verifier -- implemented as a nonlinear predictor -- uses\nexclusively for decision-making. Our evaluations show that NCV outperforms CBM\nand pixel-based PVG classifier baselines on high-dimensional, logically complex\ndatasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV\nas a promising step toward performative, verifiable AI.", "AI": {"tldr": "NCV\u7ed3\u5408PVGs\u548cCBMs\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u7684\u53ef\u89e3\u91ca\u975e\u7ebf\u6027\u5206\u7c7b\u6846\u67b6\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3PVGs\u672a\u5e94\u7528\u4e8e\u590d\u6742\u9ad8\u7ef4\u6570\u636e\uff0c\u4ee5\u53caCBMs\u4f9d\u8d56\u4f4e\u5bb9\u91cf\u7ebf\u6027\u9884\u6d4b\u5668\u7684\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528\u6982\u5ff5\u53d1\u73b0\u6a21\u578b\u63d0\u53d6\u7ed3\u6784\u5316\u6982\u5ff5\u7f16\u7801\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u9884\u6d4b\u5668\u8fdb\u884c\u51b3\u7b56\u3002", "result": "NCV\u5728\u9ad8\u7ef4\u590d\u6742\u6570\u636e\u96c6\u4e0a\u4f18\u4e8eCBM\u548c\u50cf\u7d20\u57faPVG\u5206\u7c7b\u5668\uff0c\u5e76\u51cf\u5c11\u6377\u5f84\u884c\u4e3a\u3002", "conclusion": "NCV\u662f\u5b9e\u73b0\u9ad8\u6027\u80fd\u3001\u53ef\u9a8c\u8bc1AI\u7684\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.07580", "categories": ["cs.LG", "cs.CL", "cs.NA", "math.NA", "65F55, 68T50"], "pdf": "https://arxiv.org/pdf/2507.07580", "abs": "https://arxiv.org/abs/2507.07580", "authors": ["Uliana Parkina", "Maxim Rakhuba"], "title": "COALA: Numerically Stable and Efficient Framework for Context-Aware Low-Rank Approximation", "comment": null, "summary": "Recent studies suggest that context-aware low-rank approximation is a useful\ntool for compression and fine-tuning of modern large-scale neural networks. In\nthis type of approximation, a norm is weighted by a matrix of input\nactivations, significantly improving metrics over the unweighted case.\nNevertheless, existing methods for neural networks suffer from numerical\ninstabilities due to their reliance on classical formulas involving explicit\nGram matrix computation and their subsequent inversion. We demonstrate that\nthis can degrade the approximation quality or cause numerically singular\nmatrices.\n  To address these limitations, we propose a novel inversion-free regularized\nframework that is based entirely on stable decompositions and overcomes the\nnumerical pitfalls of prior art. Our method can handle possible challenging\nscenarios: (1) when calibration matrices exceed GPU memory capacity, (2) when\ninput activation matrices are nearly singular, and even (3) when insufficient\ndata prevents unique approximation. For the latter, we prove that our solution\nconverges to a desired approximation and derive explicit error bounds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a33\u5b9a\u5206\u89e3\u7684\u65e0\u9006\u6b63\u5219\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u56e0\u4f9d\u8d56\u663e\u5f0fGram\u77e9\u9635\u8ba1\u7b97\u548c\u9006\u8fd0\u7b97\u5bfc\u81f4\u6570\u503c\u4e0d\u7a33\u5b9a\uff0c\u5f71\u54cd\u8fd1\u4f3c\u8d28\u91cf\u6216\u4ea7\u751f\u5947\u5f02\u77e9\u9635\u3002", "method": "\u91c7\u7528\u65e0\u9006\u6b63\u5219\u5316\u6846\u67b6\uff0c\u57fa\u4e8e\u7a33\u5b9a\u5206\u89e3\uff0c\u89e3\u51b3\u4e86GPU\u5185\u5b58\u4e0d\u8db3\u3001\u8f93\u5165\u6fc0\u6d3b\u77e9\u9635\u63a5\u8fd1\u5947\u5f02\u548c\u6570\u636e\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "result": "\u65b9\u6cd5\u5728\u591a\u79cd\u6311\u6218\u6027\u573a\u666f\u4e0b\u8868\u73b0\u7a33\u5b9a\uff0c\u8bc1\u660e\u4e86\u6536\u655b\u6027\u5e76\u63a8\u5bfc\u4e86\u8bef\u5dee\u754c\u9650\u3002", "conclusion": "\u65b0\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u538b\u7f29\u548c\u5fae\u8c03\u3002"}}
{"id": "2507.07581", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.07581", "abs": "https://arxiv.org/abs/2507.07581", "authors": ["Michail Kalntis", "Fernando A. Kuipers", "George Iosifidis"], "title": "CHOMET: Conditional Handovers via Meta-Learning", "comment": null, "summary": "Handovers (HOs) are the cornerstone of modern cellular networks for enabling\nseamless connectivity to a vast and diverse number of mobile users. However, as\nmobile networks become more complex with more diverse users and smaller cells,\ntraditional HOs face significant challenges, such as prolonged delays and\nincreased failures. To mitigate these issues, 3GPP introduced conditional\nhandovers (CHOs), a new type of HO that enables the preparation (i.e., resource\nallocation) of multiple cells for a single user to increase the chance of HO\nsuccess and decrease the delays in the procedure. Despite its advantages, CHO\nintroduces new challenges that must be addressed, including efficient resource\nallocation and managing signaling/communication overhead from frequent cell\npreparations and releases. This paper presents a novel framework aligned with\nthe O-RAN paradigm that leverages meta-learning for CHO optimization, providing\nrobust dynamic regret guarantees and demonstrating at least 180% superior\nperformance than other 3GPP benchmarks in volatile signal conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u6761\u4ef6\u5207\u6362\uff08CHO\uff09\uff0c\u5728\u52a8\u6001\u4fe1\u53f7\u6761\u4ef6\u4e0b\u6027\u80fd\u4f18\u4e8e3GPP\u57fa\u51c6180%\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u7f51\u7edc\u590d\u6742\u6027\u589e\u52a0\uff0c\u4f20\u7edf\u5207\u6362\u9762\u4e34\u5ef6\u8fdf\u548c\u5931\u8d25\u95ee\u9898\uff0c\u6761\u4ef6\u5207\u6362\uff08CHO\uff09\u867d\u80fd\u7f13\u89e3\u4f46\u5f15\u5165\u65b0\u6311\u6218\uff0c\u5982\u8d44\u6e90\u5206\u914d\u548c\u4fe1\u4ee4\u5f00\u9500\u3002", "method": "\u91c7\u7528\u4e0eO-RAN\u8303\u5f0f\u5bf9\u9f50\u7684\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u4f18\u5316CHO\u7684\u8d44\u6e90\u5206\u914d\u548c\u4fe1\u4ee4\u7ba1\u7406\u3002", "result": "\u5728\u52a8\u6001\u4fe1\u53f7\u6761\u4ef6\u4e0b\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e3GPP\u57fa\u51c6\u81f3\u5c11180%\u3002", "conclusion": "\u63d0\u51fa\u7684\u5143\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86CHO\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u5207\u6362\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2507.07582", "categories": ["cs.LG", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.07582", "abs": "https://arxiv.org/abs/2507.07582", "authors": ["Iago Xabier V\u00e1zquez Garc\u00eda", "Damla Partanaz", "Emrullah Fatih Yetkin"], "title": "Improving Clustering on Occupational Text Data through Dimensionality Reduction", "comment": "Preprint, 10 figures", "summary": "In this study, we focused on proposing an optimal clustering mechanism for\nthe occupations defined in the well-known US-based occupational database,\nO*NET. Even though all occupations are defined according to well-conducted\nsurveys in the US, their definitions can vary for different firms and\ncountries. Hence, if one wants to expand the data that is already collected in\nO*NET for the occupations defined with different tasks, a map between the\ndefinitions will be a vital requirement. We proposed a pipeline using several\nBERT-based techniques with various clustering approaches to obtain such a map.\nWe also examined the effect of dimensionality reduction approaches on several\nmetrics used in measuring performance of clustering algorithms. Finally, we\nimproved our results by using a specialized silhouette approach. This new\nclustering-based mapping approach with dimensionality reduction may help\ndistinguish the occupations automatically, creating new paths for people\nwanting to change their careers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBERT\u548c\u805a\u7c7b\u7684\u4f18\u5316\u673a\u5236\uff0c\u7528\u4e8e\u6620\u5c04\u4e0d\u540c\u804c\u4e1a\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u964d\u7ef4\u548c\u4e13\u7528\u8f6e\u5ed3\u65b9\u6cd5\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u7531\u4e8e\u804c\u4e1a\u5b9a\u4e49\u5728\u4e0d\u540c\u4f01\u4e1a\u548c\u56fd\u5bb6\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5c06O*NET\u6570\u636e\u5e93\u4e2d\u7684\u804c\u4e1a\u4e0e\u5176\u4ed6\u5b9a\u4e49\u8fdb\u884c\u6620\u5c04\u3002", "method": "\u91c7\u7528BERT\u6280\u672f\u548c\u591a\u79cd\u805a\u7c7b\u65b9\u6cd5\u6784\u5efa\u7ba1\u9053\uff0c\u7ed3\u5408\u964d\u7ef4\u6280\u672f\uff0c\u5e76\u4f7f\u7528\u4e13\u7528\u8f6e\u5ed3\u65b9\u6cd5\u4f18\u5316\u7ed3\u679c\u3002", "result": "\u901a\u8fc7\u964d\u7ef4\u548c\u4e13\u7528\u8f6e\u5ed3\u65b9\u6cd5\u63d0\u5347\u4e86\u805a\u7c7b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u804c\u4e1a\u5b9a\u4e49\u7684\u81ea\u52a8\u533a\u5206\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u804c\u4e1a\u5b9a\u4e49\u6620\u5c04\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u53ef\u80fd\u5e2e\u52a9\u804c\u4e1a\u8f6c\u578b\u8005\u627e\u5230\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.07589", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.07589", "abs": "https://arxiv.org/abs/2507.07589", "authors": ["Arpana Sinhal", "Anay Sinhal", "Amit Sinhal"], "title": "Stress Monitoring in Healthcare: An Ensemble Machine Learning Framework Using Wearable Sensor Data", "comment": null, "summary": "Healthcare professionals, particularly nurses, face elevated occupational\nstress, a concern amplified during the COVID-19 pandemic. While wearable\nsensors offer promising avenues for real-time stress monitoring, existing\nstudies often lack comprehensive datasets and robust analytical frameworks.\nThis study addresses these gaps by introducing a multimodal dataset comprising\nphysiological signals, electrodermal activity, heart rate and skin temperature.\nA systematic literature review identified limitations in prior stress-detection\nmethodologies, particularly in handling class imbalance and optimizing model\ngeneralizability. To overcome these challenges, the dataset underwent\npreprocessing with the Synthetic Minority Over sampling Technique (SMOTE),\nensuring balanced representation of stress states. Advanced machine learning\nmodels including Random Forest, XGBoost and a Multi-Layer Perceptron (MLP) were\nevaluated and combined into a Stacking Classifier to leverage their collective\npredictive strengths. By using a publicly accessible dataset and a reproducible\nanalytical pipeline, this work advances the development of deployable\nstress-monitoring systems, offering practical implications for safeguarding\nhealthcare workers' mental health. Future research directions include expanding\ndemographic diversity and exploring edge-computing implementations for low\nlatency stress alerts.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u96c6\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u533b\u62a4\u4eba\u5458\u538b\u529b\u76d1\u6d4b\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u548c\u6a21\u578b\u6cdb\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u90e8\u7f72\u7684\u538b\u529b\u76d1\u6d4b\u7cfb\u7edf\u3002", "motivation": "\u533b\u62a4\u4eba\u5458\uff08\u5c24\u5176\u662f\u62a4\u58eb\uff09\u9762\u4e34\u9ad8\u804c\u4e1a\u538b\u529b\uff0cCOVID-19\u52a0\u5267\u4e86\u8fd9\u4e00\u95ee\u9898\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5168\u9762\u6570\u636e\u548c\u7a33\u5065\u5206\u6790\u6846\u67b6\u3002", "method": "\u4f7f\u7528SMOTE\u9884\u5904\u7406\u6570\u636e\u4ee5\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u8bc4\u4f30\u5e76\u7ec4\u5408\u968f\u673a\u68ee\u6797\u3001XGBoost\u548cMLP\u6a21\u578b\u4e3a\u5806\u53e0\u5206\u7c7b\u5668\u3002", "result": "\u901a\u8fc7\u516c\u5f00\u6570\u636e\u96c6\u548c\u53ef\u91cd\u590d\u5206\u6790\u6d41\u7a0b\uff0c\u5f00\u53d1\u4e86\u53ef\u90e8\u7f72\u7684\u538b\u529b\u76d1\u6d4b\u7cfb\u7edf\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u6269\u5927\u4eba\u53e3\u591a\u6837\u6027\u548c\u63a2\u7d22\u8fb9\u7f18\u8ba1\u7b97\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u538b\u529b\u8b66\u62a5\u3002"}}
{"id": "2507.07604", "categories": ["cs.LG", "q-bio.QM", "q-bio.TO"], "pdf": "https://arxiv.org/pdf/2507.07604", "abs": "https://arxiv.org/abs/2507.07604", "authors": ["Sebastian Lotter", "Elisabeth Mohr", "Andrina Rutsch", "Lukas Brand", "Francesca Ronchi", "Laura D\u00edaz-Marug\u00e1n"], "title": "Synthetic MC via Biological Transmitters: Therapeutic Modulation of the Gut-Brain Axis", "comment": null, "summary": "Synthetic molecular communication (SMC) is a key enabler for future\nhealthcare systems in which Internet of Bio-Nano-Things (IoBNT) devices\nfacilitate the continuous monitoring of a patient's biochemical signals. To\nclose the loop between sensing and actuation, both the detection and the\ngeneration of in-body molecular communication (MC) signals is key. However,\ngenerating signals inside the human body, e.g., via synthetic nanodevices,\nposes a challenge in SMC, due to technological obstacles as well as legal,\nsafety, and ethical issues. Hence, this paper considers an SMC system in which\nsignals are generated indirectly via the modulation of a natural in-body MC\nsystem, namely the gut-brain axis (GBA). Therapeutic GBA modulation is already\nestablished as treatment for neurological diseases, e.g., drug refractory\nepilepsy (DRE), and performed via the administration of nutritional supplements\nor specific diets. However, the molecular signaling pathways that mediate the\neffect of such treatments are mostly unknown. Consequently, existing treatments\nare standardized or designed heuristically and able to help only some patients\nwhile failing to help others. In this paper, we propose to leverage personal\nhealth data, e.g., gathered by in-body IoBNT devices, to design more versatile\nand robust GBA modulation-based treatments as compared to the existing ones. To\nshow the feasibility of our approach, we define a catalog of theoretical\nrequirements for therapeutic GBA modulation. Then, we propose a machine\nlearning model to verify these requirements for practical scenarios when only\nlimited data on the GBA modulation exists. By evaluating the proposed model on\nseveral datasets, we confirm its excellent accuracy in identifying different\nmodulators of the GBA. Finally, we utilize the proposed model to identify\nspecific modulatory pathways that play an important role for therapeutic GBA\nmodulation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80a0\u9053-\u8111\u8f74\uff08GBA\uff09\u95f4\u63a5\u751f\u6210\u5206\u5b50\u4fe1\u53f7\u7684\u5408\u6210\u5206\u5b50\u901a\u4fe1\uff08SMC\uff09\u7cfb\u7edf\uff0c\u5229\u7528\u4e2a\u4eba\u5065\u5eb7\u6570\u636e\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u6cbb\u7597\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6cbb\u7597\u65b9\u6cd5\u6807\u51c6\u5316\u4e14\u6548\u679c\u6709\u9650\uff0c\u9700\u5229\u7528\u4e2a\u4eba\u5065\u5eb7\u6570\u636e\u548cSMC\u6280\u672f\u6539\u8fdb\u80a0\u9053-\u8111\u8f74\uff08GBA\uff09\u8c03\u5236\u6cbb\u7597\u3002", "method": "\u63d0\u51fa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9a8c\u8bc1GBA\u8c03\u5236\u7684\u7406\u8bba\u8981\u6c42\uff0c\u5e76\u5728\u6709\u9650\u6570\u636e\u4e0b\u8bc4\u4f30\u5176\u51c6\u786e\u6027\u3002", "result": "\u6a21\u578b\u5728\u8bc6\u522bGBA\u8c03\u5236\u56e0\u5b50\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u6210\u529f\u8bc6\u522b\u7279\u5b9a\u6cbb\u7597\u6027\u8c03\u5236\u901a\u8def\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e2a\u6027\u5316GBA\u8c03\u5236\u6cbb\u7597\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86SMC\u5728\u533b\u7597\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.07613", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07613", "abs": "https://arxiv.org/abs/2507.07613", "authors": ["Davide Domini", "Laura Erhan", "Gianluca Aguzzi", "Lucia Cavallaro", "Amirhossein Douzandeh Zenoozi", "Antonio Liotta", "Mirko Viroli"], "title": "Sparse Self-Federated Learning for Energy Efficient Cooperative Intelligence in Society 5.0", "comment": null, "summary": "Federated Learning offers privacy-preserving collaborative intelligence but\nstruggles to meet the sustainability demands of emerging IoT ecosystems\nnecessary for Society 5.0-a human-centered technological future balancing\nsocial advancement with environmental responsibility. The excessive\ncommunication bandwidth and computational resources required by traditional FL\napproaches make them environmentally unsustainable at scale, creating a\nfundamental conflict with green AI principles as billions of\nresource-constrained devices attempt to participate. To this end, we introduce\nSparse Proximity-based Self-Federated Learning (SParSeFuL), a resource-aware\napproach that bridges this gap by combining aggregate computing for\nself-organization with neural network sparsification to reduce energy and\nbandwidth consumption.", "AI": {"tldr": "SParSeFuL\u662f\u4e00\u79cd\u8d44\u6e90\u611f\u77e5\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u805a\u5408\u8ba1\u7b97\u548c\u795e\u7ecf\u7f51\u7edc\u7a00\u758f\u5316\uff0c\u51cf\u5c11\u80fd\u8017\u548c\u5e26\u5bbd\u6d88\u8017\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728\u53ef\u6301\u7eed\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728\u6ee1\u8db3Society 5.0\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u5176\u9ad8\u901a\u4fe1\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u4e0e\u7eff\u8272AI\u539f\u5219\u51b2\u7a81\u3002", "method": "\u63d0\u51faSParSeFuL\u65b9\u6cd5\uff0c\u7ed3\u5408\u805a\u5408\u8ba1\u7b97\u548c\u795e\u7ecf\u7f51\u7edc\u7a00\u758f\u5316\uff0c\u4ee5\u964d\u4f4e\u80fd\u8017\u548c\u5e26\u5bbd\u9700\u6c42\u3002", "result": "SParSeFuL\u80fd\u591f\u663e\u8457\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u534f\u4f5c\u667a\u80fd\u3002", "conclusion": "SParSeFuL\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u8bbe\u5907\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6301\u7eed\u7684\u8054\u90a6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07621", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07621", "abs": "https://arxiv.org/abs/2507.07621", "authors": ["Junyu Luo", "Yuhao Tang", "Yiwei Fu", "Xiao Luo", "Zhizhuo Kou", "Zhiping Xiao", "Wei Ju", "Wentao Zhang", "Ming Zhang"], "title": "Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation", "comment": "ICML 2025", "summary": "Unsupervised Graph Domain Adaptation (UGDA) leverages labeled source domain\ngraphs to achieve effective performance in unlabeled target domains despite\ndistribution shifts. However, existing methods often yield suboptimal results\ndue to the entanglement of causal-spurious features and the failure of global\nalignment strategies. We propose SLOGAN (Sparse Causal Discovery with\nGenerative Intervention), a novel approach that achieves stable graph\nrepresentation transfer through sparse causal modeling and dynamic intervention\nmechanisms. Specifically, SLOGAN first constructs a sparse causal graph\nstructure, leveraging mutual information bottleneck constraints to disentangle\nsparse, stable causal features while compressing domain-dependent spurious\ncorrelations through variational inference. To address residual spurious\ncorrelations, we innovatively design a generative intervention mechanism that\nbreaks local spurious couplings through cross-domain feature recombination\nwhile maintaining causal feature semantic consistency via covariance\nconstraints. Furthermore, to mitigate error accumulation in target domain\npseudo-labels, we introduce a category-adaptive dynamic calibration strategy,\nensuring stable discriminative learning. Extensive experiments on multiple\nreal-world datasets demonstrate that SLOGAN significantly outperforms existing\nbaselines.", "AI": {"tldr": "SLOGAN\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u56e0\u679c\u5efa\u6a21\u548c\u52a8\u6001\u5e72\u9884\u673a\u5236\u7684\u56fe\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u56fe\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u56e0\u56e0\u679c-\u865a\u5047\u7279\u5f81\u7ea0\u7f20\u548c\u5168\u5c40\u5bf9\u9f50\u7b56\u7565\u5931\u6548\u800c\u8868\u73b0\u4e0d\u4f73\u3002", "method": "SLOGAN\u901a\u8fc7\u7a00\u758f\u56e0\u679c\u56fe\u7ed3\u6784\u548c\u751f\u6210\u5e72\u9884\u673a\u5236\u5206\u79bb\u56e0\u679c\u7279\u5f81\uff0c\u5e76\u5f15\u5165\u7c7b\u522b\u81ea\u9002\u5e94\u52a8\u6001\u6821\u51c6\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cSLOGAN\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SLOGAN\u901a\u8fc7\u56e0\u679c\u5efa\u6a21\u548c\u52a8\u6001\u5e72\u9884\u5b9e\u73b0\u4e86\u7a33\u5b9a\u7684\u56fe\u8868\u793a\u8fc1\u79fb\u3002"}}
{"id": "2507.07622", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07622", "abs": "https://arxiv.org/abs/2507.07622", "authors": ["Federico Del Pup", "Riccardo Brun", "Filippo Iotti", "Edoardo Paccagnella", "Mattia Pezzato", "Sabrina Bertozzo", "Andrea Zanola", "Louis Fabrice Tshimanga", "Henning M\u00fcller", "Manfredo Atzori"], "title": "TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection", "comment": "Submitted for possible publication. GitHub repository: see\n  https://github.com/MedMaxLab/transformeeg", "summary": "Electroencephalography (EEG) is establishing itself as an important,\nlow-cost, noninvasive diagnostic tool for the early detection of Parkinson's\nDisease (PD). In this context, EEG-based Deep Learning (DL) models have shown\npromising results due to their ability to discover highly nonlinear patterns\nwithin the signal. However, current state-of-the-art DL models suffer from poor\ngeneralizability caused by high inter-subject variability. This high\nvariability underscores the need for enhancing model generalizability by\ndeveloping new architectures better tailored to EEG data. This paper introduces\nTransformEEG, a hybrid Convolutional-Transformer designed for Parkinson's\ndisease detection using EEG data. Unlike transformer models based on the EEGNet\nstructure, TransformEEG incorporates a depthwise convolutional tokenizer. This\ntokenizer is specialized in generating tokens composed by channel-specific\nfeatures, which enables more effective feature mixing within the self-attention\nlayers of the transformer encoder. To evaluate the proposed model, four public\ndatasets comprising 290 subjects (140 PD patients, 150 healthy controls) were\nharmonized and aggregated. A 10-outer, 10-inner Nested-Leave-N-Subjects-Out\n(N-LNSO) cross-validation was performed to provide an unbiased comparison\nagainst seven other consolidated EEG deep learning models. TransformEEG\nachieved the highest balanced accuracy's median (78.45%) as well as the lowest\ninterquartile range (6.37%) across all the N-LNSO partitions. When combined\nwith data augmentation and threshold correction, median accuracy increased to\n80.10%, with an interquartile range of 5.74%. In conclusion, TransformEEG\nproduces more consistent and less skewed results. It demonstrates a substantial\nreduction in variability and more reliable PD detection using EEG data compared\nto the other investigated models.", "AI": {"tldr": "TransformEEG\u662f\u4e00\u79cd\u7ed3\u5408\u5377\u79ef\u548cTransformer\u7684\u6df7\u5408\u6a21\u578b\uff0c\u7528\u4e8e\u901a\u8fc7EEG\u6570\u636e\u68c0\u6d4b\u5e15\u91d1\u68ee\u75c5\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u4f4e\u7684\u53d8\u5f02\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eEEG\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5e15\u91d1\u68ee\u75c5\u68c0\u6d4b\u4e2d\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u4e3b\u8981\u7531\u4e8e\u53d7\u8bd5\u8005\u95f4\u7684\u9ad8\u53d8\u5f02\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u9002\u5408EEG\u6570\u636e\u7684\u65b0\u67b6\u6784\u3002", "method": "\u63d0\u51faTransformEEG\u6a21\u578b\uff0c\u91c7\u7528\u6df1\u5ea6\u5377\u79ef\u5206\u8bcd\u5668\u751f\u6210\u901a\u9053\u7279\u5b9a\u7279\u5f81\uff0c\u589e\u5f3a\u81ea\u6ce8\u610f\u529b\u5c42\u7684\u7279\u5f81\u6df7\u5408\u80fd\u529b\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\uff0cTransformEEG\u7684\u4e2d\u4f4d\u6570\u5e73\u8861\u51c6\u786e\u7387\u4e3a78.45%\uff0c\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u548c\u9608\u503c\u6821\u6b63\u540e\u63d0\u5347\u81f380.10%\uff0c\u53d8\u5f02\u6027\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "TransformEEG\u5728\u5e15\u91d1\u68ee\u75c5\u68c0\u6d4b\u4e2d\u8868\u73b0\u66f4\u4e00\u81f4\u3001\u53ef\u9760\uff0c\u4f18\u4e8e\u5176\u4ed6\u73b0\u6709\u6a21\u578b\u3002"}}
{"id": "2507.07637", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07637", "abs": "https://arxiv.org/abs/2507.07637", "authors": ["Carlos Beis Penedo", "Rebeca P. D\u00edaz Redondo", "Ana Fern\u00e1ndez Vilas", "Manuel Fern\u00e1ndez Veiga", "Francisco Troncoso Pastoriza"], "title": "HLF-FSL. A Decentralized Federated Split Learning Solution for IoT on Hyperledger Fabric", "comment": "19 pages, 7 figures and 6 tables", "summary": "Collaborative machine learning in sensitive domains demands scalable, privacy\npreserving solutions for enterprise deployment. Conventional Federated Learning\n(FL) relies on a central server, introducing single points of failure and\nprivacy risks, while Split Learning (SL) partitions models for privacy but\nscales poorly due to sequential training. We present a decentralized\narchitecture that combines Federated Split Learning (FSL) with the permissioned\nblockchain Hyperledger Fabric (HLF). Our chaincode orchestrates FSL's split\nmodel execution and peer-to-peer aggregation without any central coordinator,\nleveraging HLF's transient fields and Private Data Collections (PDCs) to keep\nraw data and model activations private. On CIFAR-10 and MNIST benchmarks,\nHLF-FSL matches centralized FSL accuracy while reducing per epoch training time\ncompared to Ethereum-based works. Performance and scalability tests show\nminimal blockchain overhead and preserved accuracy, demonstrating enterprise\ngrade viability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8054\u90a6\u5206\u62c6\u5b66\u4e60\uff08FSL\uff09\u548cHyperledger Fabric\uff08HLF\uff09\u7684\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u548c\u5206\u62c6\u5b66\u4e60\uff08SL\uff09\u7684\u9690\u79c1\u548c\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u5728\u654f\u611f\u9886\u57df\u4e2d\uff0c\u534f\u4f5c\u673a\u5668\u5b66\u4e60\u9700\u8981\u53ef\u6269\u5c55\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002\u4f20\u7edfFL\u4f9d\u8d56\u4e2d\u592e\u670d\u52a1\u5668\uff0c\u5b58\u5728\u5355\u70b9\u6545\u969c\u548c\u9690\u79c1\u98ce\u9669\uff0c\u800cSL\u56e0\u987a\u5e8f\u8bad\u7ec3\u6269\u5c55\u6027\u5dee\u3002", "method": "\u91c7\u7528FSL\u4e0eHLF\u7ed3\u5408\u7684\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u5229\u7528HLF\u7684\u77ac\u6001\u5b57\u6bb5\u548c\u79c1\u6709\u6570\u636e\u96c6\u5408\uff08PDCs\uff09\u4fdd\u62a4\u539f\u59cb\u6570\u636e\u548c\u6a21\u578b\u6fc0\u6d3b\uff0c\u65e0\u9700\u4e2d\u592e\u534f\u8c03\u5668\u3002", "result": "\u5728CIFAR-10\u548cMNIST\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHLF-FSL\u4e0e\u96c6\u4e2d\u5f0fFSL\u7cbe\u5ea6\u76f8\u5f53\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u6bcf\u8f6e\u8bad\u7ec3\u65f6\u95f4\u3002\u6027\u80fd\u6d4b\u8bd5\u663e\u793a\u533a\u5757\u94fe\u5f00\u9500\u6700\u5c0f\u4e14\u7cbe\u5ea6\u4fdd\u6301\u3002", "conclusion": "\u8be5\u67b6\u6784\u5c55\u793a\u4e86\u4f01\u4e1a\u7ea7\u53ef\u884c\u6027\uff0c\u89e3\u51b3\u4e86\u9690\u79c1\u548c\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2507.07675", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07675", "abs": "https://arxiv.org/abs/2507.07675", "authors": ["Darshan Makwana"], "title": "Some Theoretical Results on Layerwise Effective Dimension Oscillations in Finite Width ReLU Networks", "comment": null, "summary": "We analyze the layerwise effective dimension (rank of the feature matrix) in\nfully-connected ReLU networks of finite width. Specifically, for a fixed batch\nof $m$ inputs and random Gaussian weights, we derive closed-form expressions\nfor the expected rank of the \\$m\\times n\\$ hidden activation matrices. Our main\nresult shows that $\\mathbb{E}[EDim(\\ell)]=m[1-(1-2/\\pi)^\\ell]+O(e^{-c m})$ so\nthat the rank deficit decays geometrically with ratio $1-2 / \\pi \\approx\n0.3634$. We also prove a sub-Gaussian concentration bound, and identify the\n\"revival\" depths at which the expected rank attains local maxima. In\nparticular, these peaks occur at depths\n$\\ell_k^*\\approx(k+1/2)\\pi/\\log(1/\\rho)$ with height $\\approx (1-e^{-\\pi/2}) m\n\\approx 0.79m$. We further show that this oscillatory rank behavior is a\nfinite-width phenomenon: under orthogonal weight initialization or strong\nnegative-slope leaky-ReLU, the rank remains (nearly) full. These results\nprovide a precise characterization of how random ReLU layers alternately\ncollapse and partially revive the subspace of input variations, adding nuance\nto prior work on expressivity of deep networks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6709\u9650\u5bbd\u5ea6\u5168\u8fde\u63a5ReLU\u7f51\u7edc\u4e2d\u6bcf\u5c42\u7684\u6709\u6548\u7ef4\u5ea6\uff08\u7279\u5f81\u77e9\u9635\u7684\u79e9\uff09\uff0c\u63a8\u5bfc\u4e86\u968f\u673a\u9ad8\u65af\u6743\u91cd\u4e0b\u9690\u85cf\u6fc0\u6d3b\u77e9\u9635\u7684\u671f\u671b\u79e9\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u53d1\u73b0\u79e9\u8d64\u5b57\u4ee5\u51e0\u4f55\u6bd4\u7387\u8870\u51cf\uff0c\u5e76\u8bc6\u522b\u4e86\u79e9\u5c40\u90e8\u6700\u5927\u503c\u7684\u201c\u590d\u5174\u201d\u6df1\u5ea6\u3002", "motivation": "\u7406\u89e3\u968f\u673aReLU\u5c42\u5982\u4f55\u4ea4\u66ff\u538b\u7f29\u548c\u90e8\u5206\u6062\u590d\u8f93\u5165\u53d8\u5316\u7684\u5b50\u7a7a\u95f4\uff0c\u4e3a\u6df1\u5ea6\u7f51\u7edc\u8868\u8fbe\u80fd\u529b\u7684\u7814\u7a76\u63d0\u4f9b\u66f4\u7ec6\u81f4\u7684\u89c6\u89d2\u3002", "method": "\u9488\u5bf9\u56fa\u5b9a\u6279\u6b21\u8f93\u5165\u548c\u968f\u673a\u9ad8\u65af\u6743\u91cd\uff0c\u63a8\u5bfc\u9690\u85cf\u6fc0\u6d3b\u77e9\u9635\u7684\u671f\u671b\u79e9\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u8bc1\u660e\u6b21\u9ad8\u65af\u6d53\u5ea6\u8fb9\u754c\u3002", "result": "\u671f\u671b\u79e9\u8d64\u5b57\u4ee5\u51e0\u4f55\u6bd4\u7387\u8870\u51cf\uff0c\u590d\u5174\u6df1\u5ea6\u51fa\u73b0\u5728\u7279\u5b9a\u4f4d\u7f6e\uff0c\u4e14\u79e9\u632f\u8361\u884c\u4e3a\u662f\u6709\u9650\u5bbd\u5ea6\u73b0\u8c61\u3002", "conclusion": "\u968f\u673aReLU\u5c42\u901a\u8fc7\u4ea4\u66ff\u538b\u7f29\u548c\u90e8\u5206\u6062\u590d\u8f93\u5165\u5b50\u7a7a\u95f4\uff0c\u4e3a\u6df1\u5ea6\u7f51\u7edc\u8868\u8fbe\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u89e3\u3002"}}
{"id": "2507.07712", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.07712", "abs": "https://arxiv.org/abs/2507.07712", "authors": ["Zhuang Qi", "Lei Meng", "Han Yu"], "title": "Balancing the Past and Present: A Coordinated Replay Framework for Federated Class-Incremental Learning", "comment": null, "summary": "Federated Class Incremental Learning (FCIL) aims to collaboratively process\ncontinuously increasing incoming tasks across multiple clients. Among various\napproaches, data replay has become a promising solution, which can alleviate\nforgetting by reintroducing representative samples from previous tasks.\nHowever, their performance is typically limited by class imbalance, both within\nthe replay buffer due to limited global awareness and between replayed and\nnewly arrived classes. To address this issue, we propose a class wise balancing\ndata replay method for FCIL (FedCBDR), which employs a global coordination\nmechanism for class-level memory construction and reweights the learning\nobjective to alleviate the aforementioned imbalances. Specifically, FedCBDR has\ntwo key components: 1) the global-perspective data replay module reconstructs\nglobal representations of prior task in a privacy-preserving manner, which then\nguides a class-aware and importance-sensitive sampling strategy to achieve\nbalanced replay; 2) Subsequently, to handle class imbalance across tasks, the\ntask aware temperature scaling module adaptively adjusts the temperature of\nlogits at both class and instance levels based on task dynamics, which reduces\nthe model's overconfidence in majority classes while enhancing its sensitivity\nto minority classes. Experimental results verified that FedCBDR achieves\nbalanced class-wise sampling under heterogeneous data distributions and\nimproves generalization under task imbalance between earlier and recent tasks,\nyielding a 2%-15% Top-1 accuracy improvement over six state-of-the-art methods.", "AI": {"tldr": "FedCBDR\u662f\u4e00\u79cd\u8054\u90a6\u7c7b\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u5c40\u534f\u8c03\u673a\u5236\u548c\u4efb\u52a1\u611f\u77e5\u6e29\u5ea6\u7f29\u653e\u6a21\u5757\u89e3\u51b3\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u7c7b\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5305\u62ec\u56de\u653e\u7f13\u51b2\u533a\u5185\u7684\u4e0d\u5e73\u8861\u548c\u65b0\u65e7\u4efb\u52a1\u95f4\u7684\u4e0d\u5e73\u8861\u3002", "method": "1) \u5168\u5c40\u89c6\u89d2\u6570\u636e\u56de\u653e\u6a21\u5757\uff0c\u9690\u79c1\u4fdd\u62a4\u5730\u91cd\u6784\u5168\u5c40\u8868\u793a\uff1b2) \u4efb\u52a1\u611f\u77e5\u6e29\u5ea6\u7f29\u653e\u6a21\u5757\uff0c\u52a8\u6001\u8c03\u6574logits\u6e29\u5ea6\u3002", "result": "\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u5b9e\u73b0\u5e73\u8861\u91c7\u6837\uff0c\u4efb\u52a1\u4e0d\u5e73\u8861\u65f6\u6cdb\u5316\u80fd\u529b\u63d0\u5347\uff0cTop-1\u51c6\u786e\u7387\u63d0\u9ad82%-15%\u3002", "conclusion": "FedCBDR\u6709\u6548\u89e3\u51b3\u4e86\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8054\u90a6\u7c7b\u589e\u91cf\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2507.07735", "categories": ["cs.LG", "cs.CL", "cs.CR", "I.2.7; I.2.8"], "pdf": "https://arxiv.org/pdf/2507.07735", "abs": "https://arxiv.org/abs/2507.07735", "authors": ["Peiyan Zhang", "Haibo Jin", "Liying Kang", "Haohan Wang"], "title": "GuardVal: Dynamic Large Language Model Jailbreak Evaluation for Comprehensive Safety Testing", "comment": "24 pages", "summary": "Jailbreak attacks reveal critical vulnerabilities in Large Language Models\n(LLMs) by causing them to generate harmful or unethical content. Evaluating\nthese threats is particularly challenging due to the evolving nature of LLMs\nand the sophistication required in effectively probing their vulnerabilities.\nCurrent benchmarks and evaluation methods struggle to fully address these\nchallenges, leaving gaps in the assessment of LLM vulnerabilities. In this\npaper, we review existing jailbreak evaluation practices and identify three\nassumed desiderata for an effective jailbreak evaluation protocol. To address\nthese challenges, we introduce GuardVal, a new evaluation protocol that\ndynamically generates and refines jailbreak prompts based on the defender LLM's\nstate, providing a more accurate assessment of defender LLMs' capacity to\nhandle safety-critical situations. Moreover, we propose a new optimization\nmethod that prevents stagnation during prompt refinement, ensuring the\ngeneration of increasingly effective jailbreak prompts that expose deeper\nweaknesses in the defender LLMs. We apply this protocol to a diverse set of\nmodels, from Mistral-7b to GPT-4, across 10 safety domains. Our findings\nhighlight distinct behavioral patterns among the models, offering a\ncomprehensive view of their robustness. Furthermore, our evaluation process\ndeepens the understanding of LLM behavior, leading to insights that can inform\nfuture research and drive the development of more secure models.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86GuardVal\uff0c\u4e00\u79cd\u52a8\u6001\u751f\u6210\u548c\u4f18\u5316\u8d8a\u72f1\u63d0\u793a\u7684\u65b0\u8bc4\u4f30\u534f\u8bae\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLM\u5728\u5b89\u5168\u5173\u952e\u60c5\u51b5\u4e0b\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u5168\u9762\u8bc4\u4f30LLM\u7684\u6f0f\u6d1e\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u8d8a\u72f1\u653b\u51fb\u65f6\u3002", "method": "\u63d0\u51faGuardVal\u534f\u8bae\uff0c\u52a8\u6001\u751f\u6210\u548c\u4f18\u5316\u8d8a\u72f1\u63d0\u793a\uff0c\u5e76\u7ed3\u5408\u65b0\u7684\u4f18\u5316\u65b9\u6cd5\u9632\u6b62\u505c\u6ede\u3002", "result": "\u5e94\u7528\u4e8e\u591a\u79cd\u6a21\u578b\uff08\u5982Mistral-7b\u548cGPT-4\uff09\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u884c\u4e3a\u6a21\u5f0f\u53ca\u5176\u9c81\u68d2\u6027\u3002", "conclusion": "GuardVal\u4e0d\u4ec5\u63d0\u5347\u4e86\u8bc4\u4f30\u6548\u679c\uff0c\u8fd8\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5f00\u53d1\u66f4\u5b89\u5168\u7684LLM\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2507.07738", "categories": ["cs.LG", "econ.EM"], "pdf": "https://arxiv.org/pdf/2507.07738", "abs": "https://arxiv.org/abs/2507.07738", "authors": ["Tomu Hirata", "Undral Byambadalai", "Tatsushi Oka", "Shota Yasui", "Shingo Uto"], "title": "Efficient and Scalable Estimation of Distributional Treatment Effects with Multi-Task Neural Networks", "comment": null, "summary": "We propose a novel multi-task neural network approach for estimating\ndistributional treatment effects (DTE) in randomized experiments. While DTE\nprovides more granular insights into the experiment outcomes over conventional\nmethods focusing on the Average Treatment Effect (ATE), estimating it with\nregression adjustment methods presents significant challenges. Specifically,\nprecision in the distribution tails suffers due to data imbalance, and\ncomputational inefficiencies arise from the need to solve numerous regression\nproblems, particularly in large-scale datasets commonly encountered in\nindustry. To address these limitations, our method leverages multi-task neural\nnetworks to estimate conditional outcome distributions while incorporating\nmonotonic shape constraints and multi-threshold label learning to enhance\naccuracy. To demonstrate the practical effectiveness of our proposed method, we\napply our method to both simulated and real-world datasets, including a\nrandomized field experiment aimed at reducing water consumption in the US and a\nlarge-scale A/B test from a leading streaming platform in Japan. The\nexperimental results consistently demonstrate superior performance across\nvarious datasets, establishing our method as a robust and practical solution\nfor modern causal inference applications requiring a detailed understanding of\ntreatment effect heterogeneity.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u4efb\u52a1\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u968f\u673a\u5b9e\u9a8c\u4e2d\u7684\u5206\u5e03\u5904\u7406\u6548\u5e94\uff08DTE\uff09\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u6570\u636e\u4e0d\u5e73\u8861\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982ATE\uff09\u65e0\u6cd5\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u5b9e\u9a8c\u6548\u679c\u5206\u6790\uff0c\u4e14\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u65f6\u5b58\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u95ee\u9898\u3002", "method": "\u5229\u7528\u591a\u4efb\u52a1\u795e\u7ecf\u7f51\u7edc\u4f30\u8ba1\u6761\u4ef6\u7ed3\u679c\u5206\u5e03\uff0c\u7ed3\u5408\u5355\u8c03\u5f62\u72b6\u7ea6\u675f\u548c\u591a\u9608\u503c\u6807\u7b7e\u5b66\u4e60\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\uff08\u5982\u8282\u6c34\u5b9e\u9a8c\u548c\u6d41\u5a92\u4f53\u5e73\u53f0A/B\u6d4b\u8bd5\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u73b0\u4ee3\u56e0\u679c\u63a8\u65ad\u5e94\u7528\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5904\u7406\u6548\u5e94\u5f02\u8d28\u6027\u5206\u6790\u3002"}}
{"id": "2507.07754", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07754", "abs": "https://arxiv.org/abs/2507.07754", "authors": ["Jaeheun Jung", "Bosung Jung", "Suhyun Bae", "Donghun Lee"], "title": "OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting", "comment": null, "summary": "Machine unlearning seeks to remove the influence of particular data or class\nfrom trained models to meet privacy, legal, or ethical requirements. Existing\nunlearning methods tend to forget shallowly: phenomenon of an unlearned model\npretend to forget by adjusting only the model response, while its internal\nrepresentations retain information sufficiently to restore the forgotten data\nor behavior. We empirically confirm the widespread shallowness by reverting the\nforgetting effect of various unlearning methods via training-free performance\nrecovery attack and gradient-inversion-based data reconstruction attack. To\naddress this vulnerability fundamentally, we define a theoretical criterion of\n``deep forgetting'' based on one-point-contraction of feature representations\nof data to forget. We also propose an efficient approximation algorithm, and\nuse it to construct a novel general-purpose unlearning algorithm:\nOne-Point-Contraction (OPC). Empirical evaluations on image classification\nunlearning benchmarks show that OPC achieves not only effective unlearning\nperformance but also superior resilience against both performance recovery\nattack and gradient-inversion attack. The distinctive unlearning performance of\nOPC arises from the deep feature forgetting enforced by its theoretical\nfoundation, and recaps the need for improved robustness of machine unlearning\nmethods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\uff08OPC\uff09\uff0c\u901a\u8fc7\u6df1\u5ea6\u7279\u5f81\u9057\u5fd8\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u6d45\u5c42\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5bf9\u6297\u6027\u80fd\u6062\u590d\u548c\u6570\u636e\u91cd\u5efa\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\u4ec5\u901a\u8fc7\u8c03\u6574\u6a21\u578b\u54cd\u5e94\u5b9e\u73b0\u6d45\u5c42\u9057\u5fd8\uff0c\u5185\u90e8\u8868\u5f81\u4ecd\u4fdd\u7559\u88ab\u9057\u5fd8\u6570\u636e\u7684\u4fe1\u606f\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9690\u79c1\u3001\u6cd5\u5f8b\u6216\u4f26\u7406\u8981\u6c42\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7279\u5f81\u8868\u793a\u5355\u70b9\u6536\u7f29\u7684\u6df1\u5ea6\u9057\u5fd8\u7406\u8bba\u6807\u51c6\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u8fd1\u4f3c\u7b97\u6cd5OPC\u3002", "result": "OPC\u5728\u56fe\u50cf\u5206\u7c7b\u9057\u5fd8\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u6709\u6548\u5bf9\u6297\u6027\u80fd\u6062\u590d\u548c\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u3002", "conclusion": "OPC\u7684\u6df1\u5ea6\u7279\u5f81\u9057\u5fd8\u673a\u5236\u63d0\u5347\u4e86\u9057\u5fd8\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.07768", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.07768", "abs": "https://arxiv.org/abs/2507.07768", "authors": ["Tejaswini Medi", "Steffen Jung", "Margret Keuper"], "title": "TRIX- Trading Adversarial Fairness via Mixed Adversarial Training", "comment": null, "summary": "Adversarial Training (AT) is a widely adopted defense against adversarial\nexamples. However, existing approaches typically apply a uniform training\nobjective across all classes, overlooking disparities in class-wise\nvulnerability. This results in adversarial unfairness: classes with well\ndistinguishable features (strong classes) tend to become more robust, while\nclasses with overlapping or shared features(weak classes) remain\ndisproportionately susceptible to adversarial attacks. We observe that strong\nclasses do not require strong adversaries during training, as their non-robust\nfeatures are quickly suppressed. In contrast, weak classes benefit from\nstronger adversaries to effectively reduce their vulnerabilities. Motivated by\nthis, we introduce TRIX, a feature-aware adversarial training framework that\nadaptively assigns weaker targeted adversaries to strong classes, promoting\nfeature diversity via uniformly sampled targets, and stronger untargeted\nadversaries to weak classes, enhancing their focused robustness. TRIX further\nincorporates per-class loss weighting and perturbation strength adjustments,\nbuilding on prior work, to emphasize weak classes during the optimization.\nComprehensive experiments on standard image classification benchmarks,\nincluding evaluations under strong attacks such as PGD and AutoAttack,\ndemonstrate that TRIX significantly improves worst-case class accuracy on both\nclean and adversarial data, reducing inter-class robustness disparities, and\npreserves overall accuracy. Our results highlight TRIX as a practical step\ntoward fair and effective adversarial defense.", "AI": {"tldr": "TRIX\u662f\u4e00\u79cd\u7279\u5f81\u611f\u77e5\u7684\u5bf9\u6297\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u4e3a\u5f3a\u7c7b\u5206\u914d\u8f83\u5f31\u7684\u76ee\u6807\u5bf9\u6297\u6837\u672c\uff0c\u4e3a\u5f31\u7c7b\u5206\u914d\u8f83\u5f3a\u7684\u65e0\u76ee\u6807\u5bf9\u6297\u6837\u672c\uff0c\u4ee5\u51cf\u5c11\u7c7b\u95f4\u9c81\u68d2\u6027\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u5bf9\u6240\u6709\u7c7b\u522b\u91c7\u7528\u7edf\u4e00\u76ee\u6807\uff0c\u5ffd\u7565\u4e86\u7c7b\u95f4\u8106\u5f31\u6027\u5dee\u5f02\uff0c\u5bfc\u81f4\u5f3a\u7c7b\u66f4\u9c81\u68d2\u800c\u5f31\u7c7b\u66f4\u6613\u53d7\u653b\u51fb\u3002", "method": "TRIX\u81ea\u9002\u5e94\u5730\u4e3a\u5f3a\u7c7b\u5206\u914d\u5f31\u76ee\u6807\u5bf9\u6297\u6837\u672c\u4ee5\u4fc3\u8fdb\u7279\u5f81\u591a\u6837\u6027\uff0c\u4e3a\u5f31\u7c7b\u5206\u914d\u5f3a\u65e0\u76ee\u6807\u5bf9\u6297\u6837\u672c\u4ee5\u589e\u5f3a\u5176\u9c81\u68d2\u6027\uff0c\u5e76\u7ed3\u5408\u6bcf\u7c7b\u635f\u5931\u6743\u91cd\u548c\u6270\u52a8\u5f3a\u5ea6\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTRIX\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u5dee\u7c7b\u522b\u5728\u5e72\u51c0\u548c\u5bf9\u6297\u6570\u636e\u4e0a\u7684\u51c6\u786e\u7387\uff0c\u51cf\u5c11\u4e86\u7c7b\u95f4\u9c81\u68d2\u6027\u5dee\u5f02\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6574\u4f53\u51c6\u786e\u7387\u3002", "conclusion": "TRIX\u662f\u5b9e\u73b0\u516c\u5e73\u6709\u6548\u5bf9\u6297\u9632\u5fa1\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2507.07778", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.07778", "abs": "https://arxiv.org/abs/2507.07778", "authors": ["Wooseong Jeong", "Jegyeong Cho", "Youngho Yoon", "Kuk-Jin Yoon"], "title": "Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training", "comment": "Accepted at ICCV 2025", "summary": "Generalizing neural networks to unseen target domains is a significant\nchallenge in real-world deployments. Test-time training (TTT) addresses this by\nusing an auxiliary self-supervised task to reduce the domain gap caused by\ndistribution shifts between the source and target. However, we find that when\nmodels are required to perform multiple tasks under domain shifts, conventional\nTTT methods suffer from unsynchronized task behavior, where the adaptation\nsteps needed for optimal performance in one task may not align with the\nrequirements of other tasks. To address this, we propose a novel TTT approach\ncalled Synchronizing Tasks for Test-time Training (S4T), which enables the\nconcurrent handling of multiple tasks. The core idea behind S4T is that\npredicting task relations across domain shifts is key to synchronizing tasks\nduring test time. To validate our approach, we apply S4T to conventional\nmulti-task benchmarks, integrating it with traditional TTT protocols. Our\nempirical results show that S4T outperforms state-of-the-art TTT methods across\nvarious benchmarks.", "AI": {"tldr": "S4T\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u540c\u6b65\u591a\u4efb\u52a1\u884c\u4e3a\u6765\u89e3\u51b3\u4f20\u7edfTTT\u65b9\u6cd5\u5728\u591a\u4efb\u52a1\u4e0b\u7684\u4e0d\u534f\u8c03\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u5728\u76ee\u6807\u57df\u6cdb\u5316\u4e2d\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u591a\u4efb\u52a1\u4e0b\u4f20\u7edfTTT\u65b9\u6cd5\u7684\u4efb\u52a1\u884c\u4e3a\u4e0d\u540c\u6b65\u95ee\u9898\u3002", "method": "\u63d0\u51faS4T\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u8de8\u57df\u4efb\u52a1\u5173\u7cfb\u6765\u540c\u6b65\u591a\u4efb\u52a1\u884c\u4e3a\uff0c\u5e76\u4e0e\u4f20\u7edfTTT\u534f\u8bae\u7ed3\u5408\u3002", "result": "S4T\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709TTT\u65b9\u6cd5\u3002", "conclusion": "S4T\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4efb\u52a1\u4e0b\u7684\u57df\u9002\u5e94\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.07804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07804", "abs": "https://arxiv.org/abs/2507.07804", "authors": ["Alba Garrido", "Alejandro Almod\u00f3var", "Patricia A. Apell\u00e1niz", "Juan Parras", "Santiago Zazo"], "title": "Deep Survival Analysis in Multimodal Medical Data: A Parametric and Probabilistic Approach with Competing Risks", "comment": "29 pages, 9 Figures", "summary": "Accurate survival prediction is critical in oncology for prognosis and\ntreatment planning. Traditional approaches often rely on a single data\nmodality, limiting their ability to capture the complexity of tumor biology. To\naddress this challenge, we introduce a multimodal deep learning framework for\nsurvival analysis capable of modeling both single and competing risks\nscenarios, evaluating the impact of integrating multiple medical data sources\non survival predictions. We propose SAMVAE (Survival Analysis Multimodal\nVariational Autoencoder), a novel deep learning architecture designed for\nsurvival prediction that integrates six data modalities: clinical variables,\nfour molecular profiles, and histopathological images. SAMVAE leverages\nmodality specific encoders to project inputs into a shared latent space,\nenabling robust survival prediction while preserving modality specific\ninformation. Its parametric formulation enables the derivation of clinically\nmeaningful statistics from the output distributions, providing patient-specific\ninsights through interactive multimedia that contribute to more informed\nclinical decision-making and establish a foundation for interpretable,\ndata-driven survival analysis in oncology. We evaluate SAMVAE on two cancer\ncohorts breast cancer and lower grade glioma applying tailored preprocessing,\ndimensionality reduction, and hyperparameter optimization. The results\ndemonstrate the successful integration of multimodal data for both standard\nsurvival analysis and competing risks scenarios across different datasets. Our\nmodel achieves competitive performance compared to state-of-the-art multimodal\nsurvival models. Notably, this is the first parametric multimodal deep learning\narchitecture to incorporate competing risks while modeling continuous time to a\nspecific event, using both tabular and image data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSAMVAE\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u5b58\u5206\u6790\uff0c\u6574\u5408\u4e86\u516d\u79cd\u6570\u636e\u6a21\u6001\uff0c\u5e76\u5728\u4e73\u817a\u764c\u548c\u4f4e\u7ea7\u522b\u80f6\u8d28\u7624\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u751f\u5b58\u9884\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u6570\u636e\u6a21\u6001\uff0c\u96be\u4ee5\u6355\u6349\u80bf\u7624\u751f\u7269\u5b66\u7684\u590d\u6742\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86SAMVAE\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u5c06\u8f93\u5165\u6620\u5c04\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\uff0c\u652f\u6301\u751f\u5b58\u9884\u6d4b\u548c\u7ade\u4e89\u98ce\u9669\u573a\u666f\u5206\u6790\u3002", "result": "\u5728\u4e73\u817a\u764c\u548c\u4f4e\u7ea7\u522b\u80f6\u8d28\u7624\u6570\u636e\u4e0a\uff0cSAMVAE\u8868\u73b0\u51fa\u8272\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u63d0\u4f9b\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u7edf\u8ba1\u4fe1\u606f\u3002", "conclusion": "SAMVAE\u4e3a\u80bf\u7624\u5b66\u4e2d\u7684\u751f\u5b58\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u3001\u6570\u636e\u9a71\u52a8\u7684\u65b0\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u548c\u7ade\u4e89\u98ce\u9669\u5efa\u6a21\u3002"}}
{"id": "2507.07814", "categories": ["cs.LG", "cs.NA", "math.NA", "15A42, 15A60, 68T07"], "pdf": "https://arxiv.org/pdf/2507.07814", "abs": "https://arxiv.org/abs/2507.07814", "authors": ["Nikolay Yudin", "Alexander Gaponov", "Sergei Kudriashov", "Maxim Rakhuba"], "title": "Pay Attention to Attention Distribution: A New Local Lipschitz Bound for Transformers", "comment": null, "summary": "We present a novel local Lipschitz bound for self-attention blocks of\ntransformers. This bound is based on a refined closed-form expression for the\nspectral norm of the softmax function. The resulting bound is not only more\naccurate than in the prior art, but also unveils the dependence of the\nLipschitz constant on attention score maps. Based on the new findings, we\nsuggest an explanation of the way distributions inside the attention map affect\nthe robustness from the Lipschitz constant perspective. We also introduce a new\nlightweight regularization term called JaSMin (Jacobian Softmax norm\nMinimization), which boosts the transformer's robustness and decreases local\nLipschitz constants of the whole network.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u6ce8\u610f\u529b\u5757\u7684\u5c40\u90e8Lipschitz\u754c\uff0c\u57fa\u4e8e\u6539\u8fdb\u7684softmax\u51fd\u6570\u8c31\u8303\u6570\u5c01\u95ed\u8868\u8fbe\u5f0f\uff0c\u63ed\u793a\u4e86\u6ce8\u610f\u529b\u5206\u6570\u56fe\u5bf9Lipschitz\u5e38\u6570\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6b63\u5219\u5316\u9879JaSMin\u4ee5\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "motivation": "\u7814\u7a76\u81ea\u6ce8\u610f\u529b\u5757\u7684Lipschitz\u6027\u8d28\uff0c\u63ed\u793a\u5176\u5bf9Transformer\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6539\u8fdb\u7684softmax\u8c31\u8303\u6570\u5c01\u95ed\u8868\u8fbe\u5f0f\u63a8\u5bfc\u5c40\u90e8Lipschitz\u754c\uff0c\u5e76\u63d0\u51faJaSMin\u6b63\u5219\u5316\u9879\u3002", "result": "\u65b0\u754c\u66f4\u51c6\u786e\uff0c\u63ed\u793a\u4e86\u6ce8\u610f\u529b\u5206\u6570\u56fe\u7684\u5f71\u54cd\uff0cJaSMin\u63d0\u5347\u4e86\u9c81\u68d2\u6027\u5e76\u964d\u4f4e\u4e86Lipschitz\u5e38\u6570\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u4e3a\u7406\u89e3Transformer\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0cJaSMin\u662f\u4e00\u79cd\u6709\u6548\u7684\u6b63\u5219\u5316\u624b\u6bb5\u3002"}}
{"id": "2507.07826", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.07826", "abs": "https://arxiv.org/abs/2507.07826", "authors": ["Erfan Mirzaei", "Andreas Maurer", "Vladimir R. Kostic", "Massimiliano Pontil"], "title": "An Empirical Bernstein Inequality for Dependent Data in Hilbert Spaces and Applications", "comment": "In The 28th International Conference on Artificial Intelligence and\n  Statistics (2025)", "summary": "Learning from non-independent and non-identically distributed data poses a\npersistent challenge in statistical learning. In this study, we introduce\ndata-dependent Bernstein inequalities tailored for vector-valued processes in\nHilbert space. Our inequalities apply to both stationary and non-stationary\nprocesses and exploit the potential rapid decay of correlations between\ntemporally separated variables to improve estimation. We demonstrate the\nutility of these bounds by applying them to covariance operator estimation in\nthe Hilbert-Schmidt norm and to operator learning in dynamical systems,\nachieving novel risk bounds. Finally, we perform numerical experiments to\nillustrate the practical implications of these bounds in both contexts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9488\u5bf9Hilbert\u7a7a\u95f4\u4e2d\u5411\u91cf\u503c\u8fc7\u7a0b\u7684\u6570\u636e\u4f9d\u8d56Bernstein\u4e0d\u7b49\u5f0f\uff0c\u9002\u7528\u4e8e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\uff0c\u6539\u8fdb\u4e86\u534f\u65b9\u5dee\u7b97\u5b50\u4f30\u8ba1\u548c\u52a8\u6001\u7cfb\u7edf\u7b97\u5b50\u5b66\u4e60\u7684\u98ce\u9669\u754c\u9650\u3002", "motivation": "\u89e3\u51b3\u7edf\u8ba1\u5b66\u4e60\u4e2d\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u7684\u6311\u6218\uff0c\u5229\u7528\u53d8\u91cf\u95f4\u76f8\u5173\u6027\u5feb\u901f\u8870\u51cf\u7684\u7279\u6027\u6539\u8fdb\u4f30\u8ba1\u3002", "method": "\u5f15\u5165\u6570\u636e\u4f9d\u8d56\u7684Bernstein\u4e0d\u7b49\u5f0f\uff0c\u9002\u7528\u4e8e\u5e73\u7a33\u548c\u975e\u5e73\u7a33\u8fc7\u7a0b\uff0c\u5e94\u7528\u4e8e\u534f\u65b9\u5dee\u7b97\u5b50\u4f30\u8ba1\u548c\u52a8\u6001\u7cfb\u7edf\u7b97\u5b50\u5b66\u4e60\u3002", "result": "\u5728Hilbert-Schmidt\u8303\u6570\u4e0b\u5b9e\u73b0\u4e86\u65b0\u7684\u98ce\u9669\u754c\u9650\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e0d\u7b49\u5f0f\u5728\u534f\u65b9\u5dee\u4f30\u8ba1\u548c\u52a8\u6001\u7cfb\u7edf\u5b66\u4e60\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u6539\u8fdb\u4e86\u73b0\u6709\u98ce\u9669\u754c\u9650\u3002"}}
{"id": "2507.07829", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07829", "abs": "https://arxiv.org/abs/2507.07829", "authors": ["Martin Mr\u00e1z", "Breenda Das", "Anshul Gupta", "Lennart Purucker", "Frank Hutter"], "title": "Towards Benchmarking Foundation Models for Tabular Data With Text", "comment": "Accepted at Foundation Models for Structured Data workshop at ICML\n  2025", "summary": "Foundation models for tabular data are rapidly evolving, with increasing\ninterest in extending them to support additional modalities such as free-text\nfeatures. However, existing benchmarks for tabular data rarely include textual\ncolumns, and identifying real-world tabular datasets with semantically rich\ntext features is non-trivial. We propose a series of simple yet effective\nablation-style strategies for incorporating text into conventional tabular\npipelines. Moreover, we benchmark how state-of-the-art tabular foundation\nmodels can handle textual data by manually curating a collection of real-world\ntabular datasets with meaningful textual features. Our study is an important\nstep towards improving benchmarking of foundation models for tabular data with\ntext.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6587\u672c\u6570\u636e\u6574\u5408\u5230\u8868\u683c\u6570\u636e\u4e2d\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u8868\u683c\u57fa\u7840\u6a21\u578b\u5904\u7406\u6587\u672c\u6570\u636e\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8868\u683c\u6570\u636e\u57fa\u51c6\u5f88\u5c11\u5305\u542b\u6587\u672c\u5217\uff0c\u4e14\u96be\u4ee5\u627e\u5230\u5177\u6709\u4e30\u5bcc\u8bed\u4e49\u6587\u672c\u7279\u5f81\u7684\u771f\u5b9e\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u7b80\u5355\u6709\u6548\u7684\u7b56\u7565\uff0c\u5c06\u6587\u672c\u6574\u5408\u5230\u4f20\u7edf\u8868\u683c\u6d41\u7a0b\u4e2d\uff0c\u5e76\u624b\u52a8\u6574\u7406\u4e86\u4e00\u7ec4\u771f\u5b9e\u6570\u636e\u96c6\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684\u8868\u683c\u57fa\u7840\u6a21\u578b\u5904\u7406\u6587\u672c\u6570\u636e\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6539\u8fdb\u8868\u683c\u6570\u636e\u57fa\u7840\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2507.07848", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07848", "abs": "https://arxiv.org/abs/2507.07848", "authors": ["Giovanni Dispoto", "Paolo Bonetti", "Marcello Restelli"], "title": "\"So, Tell Me About Your Policy...\": Distillation of interpretable policies from Deep Reinforcement Learning agents", "comment": null, "summary": "Recent advances in Reinforcement Learning (RL) largely benefit from the\ninclusion of Deep Neural Networks, boosting the number of novel approaches\nproposed in the field of Deep Reinforcement Learning (DRL). These techniques\ndemonstrate the ability to tackle complex games such as Atari, Go, and other\nreal-world applications, including financial trading. Nevertheless, a\nsignificant challenge emerges from the lack of interpretability, particularly\nwhen attempting to comprehend the underlying patterns learned, the relative\nimportance of the state features, and how they are integrated to generate the\npolicy's output. For this reason, in mission-critical and real-world settings,\nit is often preferred to deploy a simpler and more interpretable algorithm,\nalthough at the cost of performance. In this paper, we propose a novel\nalgorithm, supported by theoretical guarantees, that can extract an\ninterpretable policy (e.g., a linear policy) without disregarding the\npeculiarities of expert behavior. This result is obtained by considering the\nadvantage function, which includes information about why an action is superior\nto the others. In contrast to previous works, our approach enables the training\nof an interpretable policy using previously collected experience. The proposed\nalgorithm is empirically evaluated on classic control environments and on a\nfinancial trading scenario, demonstrating its ability to extract meaningful\ninformation from complex expert policies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u80fd\u5728\u4fdd\u6301\u4e13\u5bb6\u884c\u4e3a\u7279\u70b9\u7684\u540c\u65f6\u63d0\u53d6\u53ef\u89e3\u91ca\u7b56\u7565\uff08\u5982\u7ebf\u6027\u7b56\u7565\uff09\uff0c\u5e76\u901a\u8fc7\u4f18\u52bf\u51fd\u6570\u5b9e\u73b0\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u5173\u952e\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528\u4f18\u52bf\u51fd\u6570\u63d0\u53d6\u53ef\u89e3\u91ca\u7b56\u7565\uff0c\u652f\u6301\u4ece\u5df2\u6709\u7ecf\u9a8c\u4e2d\u8bad\u7ec3\u3002", "result": "\u5728\u7ecf\u5178\u63a7\u5236\u73af\u5883\u548c\u91d1\u878d\u4ea4\u6613\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a\u5173\u952e\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u5e73\u8861\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.07852", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.07852", "abs": "https://arxiv.org/abs/2507.07852", "authors": ["Haichen Hu", "David Simchi-Levi"], "title": "Pre-Trained AI Model Assisted Online Decision-Making under Missing Covariates: A Theoretical Perspective", "comment": null, "summary": "We study a sequential contextual decision-making problem in which certain\ncovariates are missing but can be imputed using a pre-trained AI model. From a\ntheoretical perspective, we analyze how the presence of such a model influences\nthe regret of the decision-making process. We introduce a novel notion called\n\"model elasticity\", which quantifies the sensitivity of the reward function to\nthe discrepancy between the true covariate and its imputed counterpart. This\nconcept provides a unified way to characterize the regret incurred due to model\nimputation, regardless of the underlying missingness mechanism. More\nsurprisingly, we show that under the missing at random (MAR) setting, it is\npossible to sequentially calibrate the pre-trained model using tools from\northogonal statistical learning and doubly robust regression. This calibration\nsignificantly improves the quality of the imputed covariates, leading to much\nbetter regret guarantees. Our analysis highlights the practical value of having\nan accurate pre-trained model in sequential decision-making tasks and suggests\nthat model elasticity may serve as a fundamental metric for understanding and\nimproving the integration of pre-trained models in a wide range of data-driven\ndecision-making problems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u5728\u7f3a\u5931\u534f\u53d8\u91cf\u60c5\u51b5\u4e0b\u4f7f\u7528\u9884\u8bad\u7ec3AI\u6a21\u578b\u8fdb\u884c\u586b\u8865\u7684\u5e8f\u5217\u4e0a\u4e0b\u6587\u51b3\u7b56\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u201c\u6a21\u578b\u5f39\u6027\u201d\u6982\u5ff5\uff0c\u5e76\u5728MAR\u5047\u8bbe\u4e0b\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u6821\u51c6\u63d0\u5347\u586b\u8865\u8d28\u91cf\u3002", "motivation": "\u63a2\u8ba8\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\u4e2d\u5bf9\u9057\u61be\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u7edf\u4e00\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u586b\u8865\u8bef\u5dee\u7684\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u201c\u6a21\u578b\u5f39\u6027\u201d\u6982\u5ff5\uff0c\u5229\u7528\u6b63\u4ea4\u7edf\u8ba1\u5b66\u4e60\u548c\u53cc\u91cd\u7a33\u5065\u56de\u5f52\u6280\u672f\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u6821\u51c6\u3002", "result": "\u5728\u6821\u51c6\u540e\uff0c\u586b\u8865\u534f\u53d8\u91cf\u7684\u8d28\u91cf\u663e\u8457\u63d0\u5347\uff0c\u4ece\u800c\u6539\u5584\u4e86\u9057\u61be\u4fdd\u8bc1\u3002", "conclusion": "\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u51c6\u786e\u6027\u5bf9\u5e8f\u5217\u51b3\u7b56\u4efb\u52a1\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u6a21\u578b\u5f39\u6027\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u6574\u5408\u7684\u57fa\u7840\u6307\u6807\u3002"}}
{"id": "2507.07853", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.07853", "abs": "https://arxiv.org/abs/2507.07853", "authors": ["Navish Kumar", "Thomas M\u00f6llenhoff", "Mohammad Emtiyaz Khan", "Aurelien Lucchi"], "title": "Optimization Guarantees for Square-Root Natural-Gradient Variational Inference", "comment": null, "summary": "Variational inference with natural-gradient descent often shows fast\nconvergence in practice, but its theoretical convergence guarantees have been\nchallenging to establish. This is true even for the simplest cases that involve\nconcave log-likelihoods and use a Gaussian approximation. We show that the\nchallenge can be circumvented for such cases using a square-root\nparameterization for the Gaussian covariance. This approach establishes novel\nconvergence guarantees for natural-gradient variational-Gaussian inference and\nits continuous-time gradient flow. Our experiments demonstrate the\neffectiveness of natural gradient methods and highlight their advantages over\nalgorithms that use Euclidean or Wasserstein geometries.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5e73\u65b9\u6839\u53c2\u6570\u5316\u9ad8\u65af\u534f\u65b9\u5dee\uff0c\u4e3a\u81ea\u7136\u68af\u5ea6\u53d8\u5206\u9ad8\u65af\u63a8\u65ad\u53ca\u5176\u8fde\u7eed\u65f6\u95f4\u68af\u5ea6\u6d41\u5efa\u7acb\u4e86\u65b0\u7684\u6536\u655b\u4fdd\u8bc1\u3002", "motivation": "\u5c3d\u7ba1\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u5feb\u901f\u6536\u655b\uff0c\u4f46\u5176\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u96be\u4ee5\u5efa\u7acb\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u51f9\u5bf9\u6570\u4f3c\u7136\u548c\u9ad8\u65af\u8fd1\u4f3c\u7684\u6700\u7b80\u5355\u60c5\u51b5\u4e0b\u3002", "method": "\u91c7\u7528\u5e73\u65b9\u6839\u53c2\u6570\u5316\u9ad8\u65af\u534f\u65b9\u5dee\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u81ea\u7136\u68af\u5ea6\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u7a81\u51fa\u4e86\u5176\u4f18\u4e8e\u6b27\u51e0\u91cc\u5f97\u6216Wasserstein\u51e0\u4f55\u7b97\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7\u5e73\u65b9\u6839\u53c2\u6570\u5316\uff0c\u6210\u529f\u5efa\u7acb\u4e86\u81ea\u7136\u68af\u5ea6\u53d8\u5206\u9ad8\u65af\u63a8\u65ad\u7684\u6536\u655b\u4fdd\u8bc1\u3002"}}
{"id": "2507.07854", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07854", "abs": "https://arxiv.org/abs/2507.07854", "authors": ["Zizhou Zhang", "Qinyan Shen", "Zhuohuan Hu", "Qianying Liu", "Huijie Shen"], "title": "Credit Risk Analysis for SMEs Using Graph Neural Networks in Supply Chain", "comment": "The paper will be published on 2025 International Conference on Big\n  Data, Artificial Intelligence and Digital Economy", "summary": "Small and Medium-sized Enterprises (SMEs) are vital to the modern economy,\nyet their credit risk analysis often struggles with scarce data, especially for\nonline lenders lacking direct credit records. This paper introduces a Graph\nNeural Network (GNN)-based framework, leveraging SME interactions from\ntransaction and social data to map spatial dependencies and predict loan\ndefault risks. Tests on real-world datasets from Discover and Ant Credit (23.4M\nnodes for supply chain analysis, 8.6M for default prediction) show the GNN\nsurpasses traditional and other GNN baselines, with AUCs of 0.995 and 0.701 for\nsupply chain mining and default prediction, respectively. It also helps\nregulators model supply chain disruption impacts on banks, accurately\nforecasting loan defaults from material shortages, and offers Federal Reserve\nstress testers key data for CCAR risk buffers. This approach provides a\nscalable, effective tool for assessing SME credit risk.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u6846\u67b6\uff0c\u5229\u7528\u4e2d\u5c0f\u4f01\u4e1a\u7684\u4ea4\u6613\u548c\u793e\u4ea4\u6570\u636e\u9884\u6d4b\u8d37\u6b3e\u8fdd\u7ea6\u98ce\u9669\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4e2d\u5c0f\u4f01\u4e1a\u7684\u4fe1\u7528\u98ce\u9669\u5206\u6790\u5e38\u56e0\u6570\u636e\u7a00\u7f3a\u800c\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5bf9\u7f3a\u4e4f\u76f4\u63a5\u4fe1\u7528\u8bb0\u5f55\u7684\u5728\u7ebf\u8d37\u6b3e\u673a\u6784\u3002", "method": "\u4f7f\u7528GNN\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u6613\u548c\u793e\u4ea4\u6570\u636e\u6620\u5c04\u7a7a\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u9884\u6d4b\u8d37\u6b3e\u8fdd\u7ea6\u98ce\u9669\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cGNN\u5728\u4f9b\u5e94\u94fe\u5206\u6790\u548c\u8fdd\u7ea6\u9884\u6d4b\u4e2d\u7684AUC\u5206\u522b\u4e3a0.995\u548c0.701\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e2d\u5c0f\u4f01\u4e1a\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u5de5\u5177\uff0c\u5e76\u4e3a\u76d1\u7ba1\u673a\u6784\u63d0\u4f9b\u4e86\u5173\u952e\u6570\u636e\u3002"}}
{"id": "2507.07855", "categories": ["cs.LG", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.07855", "abs": "https://arxiv.org/abs/2507.07855", "authors": ["Wenxuan Zhou", "Shujian Zhang", "Brice Magdalou", "John Lambert", "Ehsan Amid", "Richard Nock", "Andrew Hard"], "title": "Principled Foundations for Preference Optimization", "comment": null, "summary": "In this paper, we show that direct preference optimization (DPO) is a very\nspecific form of a connection between two major theories in the ML context of\nlearning from preferences: loss functions (Savage) and stochastic choice\n(Doignon-Falmagne and Machina). The connection is established for all of\nSavage's losses and at this level of generality, (i) it includes support for\nabstention on the choice theory side, (ii) it includes support for non-convex\nobjectives on the ML side, and (iii) it allows to frame for free some notable\nextensions of the DPO setting, including margins and corrections for length.\nGetting to understand how DPO operates from a general principled perspective is\ncrucial because of the huge and diverse application landscape of models,\nbecause of the current momentum around DPO, but also -- and importantly --\nbecause many state of the art variations on DPO definitely occupy a small\nregion of the map that we cover. It also helps to understand the pitfalls of\ndeparting from this map, and figure out workarounds.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u504f\u597d\u5b66\u4e60\u7684\u4e24\u79cd\u4e3b\u8981\u7406\u8bba\uff08\u635f\u5931\u51fd\u6570\u4e0e\u968f\u673a\u9009\u62e9\uff09\u4e4b\u95f4\u7684\u7279\u5b9a\u8054\u7cfb\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u6f5c\u5728\u6269\u5c55\u3002", "motivation": "\u7406\u89e3DPO\u7684\u901a\u7528\u539f\u7406\u5bf9\u4e8e\u5176\u5e7f\u6cdb\u5e94\u7528\u3001\u5f53\u524d\u7814\u7a76\u70ed\u70b9\u4ee5\u53ca\u907f\u514d\u6f5c\u5728\u9677\u9631\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5efa\u7acbSavage\u635f\u5931\u51fd\u6570\u4e0e\u968f\u673a\u9009\u62e9\u7406\u8bba\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u652f\u6301\u4e86DPO\u7684\u591a\u79cd\u6269\u5c55\uff08\u5982\u5f03\u6743\u3001\u975e\u51f8\u76ee\u6807\u7b49\uff09\u3002", "result": "\u7814\u7a76\u6db5\u76d6\u4e86\u6240\u6709Savage\u635f\u5931\u51fd\u6570\uff0c\u5e76\u5c55\u793a\u4e86DPO\u5728\u591a\u79cd\u573a\u666f\u4e0b\u7684\u9002\u7528\u6027\uff0c\u5305\u62ec\u8fb9\u9645\u548c\u957f\u5ea6\u4fee\u6b63\u3002", "conclusion": "DPO\u7684\u901a\u7528\u89c6\u89d2\u6709\u52a9\u4e8e\u7406\u89e3\u5176\u64cd\u4f5c\u539f\u7406\u3001\u6269\u5c55\u5e94\u7528\u8303\u56f4\uff0c\u5e76\u907f\u514d\u504f\u79bb\u7406\u8bba\u6846\u67b6\u7684\u6f5c\u5728\u95ee\u9898\u3002"}}
{"id": "2507.07862", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.07862", "abs": "https://arxiv.org/abs/2507.07862", "authors": ["Tianang Leng", "Fangping Wan", "Marcelo Der Torossian Torres", "Cesar de la Fuente-Nunez"], "title": "Predicting and generating antibiotics against future pathogens with ApexOracle", "comment": "3 figures", "summary": "Antimicrobial resistance (AMR) is escalating and outpacing current antibiotic\ndevelopment. Thus, discovering antibiotics effective against emerging pathogens\nis becoming increasingly critical. However, existing approaches cannot rapidly\nidentify effective molecules against novel pathogens or emerging drug-resistant\nstrains. Here, we introduce ApexOracle, an artificial intelligence (AI) model\nthat both predicts the antibacterial potency of existing compounds and designs\nde novo molecules active against strains it has never encountered. Departing\nfrom models that rely solely on molecular features, ApexOracle incorporates\npathogen-specific context through the integration of molecular features\ncaptured via a foundational discrete diffusion language model and a\ndual-embedding framework that combines genomic- and literature-derived strain\nrepresentations. Across diverse bacterial species and chemical modalities,\nApexOracle consistently outperformed state-of-the-art approaches in activity\nprediction and demonstrated reliable transferability to novel pathogens with\nlittle or no antimicrobial data. Its unified representation-generation\narchitecture further enables the in silico creation of \"new-to-nature\"\nmolecules with high predicted efficacy against priority threats. By pairing\nrapid activity prediction with targeted molecular generation, ApexOracle offers\na scalable strategy for countering AMR and preparing for future\ninfectious-disease outbreaks.", "AI": {"tldr": "ApexOracle\u662f\u4e00\u79cdAI\u6a21\u578b\uff0c\u80fd\u9884\u6d4b\u73b0\u6709\u5316\u5408\u7269\u7684\u6297\u83cc\u6548\u529b\u5e76\u8bbe\u8ba1\u65b0\u578b\u5206\u5b50\u5bf9\u6297\u65b0\u75c5\u539f\u4f53\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6297\u83cc\u7d20\u8010\u836f\u6027\uff08AMR\uff09\u52a0\u5267\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5feb\u901f\u8bc6\u522b\u6709\u6548\u5206\u5b50\u5bf9\u6297\u65b0\u75c5\u539f\u4f53\u6216\u8010\u836f\u83cc\u682a\u3002", "method": "\u7ed3\u5408\u5206\u5b50\u7279\u5f81\u548c\u75c5\u539f\u4f53\u7279\u5f02\u6027\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u548c\u53cc\u5d4c\u5165\u6846\u67b6\u6574\u5408\u57fa\u56e0\u7ec4\u548c\u6587\u732e\u6570\u636e\u3002", "result": "\u5728\u591a\u79cd\u7ec6\u83cc\u548c\u5316\u5b66\u6a21\u5f0f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u53ef\u9760\u8fc1\u79fb\u81f3\u65e0\u6297\u83cc\u6570\u636e\u7684\u65b0\u75c5\u539f\u4f53\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u65b0\u5206\u5b50\u3002", "conclusion": "ApexOracle\u4e3a\u5bf9\u6297AMR\u548c\u672a\u6765\u4f20\u67d3\u75c5\u7206\u53d1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u7b56\u7565\u3002"}}
{"id": "2507.07882", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07882", "abs": "https://arxiv.org/abs/2507.07882", "authors": ["Wei-Tse Hsu", "Savva Grevtsev", "Thomas Douglas", "Aniket Magarkar", "Philip C. Biggin"], "title": "Can AI-predicted complexes teach machine learning to compute drug binding affinity?", "comment": null, "summary": "We evaluate the feasibility of using co-folding models for synthetic data\naugmentation in training machine learning-based scoring functions (MLSFs) for\nbinding affinity prediction. Our results show that performance gains depend\ncritically on the structural quality of augmented data. In light of this, we\nestablished simple heuristics for identifying high-quality co-folding\npredictions without reference structures, enabling them to substitute for\nexperimental structures in MLSF training. Our study informs future data\naugmentation strategies based on co-folding models.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528\u5171\u6298\u53e0\u6a21\u578b\u8fdb\u884c\u5408\u6210\u6570\u636e\u589e\u5f3a\u5728\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u8bc4\u5206\u51fd\u6570\uff08MLSF\uff09\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u53d1\u73b0\u6027\u80fd\u63d0\u5347\u4f9d\u8d56\u4e8e\u589e\u5f3a\u6570\u636e\u7684\u7ed3\u6784\u8d28\u91cf\uff0c\u5e76\u63d0\u51fa\u4e86\u65e0\u9700\u53c2\u8003\u7ed3\u6784\u8bc6\u522b\u9ad8\u8d28\u91cf\u5171\u6298\u53e0\u9884\u6d4b\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u5171\u6298\u53e0\u6a21\u578b\u5728\u5408\u6210\u6570\u636e\u589e\u5f3a\u4e2d\u7684\u6f5c\u529b\uff0c\u4ee5\u6539\u8fdb\u673a\u5668\u5b66\u4e60\u8bc4\u5206\u51fd\u6570\u7684\u8bad\u7ec3\u6548\u679c\u3002", "method": "\u901a\u8fc7\u8bc4\u4f30\u5171\u6298\u53e0\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u8d28\u91cf\uff0c\u5efa\u7acb\u542f\u53d1\u5f0f\u65b9\u6cd5\u8bc6\u522b\u9ad8\u8d28\u91cf\u9884\u6d4b\u3002", "result": "\u6027\u80fd\u63d0\u5347\u4f9d\u8d56\u4e8e\u589e\u5f3a\u6570\u636e\u7684\u7ed3\u6784\u8d28\u91cf\uff0c\u542f\u53d1\u5f0f\u65b9\u6cd5\u53ef\u6709\u6548\u8bc6\u522b\u9ad8\u8d28\u91cf\u5171\u6298\u53e0\u9884\u6d4b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u57fa\u4e8e\u5171\u6298\u53e0\u6a21\u578b\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2507.07883", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07883", "abs": "https://arxiv.org/abs/2507.07883", "authors": ["Hao Ban", "Gokul Ram Subramani", "Kaiyi Ji"], "title": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation", "comment": null, "summary": "Multi-task learning (MTL) enables a joint model to capture commonalities\nacross multiple tasks, reducing computation costs and improving data\nefficiency. However, a major challenge in MTL optimization is task conflicts,\nwhere the task gradients differ in direction or magnitude, limiting model\nperformance compared to single-task counterparts. Sharpness-aware minimization\n(SAM) minimizes task loss while simultaneously reducing the sharpness of the\nloss landscape. Our empirical observations show that SAM effectively mitigates\ntask conflicts in MTL. Motivated by these findings, we explore integrating SAM\ninto MTL but face two key challenges. While both the average loss gradient and\nindividual task gradients-referred to as global and local\ninformation-contribute to SAM, how to combine them remains unclear. Moreover,\ndirectly computing each task gradient introduces significant computational and\nmemory overheads. To address these challenges, we propose SAMO, a lightweight\n\\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization\napproach, that leverages a joint global-local perturbation. The local\nperturbations are approximated using only forward passes and are layerwise\nnormalized to improve efficiency. Extensive experiments on a suite of\nmulti-task benchmarks demonstrate both the effectiveness and efficiency of our\nmethod. Code is available at https://github.com/OptMN-Lab/SAMO.", "AI": {"tldr": "SAMO\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u9510\u5ea6\u611f\u77e5\u591a\u4efb\u52a1\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u5c40-\u5c40\u90e8\u6270\u52a8\u7ed3\u5408\u89e3\u51b3\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u4efb\u52a1\u51b2\u7a81\u95ee\u9898\u3002", "motivation": "\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u4e2d\u4efb\u52a1\u51b2\u7a81\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u800c\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316\uff08SAM\uff09\u80fd\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5982\u4f55\u7ed3\u5408\u5168\u5c40\u548c\u5c40\u90e8\u4fe1\u606f\u4ee5\u53ca\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u662f\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51faSAMO\u65b9\u6cd5\uff0c\u5229\u7528\u8054\u5408\u5168\u5c40-\u5c40\u90e8\u6270\u52a8\uff0c\u901a\u8fc7\u4ec5\u524d\u5411\u4f20\u64ad\u8fd1\u4f3c\u5c40\u90e8\u6270\u52a8\u5e76\u8fdb\u884c\u5c42\u5f52\u4e00\u5316\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5728\u591a\u4e2a\u591a\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "SAMO\u6210\u529f\u89e3\u51b3\u4e86\u4efb\u52a1\u51b2\u7a81\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.07885", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07885", "abs": "https://arxiv.org/abs/2507.07885", "authors": ["Ashe Neth", "Sawinder kaur", "Mohammad Nur Hossain Khan", "Subrata Biswas", "Asif Salekin", "Bashima Islam"], "title": "UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs", "comment": "Submitted to SenSys 2026 on July 1, 2025", "summary": "Existing pruning methods are typically applied during training or compile\ntime and often rely on structured sparsity. While compatible with low-power\nmicrocontrollers (MCUs), structured pruning underutilizes the opportunity for\nfine-grained efficiency on devices without SIMD support or parallel compute. To\naddress these limitations, we introduce UnIT (Unstructured Inference-Time\npruning), a lightweight method that dynamically identifies and skips\nunnecessary multiply-accumulate (MAC) operations during inference, guided by\ninput-specific activation patterns. Unlike structured pruning, UnIT embraces\nirregular sparsity and does not require retraining or hardware specialization.\nIt transforms pruning decisions into lightweight comparisons, replacing\nmultiplications with threshold checks and approximated divisions. UnIT further\noptimizes compute by reusing threshold computations across multiple connections\nand applying layer- and group-specific pruning sensitivity. We present three\nfast, hardware-friendly division approximations tailored to the capabilities of\ncommon embedded platforms. Demonstrated on the MSP430 microcontroller, UnIT\nachieves 11.02% to 82.03% MAC reduction, 27.30% to 84.19% faster inference, and\n27.33% to 84.38% lower energy consumption compared to training-time pruned\nmodels, while maintaining accuracy with 0.48-7%. Under domain shift, UnIT\nmatches or exceeds the accuracy of retrained models while requiring\nsignificantly fewer MACs. These results establish unstructured inference-time\npruning as a viable and practical solution for efficient, retraining-free\ndeployment of deep neural networks on MCUs.", "AI": {"tldr": "UnIT\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8df3\u8fc7\u4e0d\u5fc5\u8981\u7684\u4e58\u52a0\u64cd\u4f5c\uff0c\u5b9e\u73b0\u65e0\u7ed3\u6784\u7a00\u758f\u6027\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u786c\u4ef6\u5b9a\u5236\uff0c\u663e\u8457\u63d0\u5347MCU\u4e0a\u7684\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u901a\u5e38\u5728\u8bad\u7ec3\u6216\u7f16\u8bd1\u65f6\u5e94\u7528\uff0c\u4f9d\u8d56\u7ed3\u6784\u5316\u7a00\u758f\u6027\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u65e0SIMD\u652f\u6301\u8bbe\u5907\u7684\u7ec6\u7c92\u5ea6\u6548\u7387\u3002", "method": "UnIT\u901a\u8fc7\u8f93\u5165\u7279\u5b9a\u7684\u6fc0\u6d3b\u6a21\u5f0f\u52a8\u6001\u8bc6\u522b\u5e76\u8df3\u8fc7\u4e0d\u5fc5\u8981\u7684\u4e58\u52a0\u64cd\u4f5c\uff0c\u5c06\u526a\u679d\u51b3\u7b56\u8f6c\u5316\u4e3a\u8f7b\u91cf\u7ea7\u6bd4\u8f83\uff0c\u5e76\u4f18\u5316\u8ba1\u7b97\u3002", "result": "\u5728MSP430\u4e0a\uff0cUnIT\u5b9e\u73b011.02%-82.03%\u7684\u4e58\u52a0\u64cd\u4f5c\u51cf\u5c11\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u534727.30%-84.19%\uff0c\u80fd\u8017\u964d\u4f4e27.33%-84.38%\uff0c\u7cbe\u5ea6\u635f\u5931\u4ec50.48%-7%\u3002", "conclusion": "UnIT\u8bc1\u660e\u65e0\u7ed3\u6784\u63a8\u7406\u65f6\u526a\u679d\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8eMCU\u4e0a\u7684\u9ad8\u6548\u795e\u7ecf\u7f51\u7edc\u90e8\u7f72\u3002"}}
{"id": "2507.07898", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.07898", "abs": "https://arxiv.org/abs/2507.07898", "authors": ["Mohammad Fesanghary", "Achintya Gopal"], "title": "Efficient Causal Discovery for Autoregressive Time Series", "comment": "10 pages, 8 figures", "summary": "In this study, we present a novel constraint-based algorithm for causal\nstructure learning specifically designed for nonlinear autoregressive time\nseries. Our algorithm significantly reduces computational complexity compared\nto existing methods, making it more efficient and scalable to larger problems.\nWe rigorously evaluate its performance on synthetic datasets, demonstrating\nthat our algorithm not only outperforms current techniques, but also excels in\nscenarios with limited data availability. These results highlight its potential\nfor practical applications in fields requiring efficient and accurate causal\ninference from nonlinear time series data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u975e\u7ebf\u6027\u81ea\u56de\u5f52\u65f6\u95f4\u5e8f\u5217\u7684\u65b0\u578b\u7ea6\u675f\u7b97\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u81ea\u56de\u5f52\u65f6\u95f4\u5e8f\u5217\u7684\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u4e2d\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9650\u5236\u4e86\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7ea6\u675f\u7b97\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5c24\u5176\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u975e\u7ebf\u6027\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u9ad8\u6548\u51c6\u786e\u56e0\u679c\u63a8\u65ad\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.07906", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07906", "abs": "https://arxiv.org/abs/2507.07906", "authors": ["Anant Gupta", "Rajarshi Bhowmik", "Geoffrey Gunow"], "title": "Agentic Retrieval of Topics and Insights from Earnings Calls", "comment": "The 2nd Workshop on Financial Information Retrieval in the Era of\n  Generative AI, The 48th International ACM SIGIR Conference on Research and\n  Development in Information Retrieval July 13-17, 2025 | Padua, Italy", "summary": "Tracking the strategic focus of companies through topics in their earnings\ncalls is a key task in financial analysis. However, as industries evolve,\ntraditional topic modeling techniques struggle to dynamically capture emerging\ntopics and their relationships. In this work, we propose an LLM-agent driven\napproach to discover and retrieve emerging topics from quarterly earnings\ncalls. We propose an LLM-agent to extract topics from documents, structure them\ninto a hierarchical ontology, and establish relationships between new and\nexisting topics through a topic ontology. We demonstrate the use of extracted\ntopics to infer company-level insights and emerging trends over time. We\nevaluate our approach by measuring ontology coherence, topic evolution\naccuracy, and its ability to surface emerging financial trends.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM-agent\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u5b63\u5ea6\u8d22\u62a5\u7535\u8bdd\u4f1a\u8bae\u4e2d\u52a8\u6001\u53d1\u73b0\u548c\u63d0\u53d6\u65b0\u5174\u4e3b\u9898\uff0c\u5e76\u6784\u5efa\u5c42\u6b21\u5316\u4e3b\u9898\u672c\u4f53\u3002", "motivation": "\u4f20\u7edf\u4e3b\u9898\u5efa\u6a21\u6280\u672f\u96be\u4ee5\u52a8\u6001\u6355\u6349\u65b0\u5174\u4e3b\u9898\u53ca\u5176\u5173\u7cfb\uff0c\u800c\u91d1\u878d\u5206\u6790\u9700\u8981\u8ddf\u8e2a\u516c\u53f8\u6218\u7565\u91cd\u70b9\u7684\u53d8\u5316\u3002", "method": "\u4f7f\u7528LLM-agent\u4ece\u6587\u6863\u4e2d\u63d0\u53d6\u4e3b\u9898\uff0c\u6784\u5efa\u5c42\u6b21\u5316\u4e3b\u9898\u672c\u4f53\uff0c\u5e76\u901a\u8fc7\u4e3b\u9898\u672c\u4f53\u5efa\u7acb\u65b0\u65e7\u4e3b\u9898\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u901a\u8fc7\u8bc4\u4f30\u672c\u4f53\u4e00\u81f4\u6027\u3001\u4e3b\u9898\u6f14\u5316\u51c6\u786e\u6027\u548c\u6355\u6349\u65b0\u5174\u91d1\u878d\u8d8b\u52bf\u7684\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u52a8\u6001\u6355\u6349\u65b0\u5174\u4e3b\u9898\uff0c\u4e3a\u516c\u53f8\u7ea7\u6d1e\u5bdf\u548c\u8d8b\u52bf\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.07919", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.07919", "abs": "https://arxiv.org/abs/2507.07919", "authors": ["Jakub \u010cern\u00fd", "Ji\u0159\u00ed N\u011bme\u010dek", "Ivan Dovica", "Jakub Mare\u010dek"], "title": "Plausible Counterfactual Explanations of Recommendations", "comment": "8 pages, 3 figures, 6 tables", "summary": "Explanations play a variety of roles in various recommender systems, from a\nlegally mandated afterthought, through an integral element of user experience,\nto a key to persuasiveness. A natural and useful form of an explanation is the\nCounterfactual Explanation (CE). We present a method for generating highly\nplausible CEs in recommender systems and evaluate it both numerically and with\na user study.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u9ad8\u53ef\u4fe1\u5ea6\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CE\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u8fdb\u884c\u4e86\u6570\u503c\u548c\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u3002", "motivation": "\u89e3\u91ca\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u5177\u6709\u591a\u79cd\u4f5c\u7528\uff0c\u4ece\u6cd5\u5f8b\u8981\u6c42\u7684\u8865\u5145\u5230\u7528\u6237\u4f53\u9a8c\u7684\u6838\u5fc3\u90e8\u5206\uff0c\u751a\u81f3\u662f\u8bf4\u670d\u529b\u7684\u5173\u952e\u3002\u53cd\u4e8b\u5b9e\u89e3\u91ca\u662f\u4e00\u79cd\u81ea\u7136\u4e14\u6709\u7528\u7684\u89e3\u91ca\u5f62\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u9ad8\u53ef\u4fe1\u5ea6\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u6570\u503c\u8bc4\u4f30\u548c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9ad8\u53ef\u4fe1\u5ea6\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u9002\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u591a\u79cd\u573a\u666f\u3002"}}
{"id": "2507.07947", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07947", "abs": "https://arxiv.org/abs/2507.07947", "authors": ["Sol Yarkoni", "Roi Livni"], "title": "Low Resource Reconstruction Attacks Through Benign Prompts", "comment": null, "summary": "The recent advances in generative models such as diffusion models have raised\nseveral risks and concerns related to privacy, copyright infringements and data\nstewardship. To better understand and control the risks, various researchers\nhave created techniques, experiments and attacks that reconstruct images, or\npart of images, from the training set. While these techniques already establish\nthat data from the training set can be reconstructed, they often rely on\nhigh-resources, excess to the training set as well as well-engineered and\ndesigned prompts.\n  In this work, we devise a new attack that requires low resources, assumes\nlittle to no access to the actual training set, and identifies, seemingly,\nbenign prompts that lead to potentially-risky image reconstruction. This\nhighlights the risk that images might even be reconstructed by an uninformed\nuser and unintentionally. For example, we identified that, with regard to one\nexisting model, the prompt ``blue Unisex T-Shirt'' can generate the face of a\nreal-life human model. Our method builds on an intuition from previous works\nwhich leverages domain knowledge and identifies a fundamental vulnerability\nthat stems from the use of scraped data from e-commerce platforms, where\ntemplated layouts and images are tied to pattern-like prompts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u8d44\u6e90\u3001\u65e0\u9700\u8bad\u7ec3\u96c6\u8bbf\u95ee\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u770b\u4f3c\u65e0\u5bb3\u7684\u63d0\u793a\u8bcd\u91cd\u5efa\u8bad\u7ec3\u96c6\u4e2d\u7684\u56fe\u50cf\uff0c\u63ed\u793a\u4e86\u751f\u6210\u6a21\u578b\u5728\u9690\u79c1\u548c\u6570\u636e\u7ba1\u7406\u65b9\u9762\u7684\u6f5c\u5728\u98ce\u9669\u3002", "motivation": "\u751f\u6210\u6a21\u578b\uff08\u5982\u6269\u6563\u6a21\u578b\uff09\u7684\u8fdb\u6b65\u5f15\u53d1\u4e86\u9690\u79c1\u3001\u7248\u6743\u548c\u6570\u636e\u7ba1\u7406\u7684\u98ce\u9669\u3002\u73b0\u6709\u6280\u672f\u901a\u5e38\u4f9d\u8d56\u9ad8\u8d44\u6e90\u548c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u66f4\u666e\u904d\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u5de5\u4f5c\u7684\u76f4\u89c9\uff0c\u5229\u7528\u9886\u57df\u77e5\u8bc6\uff0c\u53d1\u73b0\u4ece\u7535\u5546\u5e73\u53f0\u6293\u53d6\u7684\u6570\u636e\u5b58\u5728\u6a21\u677f\u5316\u5e03\u5c40\u548c\u56fe\u50cf\u4e0e\u6a21\u5f0f\u5316\u63d0\u793a\u8bcd\u5173\u8054\u7684\u6f0f\u6d1e\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u4f8b\u5982\u63d0\u793a\u8bcd\u201c\u84dd\u8272Unisex T-Shirt\u201d\u53ef\u4ee5\u751f\u6210\u771f\u5b9e\u4eba\u7c7b\u6a21\u7279\u7684\u56fe\u50cf\uff0c\u8868\u660e\u5373\u4f7f\u662f\u666e\u901a\u7528\u6237\u4e5f\u53ef\u80fd\u65e0\u610f\u4e2d\u91cd\u5efa\u654f\u611f\u6570\u636e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u751f\u6210\u6a21\u578b\u5728\u6570\u636e\u9690\u79c1\u65b9\u9762\u7684\u6f5c\u5728\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u6539\u8fdb\u6570\u636e\u7ba1\u7406\u548c\u6a21\u578b\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.07955", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07955", "abs": "https://arxiv.org/abs/2507.07955", "authors": ["Sukjun Hwang", "Brandon Wang", "Albert Gu"], "title": "Dynamic Chunking for End-to-End Hierarchical Sequence Modeling", "comment": null, "summary": "Despite incredible progress in language models (LMs) in recent years, largely\nresulting from moving away from specialized models designed for specific tasks\nto general models based on powerful architectures (e.g. the Transformer) that\nlearn everything from raw data, pre-processing steps such as tokenization\nremain a barrier to true end-to-end foundation models. We introduce a\ncollection of new techniques that enable a dynamic chunking mechanism which\nautomatically learns content -- and context -- dependent segmentation\nstrategies learned jointly with the rest of the model. Incorporating this into\nan explicit hierarchical network (H-Net) allows replacing the (implicitly\nhierarchical) tokenization-LM-detokenization pipeline with a single model\nlearned fully end-to-end. When compute- and data- matched, an H-Net with one\nstage of hierarchy operating at the byte level outperforms a strong Transformer\nlanguage model operating over BPE tokens. Iterating the hierarchy to multiple\nstages further increases its performance by modeling multiple levels of\nabstraction, demonstrating significantly better scaling with data and matching\na token-based Transformer of twice its size. H-Nets pretrained on English show\nsignificantly increased character-level robustness, and qualitatively learn\nmeaningful data-dependent chunking strategies without any heuristics or\nexplicit supervision. Finally, the H-Net's improvement over tokenized pipelines\nis further increased in languages and modalities with weaker tokenization\nheuristics, such as Chinese and code, or DNA sequences (nearly 4x improvement\nin data efficiency over baselines), showing the potential of true end-to-end\nmodels that learn and scale better from unprocessed data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u5206\u5757\u673a\u5236\uff08H-Net\uff09\uff0c\u53d6\u4ee3\u4f20\u7edf\u7684\u5206\u8bcd-\u8bed\u8a00\u6a21\u578b-\u53bb\u5206\u8bcd\u6d41\u7a0b\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u7aef\u5230\u7aef\u5b66\u4e60\u3002H-Net\u5728\u6027\u80fd\u548c\u6570\u636e\u6548\u7387\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u5206\u8bcd\u7684Transformer\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u4ecd\u4f9d\u8d56\u5206\u8bcd\u7b49\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u9650\u5236\u4e86\u7aef\u5230\u7aef\u6a21\u578b\u7684\u6f5c\u529b\u3002\u8bba\u6587\u65e8\u5728\u6d88\u9664\u8fd9\u4e00\u969c\u788d\uff0c\u5b9e\u73b0\u5b8c\u5168\u7aef\u5230\u7aef\u7684\u5b66\u4e60\u3002", "method": "\u5f15\u5165\u52a8\u6001\u5206\u5757\u673a\u5236\uff0c\u7ed3\u5408\u5206\u5c42\u7f51\u7edc\uff08H-Net\uff09\uff0c\u81ea\u52a8\u5b66\u4e60\u5185\u5bb9\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5206\u6bb5\u7b56\u7565\u3002", "result": "H-Net\u5728\u5b57\u8282\u7ea7\u522b\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8eBPE\u5206\u8bcd\u7684Transformer\uff0c\u591a\u7ea7\u5206\u5c42\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6570\u636e\u6548\u7387\u3002\u5728\u4e2d\u6587\u3001\u4ee3\u7801\u548cDNA\u5e8f\u5217\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "H-Net\u5c55\u793a\u4e86\u7aef\u5230\u7aef\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u6570\u636e\u6548\u7387\u548c\u591a\u8bed\u8a00\u3001\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.07965", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.07965", "abs": "https://arxiv.org/abs/2507.07965", "authors": ["Yuxin Bai", "Cecelia Shuai", "Ashwin De Silva", "Siyu Yu", "Pratik Chaudhari", "Joshua T. Vogelstein"], "title": "Prospective Learning in Retrospect", "comment": "Accepted to AGI 2025", "summary": "In most real-world applications of artificial intelligence, the distributions\nof the data and the goals of the learners tend to change over time. The\nProbably Approximately Correct (PAC) learning framework, which underpins most\nmachine learning algorithms, fails to account for dynamic data distributions\nand evolving objectives, often resulting in suboptimal performance. Prospective\nlearning is a recently introduced mathematical framework that overcomes some of\nthese limitations. We build on this framework to present preliminary results\nthat improve the algorithm and numerical results, and extend prospective\nlearning to sequential decision-making scenarios, specifically foraging. Code\nis available at: https://github.com/neurodata/prolearn2.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u524d\u77bb\u6027\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfPAC\u5b66\u4e60\u5728\u52a8\u6001\u6570\u636e\u5206\u5e03\u548c\u6f14\u53d8\u76ee\u6807\u4e2d\u7684\u4e0d\u8db3\uff0c\u5e76\u5e94\u7528\u4e8e\u987a\u5e8f\u51b3\u7b56\u573a\u666f\uff08\u5982\u89c5\u98df\uff09\u3002", "motivation": "\u4f20\u7edfPAC\u5b66\u4e60\u6846\u67b6\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u6570\u636e\u5206\u5e03\u548c\u76ee\u6807\u53d8\u5316\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u57fa\u4e8e\u524d\u77bb\u6027\u5b66\u4e60\u6846\u67b6\uff0c\u6539\u8fdb\u7b97\u6cd5\u548c\u6570\u503c\u7ed3\u679c\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u987a\u5e8f\u51b3\u7b56\u573a\u666f\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\u6539\u8fdb\u540e\u7684\u7b97\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u524d\u77bb\u6027\u5b66\u4e60\u6846\u67b6\u5728\u52a8\u6001\u548c\u987a\u5e8f\u51b3\u7b56\u573a\u666f\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.07986", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07986", "abs": "https://arxiv.org/abs/2507.07986", "authors": ["Perry Dong", "Qiyang Li", "Dorsa Sadigh", "Chelsea Finn"], "title": "EXPO: Stable Reinforcement Learning with Expressive Policies", "comment": null, "summary": "We study the problem of training and fine-tuning expressive policies with\nonline reinforcement learning (RL) given an offline dataset. Training\nexpressive policy classes with online RL present a unique challenge of stable\nvalue maximization. Unlike simpler Gaussian policies commonly used in online\nRL, expressive policies like diffusion and flow-matching policies are\nparameterized by a long denoising chain, which hinders stable gradient\npropagation from actions to policy parameters when optimizing against some\nvalue function. Our key insight is that we can address stable value\nmaximization by avoiding direct optimization over value with the expressive\npolicy and instead construct an on-the-fly RL policy to maximize Q-value. We\npropose Expressive Policy Optimization (EXPO), a sample-efficient online RL\nalgorithm that utilizes an on-the-fly policy to maximize value with two\nparameterized policies -- a larger expressive base policy trained with a stable\nimitation learning objective and a light-weight Gaussian edit policy that edits\nthe actions sampled from the base policy toward a higher value distribution.\nThe on-the-fly policy optimizes the actions from the base policy with the\nlearned edit policy and chooses the value maximizing action from the base and\nedited actions for both sampling and temporal-difference (TD) backup. Our\napproach yields up to 2-3x improvement in sample efficiency on average over\nprior methods both in the setting of fine-tuning a pretrained policy given\noffline data and in leveraging offline data to train online.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEXPO\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u7a33\u5b9a\u7684\u6a21\u4eff\u5b66\u4e60\u76ee\u6807\u548c\u8f7b\u91cf\u7ea7\u9ad8\u65af\u7f16\u8f91\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u79bb\u7ebf\u6570\u636e\u96c6\u7684\u57fa\u7840\u4e0a\u8bad\u7ec3\u548c\u5fae\u8c03\u8868\u8fbe\u6027\u7b56\u7565\uff0c\u89e3\u51b3\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7a33\u5b9a\u4ef7\u503c\u6700\u5927\u5316\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faEXPO\u7b97\u6cd5\uff0c\u4f7f\u7528\u4e24\u79cd\u53c2\u6570\u5316\u7b56\u7565\uff1a\u4e00\u4e2a\u8868\u8fbe\u6027\u57fa\u7840\u7b56\u7565\u548c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u9ad8\u65af\u7f16\u8f91\u7b56\u7565\uff0c\u901a\u8fc7\u7f16\u8f91\u52a8\u4f5c\u6765\u4f18\u5316\u4ef7\u503c\u5206\u5e03\u3002", "result": "\u5728\u5fae\u8c03\u9884\u8bad\u7ec3\u7b56\u7565\u548c\u5229\u7528\u79bb\u7ebf\u6570\u636e\u8bad\u7ec3\u5728\u7ebf\u7684\u4efb\u52a1\u4e2d\uff0c\u6837\u672c\u6548\u7387\u5e73\u5747\u63d0\u9ad8\u4e862-3\u500d\u3002", "conclusion": "EXPO\u901a\u8fc7\u907f\u514d\u76f4\u63a5\u4f18\u5316\u4ef7\u503c\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u8868\u8fbe\u6027\u7b56\u7565\u7684\u7a33\u5b9a\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2507.07996", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.07996", "abs": "https://arxiv.org/abs/2507.07996", "authors": ["Ziyue Li", "Yang Li", "Tianyi Zhou"], "title": "Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs", "comment": "9 pages, 7 figures", "summary": "Can a pretrained neural network adapt its architecture to different inputs\nwithout any finetuning? Do we need all layers for simple tasks, and are they\nadequate for challenging tasks? We found that the layers of a pretrained large\nlanguage model (LLM) can be manipulated as separate modules to build a better\nand even shallower model customized for each test sample. In particular, each\nlayer from the pretrained model can be skipped/pruned or repeated multiple\ntimes as recurrent neural networks (RNN), and stacked with others in arbitrary\norders, yielding a chain-of-layers (CoLa) per sample. This compositional space\ngreatly expands the scope of existing works on looped/recurrent pretrained\nmodules, layer pruning, or early-exit networks. We develop a Monte Carlo Tree\nSearch (MCTS) protocol to explore and identify the optimal CoLa for each sample\nfrom math and commonsense reasoning benchmarks. Compared to a static model of a\nfixed depth, CoLa allows shortcut paths (fast thinking), recurrence of the same\nlayer(s) (slow thinking), and combining both, offering more flexible, dynamic\narchitectures for different inputs. We conduct an extensive analysis of the\nMCTS-optimized CoLa, which leads to two key findings: (1) For >75% of samples\nwith correct predictions by the original LLM, we can find shorter CoLa,\nsuggesting a large space for improving inference efficiency; (2) For >60% of\nsamples with originally incorrect predictions, we can identify CoLa achieving\ncorrect predictions, suggesting a large space of performance enhancement. Our\nresults highlight the shortcomings of using a fixed architecture of pre-trained\nLLMs for inference on different samples and pave the way to unlock the\ngeneralization power of test-time depth adaptation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u67b6\u6784\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8df3\u8fc7\u3001\u91cd\u590d\u6216\u91cd\u65b0\u7ec4\u5408\u5c42\u6765\u4e3a\u6bcf\u4e2a\u6d4b\u8bd5\u6837\u672c\u5b9a\u5236\u66f4\u4f18\u7684\u6a21\u578b\uff08CoLa\uff09\u3002\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u4f18\u5316\u5c42\u7ec4\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u63a2\u8ba8\u9884\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u662f\u5426\u80fd\u5728\u4e0d\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u52a8\u6001\u8c03\u6574\u67b6\u6784\u4ee5\u9002\u5e94\u4e0d\u540c\u8f93\u5165\uff0c\u5e76\u9a8c\u8bc1\u662f\u5426\u9700\u8981\u6240\u6709\u5c42\u6765\u5904\u7406\u4e0d\u540c\u96be\u5ea6\u7684\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u94fe\u5f0f\u5c42\uff08CoLa\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u8df3\u8fc7\u3001\u91cd\u590d\u6216\u91cd\u65b0\u7ec4\u5408\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5c42\uff0c\u4e3a\u6bcf\u4e2a\u6837\u672c\u5b9a\u5236\u52a8\u6001\u67b6\u6784\u3002\u4f7f\u7528MCTS\u641c\u7d22\u6700\u4f18\u5c42\u7ec4\u5408\u3002", "result": "\u53d1\u73b075%\u7684\u6b63\u786e\u9884\u6d4b\u6837\u672c\u53ef\u901a\u8fc7\u66f4\u77ed\u7684CoLa\u63d0\u5347\u6548\u7387\uff0c60%\u7684\u9519\u8bef\u9884\u6d4b\u6837\u672c\u53ef\u901a\u8fc7\u4f18\u5316CoLa\u5b9e\u73b0\u6b63\u786e\u9884\u6d4b\u3002", "conclusion": "\u56fa\u5b9a\u67b6\u6784\u7684\u9884\u8bad\u7ec3LLM\u5b58\u5728\u5c40\u9650\u6027\uff0c\u52a8\u6001\u6df1\u5ea6\u8c03\u6574\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u548c\u6027\u80fd\u3002"}}
